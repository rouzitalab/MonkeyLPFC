{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/SachsLab/MonkeyPFCSaccadeStudies/blob/master/StudyLocationRule/Analysis/04_analyze_shallow.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/SachsLab/IMonkeyPFCSaccadeStudies/blob/master/StudyLocationRule/Analysis/04_analyze_shallow.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Decode Intended Saccade Direction from Macaque PFC Microelectrode Recordings with Shallow ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Normalize Environments\n",
    "Run the first two cells to normalize Local / Colab environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    %tensorflow_version 2.x  # Only on colab\n",
    "    os.chdir('..')\n",
    "    \n",
    "    if not (Path.home() / '.kaggle').is_dir():\n",
    "        # Configure kaggle\n",
    "        uploaded = files.upload()  # Find the kaggle.json file in your ~/.kaggle directory.\n",
    "        if 'kaggle.json' in uploaded.keys():\n",
    "            !mkdir -p ~/.kaggle\n",
    "            !mv kaggle.json ~/.kaggle/\n",
    "            !chmod 600 ~/.kaggle/kaggle.json\n",
    "    \n",
    "    !pip install git+https://github.com/SachsLab/indl.git\n",
    "    \n",
    "    if Path.cwd().stem == 'MonkeyPFCSaccadeStudies':\n",
    "        os.chdir(Path.cwd().parent)\n",
    "\n",
    "    if not (Path.cwd() / 'MonkeyPFCSaccadeStudies').is_dir():\n",
    "        !git clone --single-branch --recursive https://github.com/SachsLab/MonkeyPFCSaccadeStudies.git\n",
    "        sys.path.append(str(Path.cwd() / 'MonkeyPFCSaccadeStudies'))\n",
    "    os.chdir('MonkeyPFCSaccadeStudies')\n",
    "    \n",
    "    !pip install -q kaggle\n",
    "    plt.style.use('dark_background')\n",
    "    IN_COLAB = True\n",
    "except ModuleNotFoundError:\n",
    "    import sys\n",
    "    \n",
    "    # chdir to MonkeyPFCSaccadeStudies\n",
    "    if Path.cwd().stem == 'Analysis':\n",
    "        os.chdir(Path.cwd().parent.parent)\n",
    "    \n",
    "    # Add indl repository to path.\n",
    "    # Eventually this should already be pip installed, but it's still under heavy development so this is easier for now.\n",
    "    check_dir = Path.cwd()\n",
    "    while not (check_dir / 'Tools').is_dir():\n",
    "        check_dir = check_dir / '..'\n",
    "    indl_path = check_dir / 'Tools' / 'Neurophys' / 'indl'\n",
    "    sys.path.append(str(indl_path))\n",
    "    \n",
    "    # Make sure the kaggle executable is on the PATH\n",
    "    os.environ['PATH'] = os.environ['PATH'] + ';' + str(Path(sys.executable).parent / 'Scripts')\n",
    "    \n",
    "    IN_COLAB = False\n",
    "\n",
    "# Try to clear any logs from previous runs\n",
    "if (Path.cwd() / 'logs').is_dir():\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.rmtree(str(Path.cwd() / 'logs'))\n",
    "    except PermissionError:\n",
    "        print(\"Unable to remove logs directory.\")\n",
    "\n",
    "# Additional imports\n",
    "import tensorflow as tf\n",
    "from indl.display import turbo_cmap\n",
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 24,\n",
    "    'axes.labelsize': 20,\n",
    "    'lines.linewidth': 2,\n",
    "    'lines.markersize': 5,\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'legend.fontsize': 18\n",
    "})\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download and unzip data\n",
    "if IN_COLAB:\n",
    "    data_path = Path.cwd() / 'data' / 'monkey_pfc' / 'converted'\n",
    "else:\n",
    "    data_path = Path.cwd() / 'StudyLocationRule' / 'Data' / 'Preprocessed'\n",
    "\n",
    "if not (data_path).is_dir():\n",
    "    !kaggle datasets download --unzip --path {str(data_path)} cboulay/macaque-8a-spikes-rates-and-saccades\n",
    "    print(\"Finished downloading and extracting data.\")\n",
    "else:\n",
    "    print(\"Data directory found. Skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import\n",
    "\n",
    "We will set the parameters for our `load_macaque_pfc` function.\n",
    "Specifically, we are getting the spikerates, which have been smoothed and downsampled, only from trials where the outcome was correct and the d' was at least 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from misc.misc import load_macaque_pfc, sess_infos\n",
    "\n",
    "load_kwargs = {\n",
    "    'valid_outcomes': (0,),  # Use (0, 9) to include trials with incorrect behaviour\n",
    "    'zscore': True,\n",
    "    'dprime_range': (1.0, np.inf),  # Use (-np.inf, np.inf) to include all trials.\n",
    "    'verbose': True,\n",
    "    'y_type': 'sacClass',\n",
    "    'samples_last': True  # Our EEGNet blocks expect time-samples in the last dimension.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow ML Model\n",
    "\n",
    "We will use a 1-layer logistic regression to classify saccade target from presaccadic activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg_kwargs = {\n",
    "    'solver': 'lbfgs',\n",
    "    'C': 10.0,  # inverse regularization strength\n",
    "    'penalty': 'l2',\n",
    "    'multi_class': 'ovr',\n",
    "    'max_iter': 1000\n",
    "}\n",
    "N_SPLITS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Analysis\n",
    "\n",
    "### Calculate classification accuracy for each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies(sess_infos, time_range=(-np.inf, np.inf),\n",
    "                  log_reg_kwargs={'solver': 'lbfgs','C': 10.0,'penalty': 'l2',\n",
    "                                  'multi_class': 'ovr', 'max_iter': 500}):\n",
    "    \n",
    "    splitter = StratifiedKFold(n_splits=N_SPLITS, shuffle=True)\n",
    "    model = LogisticRegression(**log_reg_kwargs)\n",
    "\n",
    "    accs_out = []\n",
    "    for sess_ix, sess_info in enumerate(sess_infos):\n",
    "        sess_id = sess_info['exp_code']\n",
    "        print(f\"\\nProcessing session {sess_id}\")\n",
    "        X, Y, ax_info = load_macaque_pfc(data_path, sess_id, x_chunk='spikerates',\n",
    "                                         time_range=time_range,\n",
    "                                        **load_kwargs)\n",
    "        y_preds = []\n",
    "        y_true = []\n",
    "        X_flat = X.reshape(-1, np.prod(X.shape[1:]))\n",
    "\n",
    "        model = LogisticRegression(**log_reg_kwargs)\n",
    "\n",
    "        print(f\"Performing {N_SPLITS}-fold cross-validated logistic regression...\")\n",
    "        for kfold, (trn, tst) in enumerate(splitter.split(X, Y)):\n",
    "            print(f\"Fold {kfold + 1}\")\n",
    "\n",
    "            model.fit(X_flat[trn], Y[trn].ravel())\n",
    "            y_preds.append(model.predict(X_flat[tst]))\n",
    "            y_true.append(Y[tst].ravel())\n",
    "\n",
    "        y_preds = np.hstack(y_preds)\n",
    "        y_true = np.hstack(y_true)\n",
    "\n",
    "        pcnt_corr = 100 * np.sum(y_preds == y_true) / len(y_preds)\n",
    "        print(f\"{sess_id} 8-class accuracy: % {pcnt_corr:.2f}\")\n",
    "        accs_out.append(pcnt_corr)\n",
    "        \n",
    "    return accs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_out_bline = get_accuracies(sess_infos, time_range=(-np.inf, 0))\n",
    "accs_out_targ = get_accuracies(sess_infos, time_range=(-np.inf, 0.250))\n",
    "accs_out_prego = get_accuracies(sess_infos, time_range=(-np.inf, 1.45))\n",
    "accs_out_all = get_accuracies(sess_infos, time_range=(-np.inf, np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.vstack((accs_out_bline, accs_out_targ, accs_out_prego, accs_out_all)).T)\n",
    "print([_['exp_code'] for _ in sess_infos])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Analysis 2 - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "svm_kwargs = {\n",
    "    'C': 0.1,  # inverse regularization strength\n",
    "    'kernel': 'linear',  # ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’\n",
    "#     'degree': 3,  # Only used if kernel is 'poly'\n",
    "#     'gamma': 'scale',  # kernel coeff, used by 'rbf', 'poly', and 'sigmoid'\n",
    "    'class_weight': 'balanced',\n",
    "}\n",
    "\n",
    "def get_accuracies_svm(sess_infos, time_range=(-np.inf, np.inf),\n",
    "                       svm_kwargs={'C': 0.1, 'kernel': 'linear',\n",
    "                                   'class_weight': 'balanced'}):\n",
    "    \n",
    "    splitter = StratifiedKFold(n_splits=N_SPLITS, shuffle=True)\n",
    "\n",
    "    accs_out = []\n",
    "    for sess_ix, sess_info in enumerate(sess_infos):\n",
    "        sess_id = sess_info['exp_code']\n",
    "        print(f\"\\nProcessing session {sess_id}\")\n",
    "        X, Y, ax_info = load_macaque_pfc(data_path, sess_id, x_chunk='spikerates',\n",
    "                                         time_range=time_range,\n",
    "                                        **load_kwargs)\n",
    "        y_preds = []\n",
    "        y_true = []\n",
    "        X_flat = X.reshape(-1, np.prod(X.shape[1:]))\n",
    "\n",
    "        model = svm.SVC(**svm_kwargs)\n",
    "\n",
    "        print(f\"Performing {N_SPLITS}-fold cross-validated SVM...\")\n",
    "        for kfold, (trn, tst) in enumerate(splitter.split(X, Y)):\n",
    "            print(f\"Fold {kfold + 1}\")\n",
    "\n",
    "            model.fit(X_flat[trn], Y[trn].ravel())\n",
    "            y_preds.append(model.predict(X_flat[tst]))\n",
    "            y_true.append(Y[tst].ravel())\n",
    "\n",
    "        y_preds = np.hstack(y_preds)\n",
    "        y_true = np.hstack(y_true)\n",
    "\n",
    "        pcnt_corr = 100 * np.sum(y_preds == y_true) / len(y_preds)\n",
    "        print(f\"{sess_id} 8-class accuracy: % {pcnt_corr:.2f}\")\n",
    "        accs_out.append(pcnt_corr)\n",
    "        \n",
    "    return accs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_out_bline = get_accuracies(sess_infos, time_range=(-np.inf, 0))\n",
    "accs_out_targ = get_accuracies(sess_infos, time_range=(-np.inf, 0.250))\n",
    "accs_out_prego = get_accuracies(sess_infos, time_range=(-np.inf, 1.45))\n",
    "accs_out_all = get_accuracies(sess_infos, time_range=(-np.inf, np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.vstack((accs_out_bline, accs_out_targ, accs_out_prego, accs_out_all)).T)\n",
    "print([_['exp_code'] for _ in sess_infos])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
