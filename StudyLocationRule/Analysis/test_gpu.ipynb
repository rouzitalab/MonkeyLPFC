{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory found. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import signal\n",
    "from indl.display import turbo_cmap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from indl.fileio import from_neuropype_h5\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "\n",
    "if Path.cwd().stem == 'Analysis':\n",
    "    os.chdir(Path.cwd().parent.parent)\n",
    "    \n",
    "    \n",
    "data_path = Path.cwd() / 'StudyLocationRule'/ 'Data' / 'Preprocessed'\n",
    "if not (data_path).is_dir():\n",
    "    !kaggle datasets download --unzip --path {str(data_path)} cboulay/macaque-8a-spikes-rates-and-saccades\n",
    "    print(\"Finished downloading and extracting data.\")\n",
    "else:\n",
    "    print(\"Data directory found. Skipping download.\")\n",
    "    \n",
    "from misc.misc import sess_infos, load_macaque_pfc, dec_from_enc\n",
    "\n",
    "load_kwargs = {\n",
    "    'valid_outcomes': (0,),  # Use (0, 9) to include trials with incorrect behaviour\n",
    "    'zscore': True,\n",
    "    'dprime_range': (1.0, np.inf),  # Use (-np.inf, np.inf) to include all trials.\n",
    "    'time_range': (-np.inf, 1.45),\n",
    "    'verbose': False,\n",
    "    'y_type': 'sacClass',\n",
    "    'samples_last': True    \n",
    "    #     'resample_X': 20\n",
    "}\n",
    "\n",
    "load_kwargs_error = {\n",
    "    'valid_outcomes': (9,),  # Use (0, 9) to include trials with incorrect behaviour\n",
    "    'zscore': True,\n",
    "    'dprime_range': (1.0, np.inf),  # Use (-np.inf, np.inf) to include all trials.\n",
    "    'time_range': (-np.inf, 1.45),\n",
    "    'verbose': False,\n",
    "    'y_type': 'sacClass',\n",
    "    'samples_last': True    \n",
    "    #     'resample_X': 20\n",
    "}\n",
    "\n",
    "load_kwargs_all = {\n",
    "    'valid_outcomes': (0,9),  # Use (0, 9) to include trials with incorrect behaviour\n",
    "    'zscore': True,\n",
    "    'dprime_range': (1.0, np.inf),  # Use (-np.inf, np.inf) to include all trials.\n",
    "    'time_range': (-np.inf, 1.45),\n",
    "    'verbose': False,\n",
    "    'y_type': 'sacClass',\n",
    "    'samples_last': True    \n",
    "    #     'resample_X': 20\n",
    "}\n",
    "\n",
    "model_kwargs = dict(\n",
    "    filt=8,\n",
    "    kernLength=20,\n",
    "    ds_rate=5,\n",
    "    n_rnn=64,\n",
    "    n_rnn2=0,\n",
    "    dropoutRate=0.40,\n",
    "    activation='relu',\n",
    "    l1_reg=0.0000, l2_reg=0.001,\n",
    "    norm_rate=0.25,\n",
    "    latent_dim=64\n",
    ")\n",
    "model_kwargs1 = dict(\n",
    "    filt=16,\n",
    "    kernLength=30,\n",
    "    ds_rate=5,\n",
    "    n_rnn=64,\n",
    "    n_rnn2=64,\n",
    "    dropoutRate=0.40,\n",
    "    activation='relu',\n",
    "    l1_reg=0.0000, l2_reg=0.001,\n",
    "    norm_rate=0.25,\n",
    "    latent_dim=64\n",
    ")\n",
    "\n",
    "N_SPLITS = 10\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 150\n",
    "LABEL_SMOOTHING = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-97ecbf874269>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importing session sra3_1_j_050_00+\n"
     ]
    }
   ],
   "source": [
    "test_sess_ix = 1\n",
    "sess_info = sess_infos[test_sess_ix]\n",
    "sess_id = sess_info['exp_code']\n",
    "print(f\"\\nImporting session {sess_id}\")\n",
    "X_rates, Y, ax_info = load_macaque_pfc(data_path, sess_id, x_chunk='spikerates', **load_kwargs)\n",
    "Y_class = tf.keras.utils.to_categorical(Y, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape 36 205\n",
      "output 8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (16, 36, 100)             122400    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (16, 36, 100)             80400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (16, 100)                 80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (16, 8)                   808       \n",
      "=================================================================\n",
      "Total params: 284,008\n",
      "Trainable params: 284,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Created model.\n",
      "Compiled model.\n"
     ]
    }
   ],
   "source": [
    "number_of_classes = 8\n",
    "n_timesteps, n_features = X_rates.shape[1], X_rates.shape[2]\n",
    "\n",
    "print('input_shape', n_timesteps, n_features)\n",
    "print('output', number_of_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, batch_input_shape=(BATCH_SIZE,n_timesteps, n_features), return_sequences=True))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print(\"Created model.\")\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "print(\"Compiled model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = int(0.8*X_rates.shape[0])\n",
    "\n",
    "_y = Y_class\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((X_rates[:trn], _y[:trn]))\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices((X_rates[trn:], _y[trn:]))\n",
    "\n",
    "# cast data types to GPU-friendly types.\n",
    "ds_train = ds_train.map(lambda x, y: (tf.cast(x, tf.float32), tf.cast(y, tf.uint8)))\n",
    "ds_valid = ds_valid.map(lambda x, y: (tf.cast(x, tf.float32), tf.cast(y, tf.uint8)))\n",
    "\n",
    "# TODO: augmentations (random slicing?)\n",
    "\n",
    "ds_train = ds_train.shuffle(trn + 1)\n",
    "ds_train = ds_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "ds_valid = ds_valid.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "24/24 [==============================] - 6s 35ms/step - loss: 1.8628 - acc: 0.2895 - val_loss: 1.4408 - val_acc: 0.4688\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.9652 - acc: 0.5938 - val_loss: 2.0771 - val_acc: 0.3542\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6256 - acc: 0.7714 - val_loss: 0.9120 - val_acc: 0.6667\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4441 - acc: 0.8420 - val_loss: 1.0547 - val_acc: 0.6458\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2551 - acc: 0.9222 - val_loss: 1.1037 - val_acc: 0.6146\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2661 - acc: 0.9046 - val_loss: 1.6680 - val_acc: 0.4792\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2369 - acc: 0.9330 - val_loss: 1.2726 - val_acc: 0.5833\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0911 - acc: 0.9833 - val_loss: 1.0703 - val_acc: 0.6562\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1090 - acc: 0.9599 - val_loss: 1.4575 - val_acc: 0.5938\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0566 - acc: 0.9848 - val_loss: 1.7326 - val_acc: 0.5521\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0799 - acc: 0.9638 - val_loss: 1.3166 - val_acc: 0.6250\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0738 - acc: 0.9765 - val_loss: 1.7176 - val_acc: 0.5521\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0604 - acc: 0.9767 - val_loss: 1.6020 - val_acc: 0.5938\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0441 - acc: 0.9912 - val_loss: 1.4014 - val_acc: 0.5833\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.6794 - val_acc: 0.5833\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 1.5319 - val_acc: 0.6042\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0262 - acc: 0.9915 - val_loss: 1.7994 - val_acc: 0.5312\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 1.8157 - val_acc: 0.5729\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 1.8202 - val_acc: 0.5833\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.8001 - val_acc: 0.5833\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.8243 - val_acc: 0.5833\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.8427 - val_acc: 0.5833\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.8646 - val_acc: 0.5729\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.8834 - val_acc: 0.5938\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.8962 - val_acc: 0.5938\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.9144 - val_acc: 0.5938\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.9306 - val_acc: 0.5938\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.9413 - val_acc: 0.5938\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.9584 - val_acc: 0.5938\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.9676 - val_acc: 0.5938\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.9841 - val_acc: 0.5938\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.9924 - val_acc: 0.5833\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.0083 - val_acc: 0.5833\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.0272 - val_acc: 0.5833\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.0364 - val_acc: 0.5833\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 9.8138e-04 - acc: 1.0000 - val_loss: 2.0447 - val_acc: 0.5833\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.1022e-04 - acc: 1.0000 - val_loss: 2.0601 - val_acc: 0.5833\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 8.8198e-04 - acc: 1.0000 - val_loss: 2.0746 - val_acc: 0.5833\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 8.1887e-04 - acc: 1.0000 - val_loss: 2.0880 - val_acc: 0.5833\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 7.7055e-04 - acc: 1.0000 - val_loss: 2.0967 - val_acc: 0.5833\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 7.3318e-04 - acc: 1.0000 - val_loss: 2.1085 - val_acc: 0.5833\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 7.2828e-04 - acc: 1.0000 - val_loss: 2.1243 - val_acc: 0.5833\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 6.6380e-04 - acc: 1.0000 - val_loss: 2.1313 - val_acc: 0.5833\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 6.8655e-04 - acc: 1.0000 - val_loss: 2.1462 - val_acc: 0.5833\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 6.6175e-04 - acc: 1.0000 - val_loss: 2.1570 - val_acc: 0.5833\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 6.0746e-04 - acc: 1.0000 - val_loss: 2.1646 - val_acc: 0.5833\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 5.9388e-04 - acc: 1.0000 - val_loss: 2.1745 - val_acc: 0.5833\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 5.8014e-04 - acc: 1.0000 - val_loss: 2.1875 - val_acc: 0.5833\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 5.5873e-04 - acc: 1.0000 - val_loss: 2.1948 - val_acc: 0.5833\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 5.4182e-04 - acc: 1.0000 - val_loss: 2.2070 - val_acc: 0.5833\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 5.0798e-04 - acc: 1.0000 - val_loss: 2.2100 - val_acc: 0.5833\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 5.0066e-04 - acc: 1.0000 - val_loss: 2.2246 - val_acc: 0.5833\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 4.8815e-04 - acc: 1.0000 - val_loss: 2.2300 - val_acc: 0.5833\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 4.5466e-04 - acc: 1.0000 - val_loss: 2.2439 - val_acc: 0.5833\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 4.8325e-04 - acc: 1.0000 - val_loss: 2.2482 - val_acc: 0.5833\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 4.2854e-04 - acc: 1.0000 - val_loss: 2.2583 - val_acc: 0.5833\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 4.4314e-04 - acc: 1.0000 - val_loss: 2.2669 - val_acc: 0.5833\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 4.2756e-04 - acc: 1.0000 - val_loss: 2.2737 - val_acc: 0.5938\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.9507e-04 - acc: 1.0000 - val_loss: 2.2843 - val_acc: 0.5938\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.7598e-04 - acc: 1.0000 - val_loss: 2.2911 - val_acc: 0.5938\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.8806e-04 - acc: 1.0000 - val_loss: 2.3027 - val_acc: 0.5938\n",
      "Epoch 62/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 6ms/step - loss: 3.7348e-04 - acc: 1.0000 - val_loss: 2.3074 - val_acc: 0.5938\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.6739e-04 - acc: 1.0000 - val_loss: 2.3159 - val_acc: 0.6042\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.5549e-04 - acc: 1.0000 - val_loss: 2.3209 - val_acc: 0.6042\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.5583e-04 - acc: 1.0000 - val_loss: 2.3298 - val_acc: 0.5938\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.5313e-04 - acc: 1.0000 - val_loss: 2.3394 - val_acc: 0.6042\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.4117e-04 - acc: 1.0000 - val_loss: 2.3474 - val_acc: 0.5938\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.4154e-04 - acc: 1.0000 - val_loss: 2.3548 - val_acc: 0.5938\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.2681e-04 - acc: 1.0000 - val_loss: 2.3629 - val_acc: 0.5938\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.8884e-04 - acc: 1.0000 - val_loss: 2.3702 - val_acc: 0.5938\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.7425e-04 - acc: 1.0000 - val_loss: 2.3770 - val_acc: 0.5938\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.8505e-04 - acc: 1.0000 - val_loss: 2.3840 - val_acc: 0.5938\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.6099e-04 - acc: 1.0000 - val_loss: 2.3896 - val_acc: 0.5938\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 2.7404e-04 - acc: 1.0000 - val_loss: 2.3999 - val_acc: 0.5938\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.7820e-04 - acc: 1.0000 - val_loss: 2.4059 - val_acc: 0.5938\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.5901e-04 - acc: 1.0000 - val_loss: 2.4120 - val_acc: 0.5938\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.5027e-04 - acc: 1.0000 - val_loss: 2.4187 - val_acc: 0.5938\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.4574e-04 - acc: 1.0000 - val_loss: 2.4268 - val_acc: 0.5938\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.2795e-04 - acc: 1.0000 - val_loss: 2.4325 - val_acc: 0.5938\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.2839e-04 - acc: 1.0000 - val_loss: 2.4412 - val_acc: 0.5938\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.1686e-04 - acc: 1.0000 - val_loss: 2.4481 - val_acc: 0.5938\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.2306e-04 - acc: 1.0000 - val_loss: 2.4520 - val_acc: 0.5938\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.1681e-04 - acc: 1.0000 - val_loss: 2.4595 - val_acc: 0.5938\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.1243e-04 - acc: 1.0000 - val_loss: 2.4658 - val_acc: 0.5938\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.1284e-04 - acc: 1.0000 - val_loss: 2.4705 - val_acc: 0.5938\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.0522e-04 - acc: 1.0000 - val_loss: 2.4769 - val_acc: 0.5833\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.0474e-04 - acc: 1.0000 - val_loss: 2.4833 - val_acc: 0.5938\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.9859e-04 - acc: 1.0000 - val_loss: 2.4872 - val_acc: 0.5833\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.9057e-04 - acc: 1.0000 - val_loss: 2.4995 - val_acc: 0.5833\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.8166e-04 - acc: 1.0000 - val_loss: 2.4998 - val_acc: 0.5833\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.8591e-04 - acc: 1.0000 - val_loss: 2.5088 - val_acc: 0.5833\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.7921e-04 - acc: 1.0000 - val_loss: 2.5130 - val_acc: 0.5833\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.7342e-04 - acc: 1.0000 - val_loss: 2.5198 - val_acc: 0.5833\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.6543e-04 - acc: 1.0000 - val_loss: 2.5263 - val_acc: 0.5833\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.6316e-04 - acc: 1.0000 - val_loss: 2.5313 - val_acc: 0.5833\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.7588e-04 - acc: 1.0000 - val_loss: 2.5393 - val_acc: 0.5833\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.6147e-04 - acc: 1.0000 - val_loss: 2.5451 - val_acc: 0.5729\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.5653e-04 - acc: 1.0000 - val_loss: 2.5502 - val_acc: 0.5729\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.5588e-04 - acc: 1.0000 - val_loss: 2.5548 - val_acc: 0.5729\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.4790e-04 - acc: 1.0000 - val_loss: 2.5620 - val_acc: 0.5729\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.5009e-04 - acc: 1.0000 - val_loss: 2.5645 - val_acc: 0.5729\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.4557e-04 - acc: 1.0000 - val_loss: 2.5698 - val_acc: 0.5729\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.4843e-04 - acc: 1.0000 - val_loss: 2.5763 - val_acc: 0.5625\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.3136e-04 - acc: 1.0000 - val_loss: 2.5813 - val_acc: 0.5625\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.3099e-04 - acc: 1.0000 - val_loss: 2.5864 - val_acc: 0.5625\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.3390e-04 - acc: 1.0000 - val_loss: 2.5928 - val_acc: 0.5625\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.2986e-04 - acc: 1.0000 - val_loss: 2.5968 - val_acc: 0.5625\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.3512e-04 - acc: 1.0000 - val_loss: 2.6030 - val_acc: 0.5625\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.2604e-04 - acc: 1.0000 - val_loss: 2.6082 - val_acc: 0.5625\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.3089e-04 - acc: 1.0000 - val_loss: 2.6112 - val_acc: 0.5625\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.2348e-04 - acc: 1.0000 - val_loss: 2.6162 - val_acc: 0.5625\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.1938e-04 - acc: 1.0000 - val_loss: 2.6221 - val_acc: 0.5625\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.2196e-04 - acc: 1.0000 - val_loss: 2.6254 - val_acc: 0.5625\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.1916e-04 - acc: 1.0000 - val_loss: 2.6290 - val_acc: 0.5625\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.2029e-04 - acc: 1.0000 - val_loss: 2.6363 - val_acc: 0.5625\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.1058e-04 - acc: 1.0000 - val_loss: 2.6402 - val_acc: 0.5625\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.0886e-04 - acc: 1.0000 - val_loss: 2.6454 - val_acc: 0.5625\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.0367e-04 - acc: 1.0000 - val_loss: 2.6514 - val_acc: 0.5625\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.0160e-04 - acc: 1.0000 - val_loss: 2.6557 - val_acc: 0.5625\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.0803e-04 - acc: 1.0000 - val_loss: 2.6599 - val_acc: 0.5625\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.0002e-04 - acc: 1.0000 - val_loss: 2.6645 - val_acc: 0.5625\n",
      "Epoch 122/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 6ms/step - loss: 1.0081e-04 - acc: 1.0000 - val_loss: 2.6693 - val_acc: 0.5625\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.7562e-05 - acc: 1.0000 - val_loss: 2.6741 - val_acc: 0.5625\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.5948e-05 - acc: 1.0000 - val_loss: 2.6790 - val_acc: 0.5625\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.3781e-05 - acc: 1.0000 - val_loss: 2.6847 - val_acc: 0.5625\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.4444e-05 - acc: 1.0000 - val_loss: 2.6898 - val_acc: 0.5625\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 9.3683e-05 - acc: 1.0000 - val_loss: 2.6951 - val_acc: 0.5625\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 8.9433e-05 - acc: 1.0000 - val_loss: 2.6989 - val_acc: 0.5625\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 8.8750e-05 - acc: 1.0000 - val_loss: 2.7049 - val_acc: 0.5625\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 8.7555e-05 - acc: 1.0000 - val_loss: 2.7105 - val_acc: 0.5625\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 8.3270e-05 - acc: 1.0000 - val_loss: 2.7132 - val_acc: 0.5625\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 8.3647e-05 - acc: 1.0000 - val_loss: 2.7172 - val_acc: 0.5625\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 8.4782e-05 - acc: 1.0000 - val_loss: 2.7236 - val_acc: 0.5625\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 8.5302e-05 - acc: 1.0000 - val_loss: 2.7282 - val_acc: 0.5625\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 7.8022e-05 - acc: 1.0000 - val_loss: 2.7324 - val_acc: 0.5625\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 7.6942e-05 - acc: 1.0000 - val_loss: 2.7381 - val_acc: 0.5625\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 7.6454e-05 - acc: 1.0000 - val_loss: 2.7416 - val_acc: 0.5625\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 7.4882e-05 - acc: 1.0000 - val_loss: 2.7470 - val_acc: 0.5625\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 7.4777e-05 - acc: 1.0000 - val_loss: 2.7513 - val_acc: 0.5625\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 7.4539e-05 - acc: 1.0000 - val_loss: 2.7556 - val_acc: 0.5625\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 6.8752e-05 - acc: 1.0000 - val_loss: 2.7618 - val_acc: 0.5625\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 7.6205e-05 - acc: 1.0000 - val_loss: 2.7659 - val_acc: 0.5625\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 6.8363e-05 - acc: 1.0000 - val_loss: 2.7706 - val_acc: 0.5625\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 6.8491e-05 - acc: 1.0000 - val_loss: 2.7748 - val_acc: 0.5625\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 6.9954e-05 - acc: 1.0000 - val_loss: 2.7785 - val_acc: 0.5625\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 6.3434e-05 - acc: 1.0000 - val_loss: 2.7837 - val_acc: 0.5625\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 6.5626e-05 - acc: 1.0000 - val_loss: 2.7895 - val_acc: 0.5625\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 6.2661e-05 - acc: 1.0000 - val_loss: 2.7924 - val_acc: 0.5625\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 6.4433e-05 - acc: 1.0000 - val_loss: 2.7968 - val_acc: 0.5625\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 6.1875e-05 - acc: 1.0000 - val_loss: 2.8012 - val_acc: 0.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1e84ac0b50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=ds_train, epochs=EPOCHS,validation_data=ds_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-46a8a2031c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/alireza/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42bf90277c7a4167bd8627748c2ef99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mDataset mnist downloaded and prepared to /home/alireza/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.3562 - sparse_categorical_accuracy: 0.9033 - val_loss: 0.1957 - val_sparse_categorical_accuracy: 0.9428\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1609 - sparse_categorical_accuracy: 0.9544 - val_loss: 0.1361 - val_sparse_categorical_accuracy: 0.9609\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 0s 987us/step - loss: 0.1142 - sparse_categorical_accuracy: 0.9680 - val_loss: 0.1100 - val_sparse_categorical_accuracy: 0.9668\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.0895 - sparse_categorical_accuracy: 0.9745 - val_loss: 0.1009 - val_sparse_categorical_accuracy: 0.9698\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0711 - sparse_categorical_accuracy: 0.9798 - val_loss: 0.0836 - val_sparse_categorical_accuracy: 0.9738\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.0603 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.0793 - val_sparse_categorical_accuracy: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f84080a1d30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128,activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
