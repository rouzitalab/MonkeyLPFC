{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform spike rates to behaviour using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "Configure the local or Google Colab environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6HwqG-TtNfh6",
    "outputId": "b43a9836-bb95-469f-8622-a4666bb29a01"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "vGnyG0prNfiC",
    "outputId": "11ba9f8f-249f-475b-8f13-f6e13e8905a3"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "try:\n",
    "    # Only on works on Google Colab\n",
    "    from google.colab import files\n",
    "    %tensorflow_version 2.x\n",
    "    os.chdir('..')\n",
    "    \n",
    "    # Configure kaggle if necessary\n",
    "    if not (Path.home() / '.kaggle').is_dir():\n",
    "        uploaded = files.upload()  # Find the kaggle.json file in your ~/.kaggle directory.\n",
    "        if 'kaggle.json' in uploaded.keys():\n",
    "            !mkdir -p ~/.kaggle\n",
    "            !mv kaggle.json ~/.kaggle/\n",
    "            !chmod 600 ~/.kaggle/kaggle.json\n",
    "    \n",
    "    !pip install git+https://github.com/SachsLab/indl.git\n",
    "    \n",
    "    if Path.cwd().stem == 'MonkeyPFCSaccadeStudies':\n",
    "        os.chdir(Path.cwd().parent)\n",
    "    \n",
    "    if not (Path.cwd() / 'MonkeyPFCSaccadeStudies').is_dir():\n",
    "        !git clone --single-branch --recursive https://github.com/SachsLab/MonkeyPFCSaccadeStudies.git\n",
    "        sys.path.append(str(Path.cwd() / 'MonkeyPFCSaccadeStudies'))\n",
    "    \n",
    "    os.chdir('MonkeyPFCSaccadeStudies')\n",
    "        \n",
    "    !pip install -q kaggle\n",
    "    \n",
    "    # Latest version of SKLearn\n",
    "    !pip install -U scikit-learn\n",
    "    \n",
    "    IN_COLAB = True\n",
    "    \n",
    "except ModuleNotFoundError:    \n",
    "    # chdir to MonkeyPFCSaccadeStudies\n",
    "    if Path.cwd().stem == 'Analysis':\n",
    "        os.chdir(Path.cwd().parent.parent)\n",
    "        \n",
    "    # Add indl repository to path.\n",
    "    # Eventually this should already be pip installed, but it's still under heavy development so this is easier for now.\n",
    "    check_dir = Path.cwd()\n",
    "    while not (check_dir / 'Tools').is_dir():\n",
    "        check_dir = check_dir / '..'\n",
    "    indl_path = check_dir / 'Tools' / 'Neurophys' / 'indl'\n",
    "    sys.path.append(str(indl_path))\n",
    "    \n",
    "    # Make sure the kaggle executable is on the PATH\n",
    "    os.environ['PATH'] = os.environ['PATH'] + ';' + str(Path(sys.executable).parent / 'Scripts')\n",
    "    \n",
    "    IN_COLAB = False\n",
    "\n",
    "# Try to clear any logs from previous runs\n",
    "if (Path.cwd() / 'logs').is_dir():\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.rmtree(str(Path.cwd() / 'logs'))\n",
    "    except PermissionError:\n",
    "        print(\"Unable to remove logs directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from indl.display import turbo_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 24,\n",
    "    'axes.labelsize': 20,\n",
    "    'lines.linewidth': 2,\n",
    "    'lines.markersize': 5,\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'legend.fontsize': 18,\n",
    "    'figure.figsize': (6.4, 6.4)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "UVWjIh21OIQ0",
    "outputId": "109a9974-aa9f-49d1-acdc-62a9a9c50cde"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    data_path = Path.cwd() / 'data' / 'monkey_pfc' / 'converted'\n",
    "else:\n",
    "    data_path = Path.cwd() / 'StudyLocationRule' / 'Data' / 'Preprocessed'\n",
    "\n",
    "if not (data_path).is_dir():\n",
    "    !kaggle datasets download --unzip --path {str(data_path)} cboulay/macaque-8a-spikes-rates-and-saccades\n",
    "    print(\"Finished downloading and extracting data.\")\n",
    "else:\n",
    "    print(\"Data directory found. Skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Prepare to) Load Data\n",
    "\n",
    "We will use a custom function `load_macaque_pfc` to load the data into memory.\n",
    "\n",
    "There are 4 different strings to be passed to the import `x_chunk` argument:\n",
    "* 'analogsignals' - if present. Returns 1 kHz LFPs\n",
    "* 'gaze'          - Returns 2-channel gaze data.\n",
    "* 'spikerates'    - Returns smoothed spikerates\n",
    "* 'spiketrains'\n",
    "\n",
    "The `y_type` argument can be\n",
    "* 'pair and choice' - returns Y as np.array of (target_pair, choice_within_pair)\n",
    "* 'encoded input' - returns Y as np.array of shape (n_samples, 10) (explained below)\n",
    "* 'replace with column name' - returns Y as a vector of per-trial values. e.g., 'sacClass'\n",
    "\n",
    "The actual data we load depends on the particular analysis below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.misc import sess_infos, load_macaque_pfc, dec_from_enc\n",
    "\n",
    "load_kwargs = {\n",
    "    'valid_outcomes': (0,),  # Use (0, 9) to include trials with incorrect behaviour\n",
    "    'zscore': True,\n",
    "    'dprime_range': (1.0, np.inf),  # Use (-np.inf, np.inf) to include all trials.\n",
    "    'time_range': (-np.inf, 1.45),\n",
    "    'verbose': False,\n",
    "    'y_type': 'sacClass',\n",
    "    'samples_last': True    \n",
    "    #     'resample_X': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding trial class (0:7) from spike rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Load the per-trial spikerates and saccadeClass (0:7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sess_ix = 1\n",
    "sess_info = sess_infos[test_sess_ix]\n",
    "sess_id = sess_info['exp_code']\n",
    "print(f\"\\nImporting session {sess_id}\")\n",
    "X_rates, Y_class, ax_info = load_macaque_pfc(data_path, sess_id, x_chunk='spikerates', **load_kwargs)\n",
    "Y_class = tf.keras.utils.to_categorical(Y_class, num_classes=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model\n",
    "\n",
    "Our model objective is to transform timeseries segments into probabilities of each class.\n",
    "\n",
    "Let's start with a function to make the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indl.model import parts\n",
    "from indl.model.helper import check_inputs\n",
    "from indl.regularizers import KernelLengthRegularizer\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "@check_inputs\n",
    "def make_model(\n",
    "    _input,\n",
    "    filt=8,\n",
    "    kernLength=25,\n",
    "    ds_rate=10,\n",
    "    n_rnn=64,\n",
    "    n_rnn2=64,\n",
    "    dropoutRate=0.25,\n",
    "    activation='relu',\n",
    "    l1_reg=0.000, l2_reg=0.000,\n",
    "    norm_rate=0.25,\n",
    "    latent_dim=16,\n",
    "    return_model=True\n",
    "):\n",
    "    _y = _input\n",
    "    \n",
    "    input_shape = _input.shape.as_list()\n",
    "    # The Conv layers are insensitive to the number of samples in the time dimension.\n",
    "    # To make it possible for this trained model to be applied to segments of different\n",
    "    # durations, we need to explicitly state that we don't care about the number of samples.\n",
    "    # input_shape[2] = -1  # Comment out during debug\n",
    "    # _y = layers.Reshape(input_shape[1:])(_input)  # Note that Reshape ignores the batch dimension.\n",
    "\n",
    "    # RNN\n",
    "    if len(input_shape) < 4:\n",
    "        input_shape = input_shape + [1]\n",
    "    # The Conv layers are insensitive to the number of samples in the time dimension.\n",
    "    # To make it possible for this trained model to be applied to segments of different\n",
    "    # durations, we need to explicitly state that we don't care about the number of samples.\n",
    "    _y = layers.Reshape(input_shape[1:])(_y)\n",
    "    _y = tf.keras.layers.Conv2D(filt, (1, kernLength), padding='valid', data_format=None,\n",
    "                                dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "                                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None,\n",
    "                                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(_y)\n",
    "    _y = tf.keras.layers.BatchNormalization()(_y)\n",
    "    _y = tf.keras.layers.DepthwiseConv2D((_y.shape.as_list()[1], 1), padding='valid',\n",
    "                                      depth_multiplier=1, data_format=None, dilation_rate=(1, 1),\n",
    "                                      activation=None, use_bias=True, depthwise_initializer='glorot_uniform',\n",
    "                                      bias_initializer='zeros', depthwise_regularizer=None,\n",
    "                                      bias_regularizer=None, activity_regularizer=None,\n",
    "                                      depthwise_constraint=None, bias_constraint=None)(_y)\n",
    "    _y = tf.keras.layers.BatchNormalization()(_y)\n",
    "    _y = tf.keras.layers.Activation(activation)(_y)\n",
    "    _y = tf.keras.layers.AveragePooling2D(pool_size=(1, ds_rate))(_y)\n",
    "    _y = tf.keras.layers.Dropout(dropoutRate)(_y)\n",
    "    _y = layers.Reshape(_y.shape.as_list()[2:])(_y)\n",
    "    _y = tf.keras.layers.LSTM(n_rnn,\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
    "                              recurrent_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
    "                              return_sequences=n_rnn2 > 0,\n",
    "                              stateful=False,\n",
    "                              name='rnn1')(_y)\n",
    "    _y = tf.keras.layers.Activation(activation)(_y)\n",
    "    _y = tf.keras.layers.BatchNormalization()(_y)\n",
    "    _y = tf.keras.layers.Dropout(dropoutRate)(_y)\n",
    "    \n",
    "    \n",
    "    if n_rnn2 > 0:\n",
    "        \n",
    "        _y = tf.keras.layers.LSTM(n_rnn2,\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
    "                              recurrent_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
    "                              return_sequences=False,\n",
    "                              stateful=False,\n",
    "                              name='rnn2')(_y)\n",
    "        _y = tf.keras.layers.Activation(activation)(_y)\n",
    "        _y = tf.keras.layers.BatchNormalization()(_y)\n",
    "        _y = tf.keras.layers.Dropout(dropoutRate)(_y)\n",
    "    \n",
    "    # Dense\n",
    "    _y = parts.Bottleneck(_y, latent_dim=latent_dim, activation=activation)\n",
    "    \n",
    "    # Classify\n",
    "    _y = parts.Classify(_y, n_classes=8, norm_rate=norm_rate)\n",
    "    \n",
    "\n",
    "    if return_model is False:\n",
    "        return _y\n",
    "    else:\n",
    "        return tf.keras.models.Model(inputs=_input, outputs=_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_SMOOTHING = 0.2\n",
    "model_kwargs = dict(\n",
    "    filt=8,\n",
    "    kernLength=25,\n",
    "    ds_rate=9,\n",
    "    n_rnn=64,\n",
    "    n_rnn2=64,\n",
    "    dropoutRate=0.40,\n",
    "    activation='relu',\n",
    "    l1_reg=0.0000, l2_reg=0.001,\n",
    "    norm_rate=0.25,\n",
    "    latent_dim=32\n",
    ")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "randseed = 12345\n",
    "random.seed(randseed)\n",
    "np.random.seed(randseed)\n",
    "tf.random.set_seed(randseed)\n",
    "\n",
    "input_spec = tf.data.Dataset.from_tensor_slices(X_rates).batch(16, drop_remainder=True).element_spec\n",
    "model = make_model(\n",
    "    input_spec,\n",
    "    **model_kwargs\n",
    ")\n",
    "optim = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
    "loss_obj = tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING)\n",
    "model.compile(optimizer=optim, loss=loss_obj, metrics=['accuracy'])\n",
    "model.summary()\n",
    "if False:\n",
    "    tf.keras.utils.plot_model(\n",
    "        model,\n",
    "        to_file='model.png',\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        rankdir='TB',\n",
    "        expand_nested=False,\n",
    "        dpi=96\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "cpSTWqR0UoB4",
    "outputId": "638dd00b-8836-4288-b41a-6752b832dae0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "N_SPLITS = 10\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 180\n",
    "\n",
    "\n",
    "def get_hists_acc(sess_id, verbose=1):\n",
    "    print(f\"Processing session {sess_id}...\")\n",
    "    X_rates, Y_class, ax_info = load_macaque_pfc(data_path, sess_id, x_chunk='spikerates', **load_kwargs)\n",
    "    \n",
    "    splitter = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=0)\n",
    "    split_ix = 0\n",
    "    histories = []\n",
    "    per_fold_eval = []\n",
    "    per_fold_true = []\n",
    "\n",
    "    for trn, vld in splitter.split(X_rates, Y_class):\n",
    "        print(f\"\\tSplit {split_ix + 1} of {N_SPLITS}\")\n",
    "        _y = tf.keras.utils.to_categorical(Y_class, num_classes=8)\n",
    "        \n",
    "        ds_train = tf.data.Dataset.from_tensor_slices((X_rates[trn], _y[trn]))\n",
    "        ds_valid = tf.data.Dataset.from_tensor_slices((X_rates[vld], _y[vld]))\n",
    "\n",
    "        # cast data types to GPU-friendly types.\n",
    "        ds_train = ds_train.map(lambda x, y: (tf.cast(x, tf.float32), tf.cast(y, tf.uint8)))\n",
    "        ds_valid = ds_valid.map(lambda x, y: (tf.cast(x, tf.float32), tf.cast(y, tf.uint8)))\n",
    "\n",
    "        # TODO: augmentations (random slicing?)\n",
    "\n",
    "        ds_train = ds_train.shuffle(len(trn) + 1)\n",
    "        ds_train = ds_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "        ds_valid = ds_valid.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        randseed = 12345\n",
    "        random.seed(randseed)\n",
    "        np.random.seed(randseed)\n",
    "        tf.random.set_seed(randseed)\n",
    "        \n",
    "        model = make_model(\n",
    "            ds_train.element_spec[0],\n",
    "            **model_kwargs\n",
    "        )\n",
    "        optim = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
    "        loss_obj = tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING)\n",
    "        model.compile(optimizer=optim, loss=loss_obj, metrics=['accuracy'])\n",
    "        \n",
    "        best_model_path = f'r2c_lstm_{sess_id}_split{split_ix}.h5'\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=best_model_path,\n",
    "                # Path where to save the model\n",
    "                # The two parameters below mean that we will overwrite\n",
    "                # the current checkpoint if and only if\n",
    "                # the `val_loss` score has improved.\n",
    "                save_best_only=True,\n",
    "                monitor='val_accuracy',\n",
    "                verbose=verbose)\n",
    "        ]\n",
    "\n",
    "        hist = model.fit(x=ds_train, epochs=EPOCHS,\n",
    "                         verbose=verbose,\n",
    "                         validation_data=ds_valid,\n",
    "                         callbacks=callbacks)\n",
    "        # tf.keras.models.save_model(model, 'model.h5')\n",
    "        histories.append(hist.history)\n",
    "        \n",
    "        model = tf.keras.models.load_model(best_model_path)\n",
    "        per_fold_eval.append(model(X_rates[vld]).numpy())\n",
    "        per_fold_true.append(Y_class[vld])\n",
    "        \n",
    "        split_ix += 1\n",
    "        \n",
    "    # Combine histories into one dictionary.\n",
    "    history = {}\n",
    "    for h in histories:\n",
    "        for k,v in h.items():\n",
    "            if k not in history:\n",
    "                history[k] = v\n",
    "            else:\n",
    "                history[k].append(np.nan)\n",
    "                history[k].extend(v)\n",
    "                \n",
    "    pred_y = np.concatenate([np.argmax(_, axis=1) for _ in per_fold_eval])\n",
    "    true_y = np.concatenate(per_fold_true).flatten()\n",
    "    accuracy = 100 * np.sum(pred_y == true_y) / len(pred_y)\n",
    "    print(f\"Session {sess_id} overall accuracy: {accuracy}%\")\n",
    "    \n",
    "    return history, accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from indl.metrics import quickplot_history\n",
    "\n",
    "history, accuracy = get_hists_acc(sess_infos[1]['exp_code'], verbose=2)\n",
    "quickplot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation - per session\n",
    "\n",
    "Note that using verbose=0 will suppress most of the log information. Progress indicators might only be updated once every few minutes, depending on the number of epochs and the amount of time it takes to process a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = []\n",
    "accs = []\n",
    "for sess_info in sess_infos:\n",
    "    _hist, _acc = get_hists_acc(sess_info['exp_code'], verbose=0)\n",
    "    hists.append(_hist)\n",
    "    accs.append(_acc)\n",
    "    \n",
    "print(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Best Model (Manual Hyperparameter Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "input_spec = tf.data.Dataset.from_tensor_slices(X_rates).batch(16, drop_remainder=True).element_spec\n",
    "\n",
    "dsrate = 9\n",
    "rnn1s = [32, 64, 128, 256]\n",
    "rnn2s = [32, 64, 128, 256]\n",
    "denses = [0, 8, 16, 32, 64, 128]\n",
    "meanacc = 0\n",
    "best_rnn1 = 0\n",
    "best_rnn2 = 0\n",
    "best_dense = 0\n",
    "best_acc = []\n",
    "best_model = None\n",
    "count=1\n",
    "for rnn1 in rnn1s:\n",
    "    for rnn2 in rnn2s:\n",
    "        for dense in denses:\n",
    "            f = open(\"C:/Users/alire/OneDrive/rnnLog.txt\", \"a\")\n",
    "            f.write(f\"\\n\\nLoop # {count} of {len(rnn1s)*len(rnn2s)*len(denses)}\\n\")\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            f.write(str(current_time))\n",
    "            print(f\"Loop # {count} of 96\")\n",
    "            print(current_time)\n",
    "            count+=1\n",
    "            model_kwargs = dict(\n",
    "                filt=8,\n",
    "                kernLength=25,\n",
    "                ds_rate=9,\n",
    "                n_rnn=rnn1,\n",
    "                n_rnn2=rnn2,\n",
    "                dropoutRate=0.40,\n",
    "                activation='relu',\n",
    "                l1_reg=0.0000, l2_reg=0.001,\n",
    "                norm_rate=0.25,\n",
    "                latent_dim=dense\n",
    "            )\n",
    "            model = make_model(\n",
    "                input_spec,\n",
    "                **model_kwargs\n",
    "            )\n",
    "            hists = []\n",
    "            accs = []\n",
    "            for sess_info in sess_infos:\n",
    "                _hist, _acc = get_hists_acc(sess_info['exp_code'], verbose=0)\n",
    "                hists.append(_hist)\n",
    "                accs.append(_acc)\n",
    "            if np.mean(accs) > meanacc:\n",
    "                meanacc = np.mean(accs)\n",
    "                f.write(f\"\\nAverage Accuracy Improved to: {meanacc}\\n\")\n",
    "                f.write(str(accs))\n",
    "                print(f\"Average Accuracy Improved to: {meanacc}\")\n",
    "                print(accs)\n",
    "                f.write(f\"\\nRNN1: {rnn1}, RNN2: {rnn2}, Bottle: {dense}\")\n",
    "                print(f\"RNN1: {rnn1}, RNN2: {rnn2}, Bottle: {dense}\")\n",
    "                best_rnn1 = rnn1\n",
    "                best_rnn2 = rnn2\n",
    "                best_dense = dense\n",
    "                best_acc = accs\n",
    "                best_model = model\n",
    "                f.close()                    \n",
    "\n",
    "f.close()\n",
    "f.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 6 Models\n",
    "\n",
    "All models have similiar architecture:\n",
    "* Two covoloutional layers to decrease number of channels\n",
    "* A dense layer to downsample timeseries\n",
    "* First RNN (RNN1)\n",
    "* Second RNN (RNN2)\n",
    "* Dense Bottleneck (Botl)\n",
    "* Dense Classifier\n",
    "\n",
    "Model 1: RNN1 = 32(GRU), RNN2 = 32(GRU), Botl = 64\n",
    "\n",
    "Model 2: RNN1 = 32(LSTM), RNN2 = 64(LSTM), Botl = 64\n",
    "\n",
    "Model 3: RNN1 = 32(LSTM), RNN2 = 128(LSTM), Botl = 16\n",
    "\n",
    "Model 4: RNN1 = 32(LSTM), RNN2 = 128(LSTM), Botl = 128\n",
    "\n",
    "Model 5: RNN1 = 32(LSTM), RNN2 = 256(LSTM), Botl = 16\n",
    "\n",
    "Model 6: RNN1 = 64(LSTM), RNN2 = 128(LSTM), Botl = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Model1', 'Model2', 'Model3', 'Model4', 'Model5', 'Model6']\n",
    "data = np.array([[63.75,           73.125,             71.25,               70.,            71.875,             73.75],\n",
    "                [88.42, 88.42105263157895,  86.3157894736842, 86.66666666666667, 87.71929824561404,  88.0701754385965],\n",
    "                [80.71, 75.64575645756457, 77.49077490774907, 76.75276752767527, 77.12177121771218, 79.33579335793358],\n",
    "                [74.,   77.61732851985559, 78.33935018050542, 80.50541516245487, 79.06137184115524, 79.06137184115524],\n",
    "                [67.1875,         70.3125,          66.40625,          66.40625,           70.3125,          64.84375],\n",
    "                [83.33,            71.875, 77.08333333333333,            78.125, 77.08333333333333,            78.125],\n",
    "                [85.93,           79.6875,           85.9375,            84.375,            84.375,            84.375],\n",
    "                [80.,   81.17647058823529, 81.17647058823529,  82.3529411764706, 81.17647058823529,  82.3529411764706]])\n",
    "                     \n",
    "sess_names = [_['exp_code'].split('_')[2] for _ in sess_infos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "plt.axhline(70, color='k', linestyle='--')\n",
    "\n",
    "ax1.boxplot(data, showfliers=False, medianprops=dict(color='k'))\n",
    "ax1.set_xticklabels(labels, fontsize=12)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Model')\n",
    "\n",
    "for row_ix, m in zip(range(data.shape[0]), ['o', '^', '1', 's', '+', 'x', 'd', '*']):\n",
    "    plt.scatter([1, 2, 3, 4, 5, 6], data[row_ix, :], marker=m)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig1.savefig('classif_acc.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "8vpRkztmSA45",
    "JAo8NqmBU-Wz",
    "eMmkVzfcXYNV",
    "8rktdy_9lOWu",
    "Gg5XgclGzzZH",
    "rCNSkqyxeMzj",
    "QVbgVGh5vu-5",
    "E_hTaBFKLd6f",
    "KwUJm-XEYPWi",
    "w692QusPIX-7",
    "HCaIgFsUG6dI"
   ],
   "name": "06_RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
