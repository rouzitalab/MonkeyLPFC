{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import indl\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from indl.fileio import from_neuropype_h5\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from itertools import cycle\n",
    "from filterpy.kalman.UKF import UnscentedKalmanFilter as ukf\n",
    "from filterpy.kalman import MerweScaledSigmaPoints\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "if Path.cwd().stem == 'Analysis':\n",
    "    os.chdir(Path.cwd().parent.parent)\n",
    "\n",
    "from misc.misc import sess_infos, load_macaque_pfc, dec_from_enc    \n",
    "    \n",
    "data_path = Path.cwd() / 'StudyLocationRule'/ 'Data' / 'Preprocessed'\n",
    "if not (data_path).is_dir():\n",
    "    !kaggle datasets download --unzip --path {str(data_path)} cboulay/macaque-8a-spikes-rates-and-saccades\n",
    "    print(\"Finished downloading and extracting data.\")\n",
    "else:\n",
    "    print(\"Data directory found. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b388318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_joeyo_reaching(data_path, sess_id, x_chunk='lfps', zscore=False):\n",
    "    \"\"\"\n",
    "    Load data from the joeyo dataset.\n",
    "    :param data_path: path to joeyo data dir (i.e., parent of 'converted'\n",
    "    :param sess_id: 'indy_2016' + one of '0921_01', '0927_04', '0927_06', '0930_02', '0930_05' '1005_06' '1006_02'\n",
    "    :param x_chunk: 'lfps' (default), 'mu_rates', 'su_rates', 'spiketimes', or 'mu_spiketimes'.\n",
    "    :param zscore: Set to True to z-score data before returning. default: False\n",
    "    :return: X, Y, X_ax_info, Y_ax_info\n",
    "    \"\"\"\n",
    "    file_path = Path(data_path) / 'converted' / (sess_id + '.h5')\n",
    "    chunks = from_neuropype_h5(file_path)\n",
    "    chunk_names = [_[0] for _ in chunks]\n",
    "\n",
    "    Y_chunk = chunks[chunk_names.index('behav')][1]\n",
    "    Y_ax_types = [_['type'] for _ in Y_chunk['axes']]\n",
    "    Y_ax_info = {'channel_names': Y_chunk['axes'][Y_ax_types.index('space')]['names'],\n",
    "                 'timestamps': Y_chunk['axes'][Y_ax_types.index('time')]['times'],\n",
    "                 'fs': Y_chunk['axes'][Y_ax_types.index('time')]['nominal_rate']}\n",
    "\n",
    "    X_chunk = chunks[chunk_names.index(x_chunk)][1]\n",
    "    X_ax_types = [_['type'] for _ in X_chunk['axes']]\n",
    "    X_ax_info = {'channel_names': X_chunk['axes'][X_ax_types.index('space')]['names'],\n",
    "                 'timestamps': X_chunk['axes'][X_ax_types.index('time')]['times'],\n",
    "                 'fs': X_chunk['axes'][X_ax_types.index('time')]['nominal_rate']}\n",
    "\n",
    "    if zscore:\n",
    "        X_chunk['data'] = (X_chunk['data'] - np.mean(X_chunk['data'], axis=1, keepdims=True))\\\n",
    "                          / np.std(X_chunk['data'], axis=1, keepdims=True)\n",
    "        Y_chunk['data'] = (Y_chunk['data'] - np.mean(Y_chunk['data'], axis=1, keepdims=True)) \\\n",
    "                          / np.std(Y_chunk['data'], axis=1, keepdims=True)\n",
    "\n",
    "    return X_chunk['data'], Y_chunk['data'], X_ax_info, Y_ax_info\n",
    "\n",
    "def load_dat_with_vel_accel(datadir, sess_idx):\n",
    "    BEHAV_CHANS = ['CursorX', 'CursorY']\n",
    "    sess_names = ['indy_201' + _ for _ in ['60921_01', '60927_04', '60927_06', '60930_02', '60930_05', '61005_06',\n",
    "                                       '61006_02', '60124_01', '60127_03']]\n",
    "    X, Y, X_ax_info, Y_ax_info = load_joeyo_reaching(datadir, sess_names[sess_idx], x_chunk='mu_spiketimes')\n",
    "\n",
    "    # Slice Y to only keep required behaviour data (cursor position)\n",
    "    b_keep_y_chans = np.in1d(Y_ax_info['channel_names'] , BEHAV_CHANS)\n",
    "    Y = Y[b_keep_y_chans, :]\n",
    "    Y_ax_info['channel_names'] = [_ for _ in Y_ax_info['channel_names'] if _ in BEHAV_CHANS]\n",
    "\n",
    "    # Calculate discrete derivative and double-derivative to get velocity and acceleration.\n",
    "    vel = np.diff(Y, axis=1)\n",
    "    vel = np.concatenate((vel[:, 0][:, None], vel), axis=1)  # Assume velocity was constant across the first two samples.\n",
    "    accel = np.concatenate(([[0], [0]], np.diff(vel, axis=1)), axis=1)  # Assume accel was 0 in the first sample.\n",
    "    Y = np.concatenate((Y, vel, accel), axis=0)\n",
    "    Y_ax_info['channel_names'] += ['VelX', 'VelY', 'AccX', 'AccY']\n",
    "    \n",
    "    return X, Y, X_ax_info, Y_ax_info\n",
    "\n",
    "def bin_spike_times(X, X_ax_info, bin_duration=0.256, bin_step_dur=0.004):\n",
    "    bin_samples = int(np.ceil(bin_duration * X_ax_info['fs']))\n",
    "    bin_starts_t = np.arange(X_ax_info['timestamps'][0], X_ax_info['timestamps'][-1], bin_step_dur)\n",
    "    bin_starts_idx = np.searchsorted(X_ax_info['timestamps'], bin_starts_t)\n",
    "    \n",
    "    # Only keep bins that do not extend beyond the data limit.\n",
    "    b_full_bins = bin_starts_idx <= (X.shape[-1] - bin_samples)\n",
    "    bin_starts_idx = bin_starts_idx[b_full_bins]\n",
    "    bin_starts_t = bin_starts_t[b_full_bins]\n",
    "    \n",
    "    # The next chunk of code counts the number of spikes in each bin.\n",
    "    # Create array of indices to reslice the raster data\n",
    "    bin_ix = np.arange(bin_samples)[:, None] + bin_starts_idx[None, :]\n",
    "    # Create buffer to hold the dense raster data\n",
    "    _temp = np.zeros(X[0].shape, dtype=bool)\n",
    "    # Create output variable to hold spike counts per bin\n",
    "    _X = np.zeros((len(bin_starts_idx), X.shape[0]), dtype=np.int32)\n",
    "    for chan_ix in range(X.shape[0]):\n",
    "        _X[:, chan_ix] = np.sum(X[chan_ix].toarray(out=_temp)[0][bin_ix], axis=0)\n",
    "    _X = _X / bin_duration\n",
    "\n",
    "    return _X.astype(np.float32), bin_starts_t, bin_samples\n",
    "\n",
    "def get_binned_rates_with_history(_X, Y, X_ax_info, bin_starts_t, bin_samples, n_taps=3):\n",
    "    bin_stops_t = bin_starts_t + bin_samples / X_ax_info['fs']\n",
    "    bin_stops_t = bin_stops_t[(N_TAPS-1):]\n",
    "\n",
    "    _X_tapped = np.lib.stride_tricks.as_strided(_X, shape=(len(bin_stops_t), N_TAPS, _X.shape[-1]),\n",
    "                                                strides=(_X.strides[-2], _X.strides[-2], _X.strides[-1]))\n",
    "    \n",
    "    b_keep_y = Y_ax_info['timestamps'] > bin_stops_t[0]\n",
    "    n_extra_y = np.sum(b_keep_y) - len(bin_stops_t)\n",
    "    if n_extra_y > 0:\n",
    "        b_keep_y[-n_extra_y] = False\n",
    "    _Y = Y[:, b_keep_y].T\n",
    "    \n",
    "    _X_tapped = _X_tapped[:_Y.shape[0], :, :]\n",
    "    bin_stops_t = bin_stops_t[:_Y.shape[0]]\n",
    "    \n",
    "    return _X_tapped, _Y.astype(np.float32), bin_stops_t\n",
    "\n",
    "def get_binned_rates(_X, Y, X_ax_info, bin_starts_t, bin_samples, n_taps=1):\n",
    "    bin_stops_t = bin_starts_t + bin_samples / X_ax_info['fs']\n",
    "\n",
    "    _X_tapped = np.lib.stride_tricks.as_strided(_X, shape=(len(bin_stops_t), 1, _X.shape[-1]),\n",
    "                                                strides=(_X.strides[-2], _X.strides[-2], _X.strides[-1]))\n",
    "    \n",
    "    b_keep_y = Y_ax_info['timestamps'] > bin_stops_t[0]\n",
    "    n_extra_y = np.sum(b_keep_y) - len(bin_stops_t)\n",
    "    if n_extra_y > 0:\n",
    "        b_keep_y[-n_extra_y] = False\n",
    "    _Y = Y[:, b_keep_y].T\n",
    "    \n",
    "    _X_tapped = _X_tapped[:_Y.shape[0], :, :]\n",
    "    bin_stops_t = bin_stops_t[:_Y.shape[0]]\n",
    "    \n",
    "    return _X_tapped, _Y.astype(np.float32), bin_stops_t\n",
    "\n",
    "\n",
    "def prepare_for_tensorflow(_X_tapped, _Y, p_train=0.8, batch_size=32, stateful=False):\n",
    "    if stateful:\n",
    "        # If using stateful then we keep the sequences in order.\n",
    "        valid_start = int(np.ceil(_X_tapped.shape[0] * p_train))\n",
    "        X_train = _X_tapped[:valid_start]\n",
    "        Y_train = _Y[:valid_start]\n",
    "        X_valid = _X_tapped[valid_start:]\n",
    "        Y_valid = _Y[valid_start:]\n",
    "    else:\n",
    "        # If not using stateful then we shuffle sequences.\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_valid, Y_train, Y_valid = train_test_split(_X_tapped, _Y, train_size=p_train)\n",
    "\n",
    "    # Get mean and std of training data for z-scoring\n",
    "    _X_mean = np.nanmean(X_train[:, 0, :], axis=0)[None, None, :]\n",
    "    _X_std = np.nanstd(X_train[:, 0, :], axis=0)[None, None, :]\n",
    "    _Y_mean = np.nanmean(Y_train, axis=0, keepdims=True)\n",
    "    _Y_std = np.nanstd(Y_train, axis=0, keepdims=True)\n",
    "\n",
    "    # Z-score both training and testing data. For Y, only center it.\n",
    "    X_train = (X_train - _X_mean) / _X_std\n",
    "    X_valid = (X_valid - _X_mean) / _X_std\n",
    "    Y_train = (Y_train - _Y_mean)  # / _Y_std  # Only standardize Y if top layer demands it.\n",
    "    Y_valid = (Y_valid - _Y_mean)  # / _Y_std  # Only standardize Y if top layer demands it.\n",
    "    \n",
    "    # Also transform all of _X_tapped and _Y for plotting.\n",
    "    _X_tapped = (_X_tapped - _X_mean) / _X_std\n",
    "    _Y = (_Y - _Y_mean)\n",
    "\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    ds_valid = tf.data.Dataset.from_tensor_slices((X_valid, Y_valid))\n",
    "\n",
    "    if not stateful:\n",
    "        ds_train = ds_train.shuffle(int(_X_tapped.shape[0] * P_TRAIN) + 1)\n",
    "    ds_train = ds_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    ds_valid = ds_valid.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    \n",
    "    return _X_tapped, _Y, ds_train, ds_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cadd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualKalmanFilter(object):\n",
    "    def __init__(self, x, z):\n",
    "        self.x = x\n",
    "        self.z = z\n",
    "        self.m = np.size(self.x, 0)\n",
    "        self.n = np.size(self.z, 0)\n",
    "        self.F = np.zeros((self.m, self.m))\n",
    "        self.H = np.zeros((self.n, self.m))\n",
    "        self.Q = np.zeros((self.m, self.m))\n",
    "        self.R = np.zeros((self.n, self.n))\n",
    "        self.xk_bar = np.zeros(self.m)\n",
    "        self.pk_bar = np.zeros((self.m, self.m))\n",
    "        self.P = np.eye(self.m)\n",
    "        self.model_initialize()\n",
    "\n",
    "    def model_initialize(self):\n",
    "        # F = X2.X1^T.(X1.X1^T)^-1\n",
    "        x1 = self.x[:, :-1]\n",
    "        x2 = self.x[:, 1:]\n",
    "        temp1 = np.dot(x2, x1.T)\n",
    "        temp2 = np.linalg.inv(np.dot(x1, x1.T))\n",
    "        self.F = np.dot(temp1, temp2)\n",
    "        # Q = ((X2 - F.X1).(X2 - FX1)^T) / (M-1)\n",
    "        temp = x2 - np.dot(self.F, x1)\n",
    "        self.Q = np.dot(temp, temp.T) / (self.m - 1)\n",
    "        # H = Z.X^T.(X.X^T)^-1\n",
    "        temp1 = np.dot(self.z, self.x.T)\n",
    "        temp2 = np.linalg.inv(np.dot(self.x, self.x.T))\n",
    "        self.H = np.dot(temp1, temp2)\n",
    "        # R = ((Z - H.X).(Z - H.X)^T) / M\n",
    "        Z_HX = self.z - np.dot(self.H, self.x)\n",
    "        temp = np.dot(Z_HX, Z_HX.T)\n",
    "        self.R = np.divide(temp, self.m)\n",
    "\n",
    "    def predict(self):\n",
    "        # I. Priori Step\n",
    "        x_k_minus_one = self.x[:, -1]  # Initial State\n",
    "        p_k_minus_one = self.P  # Initial Error Covariance\n",
    "        self.xk_bar = np.dot(self.F, x_k_minus_one)\n",
    "        temp = np.dot(self.F, p_k_minus_one)\n",
    "        self.pk_bar = np.dot(temp, np.transpose(self.F)) + self.Q\n",
    "\n",
    "    def update(self, z_test):\n",
    "        # Kk = Pk^-.H^T.(H.Pk^-.H^T + R)^-1\n",
    "        temp = np.dot(self.pk_bar, np.transpose(self.H))\n",
    "        temp1 = np.dot(self.H, temp) + self.R\n",
    "        temp2 = np.linalg.inv(temp1)\n",
    "        kk = np.dot(temp, temp2)\n",
    "        # Next State Estimation\n",
    "        zk = z_test\n",
    "        temp1 = zk - np.dot(self.H, self.xk_bar)  # z - dot(H, x)\n",
    "        temp2 = np.dot(kk, temp1)\n",
    "        xk = self.xk_bar + temp2  # x = x + dot(K, y)\n",
    "        # Next Error Covariance Estimation\n",
    "        temp = np.eye(self.m) - np.dot(kk, self.H)  # I_KH = self._I - dot(self.K, H)\n",
    "        pk = np.dot(temp, self.pk_bar)  # self.P = dot(dot(I_KH, self.P), I_KH.T) + dot(dot(self.K, R), self.K.T)\n",
    "        # Initializing Next Loop\n",
    "        xk = np.reshape(xk, (self.m, 1))\n",
    "        self.x = np.hstack((self.x, xk))\n",
    "        self.P = pk\n",
    "        # Updating the model\n",
    "        zk = np.reshape(zk, (self.n, 1))\n",
    "        self.z = np.hstack((self.z, zk))\n",
    "        return xk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e76a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SESS_IDX = 0          # Index of recording session we will use. 0:8\n",
    "BIN_DURATION = 0.250  # Width of window used to bin spikes, in seconds\n",
    "N_TAPS = 2            # Number of bins of history used in a sequence.\n",
    "P_TRAIN = 0.8         # Proportion of data used for training.\n",
    "BATCH_SIZE = 32       # Number of sequences in each training step.\n",
    "P_DROPOUT = 0.05      # Proportion of units to set to 0 on each step.\n",
    "N_RNN_UNITS = 64      # Size of RNN output (state)\n",
    "L2_REG = 0.000017       # Parameter regularization strength.\n",
    "STATEFUL = False      # Whether or not to keep state between sequences (True is not tested)\n",
    "EPOCHS = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ade44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_ax_info, Y_ax_info = load_dat_with_vel_accel(data_path, SESS_IDX)\n",
    "_X, bin_starts_t, bin_samples = bin_spike_times(X, X_ax_info, bin_duration=BIN_DURATION, bin_step_dur=(1 / Y_ax_info['fs']))\n",
    "_X_tapped, _Y, bin_stops_t = get_binned_rates_with_history(_X, Y, X_ax_info, bin_starts_t, bin_samples, n_taps=N_TAPS)\n",
    "print(_X.shape,_X_tapped.shape, _Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b83e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "x = _Y[step,0]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "while step < 1000:\n",
    "    plt.plot(step, _Y[step, 0], '.-', color='green', label=\"True\")\n",
    "    x = x + _Y[step-1,2]\n",
    "    plt.plot(step, x, '.-', color='red', label=\"Reversed\")\n",
    "#     plt.legend()\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    step = step + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3cbfe3",
   "metadata": {},
   "source": [
    "# Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d843329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nengo\n",
    "from nengo.utils.ensemble import sorted_neurons\n",
    "from nengo.utils.matplotlib import rasterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v= _Y[:, 2:4]\n",
    "def xvelocity(t):\n",
    "    return v[int(1000*t),0]\n",
    "def yvelocity(t):\n",
    "    return v[int(1000*t),1]\n",
    "\n",
    "model = nengo.Network(label=\"Velocity Encoder\")\n",
    "with model:\n",
    "    # Our ensemble consists of N leaky integrate-and-fire neurons,\n",
    "    # and represents a 2-dimensional signal\n",
    "    neurons = nengo.Ensemble(100, dimensions=2)\n",
    "\n",
    "with model:\n",
    "    # Create input nodes representing the sine and cosine\n",
    "    xvel = nengo.Node(output=xvelocity)\n",
    "    yvel = nengo.Node(output=yvelocity)\n",
    "    \n",
    "with model:\n",
    "    # The indices in neurons define which dimension the input will project to\n",
    "    nengo.Connection(xvel, neurons[0])\n",
    "    nengo.Connection(yvel, neurons[1])\n",
    "    \n",
    "with model:\n",
    "    xvel_probe = nengo.Probe(xvel, \"output\")\n",
    "    yvel_probe = nengo.Probe(yvel, \"output\")\n",
    "    output_probe = nengo.Probe(neurons, \"decoded_output\", synapse=0.01)\n",
    "    neurons_probe = nengo.Probe(neurons.neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    # Run it for 1 second\n",
    "    sim.run(89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb22976",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.data[neurons_probe].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43f4473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decoded output of the ensemble\n",
    "plt.figure()\n",
    "plt.plot(sim.trange(), sim.data[xvel_probe], \"g\", label=\"X Velocity\")\n",
    "plt.plot(sim.trange(), sim.data[output_probe][:,0], \"r\", label=\"Decoded X Velocity\")\n",
    "plt.xlim(10, 16)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sim.trange(), sim.data[yvel_probe], \"g\", label=\"Y Velocity\")\n",
    "plt.plot(sim.trange(), sim.data[output_probe][:,1], \"r\", label=\"Decoded Y Velocity\")\n",
    "plt.xlim(10, 16)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "# Plot the spiking output of the ensemble\n",
    "plt.figure()\n",
    "rasterplot(sim.trange(), sim.data[neurons_probe])\n",
    "plt.xlim(10, 11.5)\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f075848",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_spikes = sim.data[neurons_probe]/np.max(sim.data[neurons_probe])\n",
    "states = _Y[:sim_spikes.shape[0],:]\n",
    "print(sim_spikes.shape, states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(sim_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ddeda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = 250\n",
    "sim_rates = np.zeros((sim_spikes.shape[0], sim_spikes.shape[1]))\n",
    "for t in range(sim_spikes.shape[0]):\n",
    "    if t < bin_size:\n",
    "        sim_rates[t,:] = np.sum(sim_spikes[:t], axis=0)\n",
    "    else:\n",
    "        sim_rates[t,:] = np.sum(sim_spikes[t-bin_size:t], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b060fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim_rates[:5000, 0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad19351",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural = np.squeeze(sim_rates).T\n",
    "state = states[:, :4].T\n",
    "\n",
    "# Seperating training and test samples\n",
    "training_size = 10000\n",
    "\n",
    "state_train = state[:, :training_size]\n",
    "neural_train = neural[:, :training_size]\n",
    "state_test = state[:, training_size:]\n",
    "neural_test = neural[:, training_size:]\n",
    "\n",
    "# Initialize predicted states\n",
    "kf_predict = np.zeros((4, 6000))\n",
    "\n",
    "# Instantiating from KF class\n",
    "mykf = ManualKalmanFilter(x=state_train, z = neural_train)\n",
    "\n",
    "# Looping through test data\n",
    "rng = 6000\n",
    "for i in range(rng):\n",
    "    mykf.predict()\n",
    "    neural_in = neural_test[:,i]\n",
    "    kf_predict[:, i] = np.reshape(mykf.update(neural_in), (mykf.m, ))\n",
    "    if i%200 == 0:\n",
    "        print('KF - Step: ' + str(i) + ' out of ' + str(rng))\n",
    "print('KF Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c937da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(kf_predict[0,:], color='r', label=\"Kalman Filter\")\n",
    "plt.plot(state[0,training_size:training_size+rng], label=\"True\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"X Position\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(kf_predict[1,:], color='r', label=\"Kalman Filter\")\n",
    "plt.plot(state[1,training_size:training_size+rng], label=\"True\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Y Position\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(kf_predict[2,:], color='r', label=\"Kalman Filter\")\n",
    "plt.plot(state[2,training_size:training_size+rng], label=\"True\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"X Velocity\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(kf_predict[3,:], color='r', label=\"Kalman Filter\")\n",
    "plt.plot(state[3,training_size:training_size+rng], label=\"True\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Y Velocity\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b05071",
   "metadata": {},
   "source": [
    "# Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nengo\n",
    "from nengo.utils.ensemble import sorted_neurons\n",
    "from nengo.utils.matplotlib import rasterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74189347",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_RANGE = [10, 50] # The frequncy of neuron's firing\n",
    "N_NEURON = 100 # Number of channels/neurons\n",
    "STATE_DIM = 2 # Kinematic input dimension i.e. position + velocity + acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v= _Y[:51, 2:4]\n",
    "def xvelocity(t):\n",
    "    return v[int(1000*t),0]\n",
    "def yvelocity(t):\n",
    "    return v[int(1000*t),1]\n",
    "\n",
    "model = nengo.Network(label=\"Motor\")\n",
    "with model:\n",
    "    # Our ensemble consists of N leaky integrate-and-fire neurons,\n",
    "    # and represents a 2-dimensional signal\n",
    "    neurons = nengo.Ensemble(n_neurons=N_NEURON, dimensions=STATE_DIM,\n",
    "#                              max_rates=np.random.uniform(FREQ_RANGE[0], FREQ_RANGE[1]),\n",
    "                             neuron_type=nengo.AdaptiveLIF())\n",
    "\n",
    "with model:\n",
    "    # Create input nodes representing the sine and cosine\n",
    "    xvel = nengo.Node(output=xvelocity)\n",
    "    yvel = nengo.Node(output=yvelocity)\n",
    "    \n",
    "with model:\n",
    "    # The indices in neurons define which dimension the input will project to\n",
    "    nengo.Connection(xvel, neurons[0])\n",
    "    nengo.Connection(yvel, neurons[1])\n",
    "    \n",
    "with model:\n",
    "    xvel_probe = nengo.Probe(xvel, \"output\")\n",
    "    yvel_probe = nengo.Probe(yvel, \"output\")\n",
    "    output_probe = nengo.Probe(neurons, \"decoded_output\", synapse=0.01)\n",
    "    neurons_probe = nengo.Probe(neurons.neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# import matplotlib.pylab as pl\n",
    "from IPython import display\n",
    "t = 0\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "\n",
    "\n",
    "while t < 100:\n",
    "    ax1.plot(_Y[t:t+50,0], _Y[t:t+50,1],'.-', color='blue')\n",
    "    ax2.plot(np.arange(t,t+50),_X[t:t+50,:], '|')\n",
    "    ax3.plot(_Y[t:t+50,2], _Y[t:t+50,3],'.-', color='blue')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    t = t+1\n",
    "    ax2.set_xlim([t-50, t+50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e2b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.data[output_probe].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(_Y[:50,0], _Y[:50,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dec_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32636e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pylab as pl\n",
    "\n",
    "\n",
    "# plot_kwargs = {\n",
    "#     'colors': [\"k\"]\n",
    "# }\n",
    "BUF_SIZE = 50\n",
    "dec_pos = np.zeros((_Y.shape[0],2))\n",
    "dec_pos[0] = _Y[0,:2]\n",
    "t_step = 0\n",
    "f, axs = plt.subplots(4,1,figsize=(15,15))\n",
    "# ax1 = plt.subplot(2, 1, 1)\n",
    "# ax2 = plt.subplot(2, 1, 2)\n",
    "while t_step < 5000:\n",
    "    with nengo.Simulator(model) as sim:\n",
    "        sim.run(BUF_SIZE/1000, progress_bar=False)\n",
    "#     xpos = sim.data[xvel_probe] + np.ones(BUF_SIZE)*x0\n",
    "#     ypos = sim.data[yvel_probe] + np.ones(BUF_SIZE)*y0\n",
    "#     x0 = xpos[-1]\n",
    "#     y0 = ypos[-1]\n",
    "    for i in range(t_step+1,t_step+BUF_SIZE+1):\n",
    "        dec_pos[i,0] = dec_pos[i-1,0] + sim.data[output_probe][i-t_step-1,0]\n",
    "        dec_pos[i,1] = dec_pos[i-1,1] + sim.data[output_probe][i-t_step-1,1]\n",
    "    axs[0].plot(_Y[t_step:t_step+BUF_SIZE,0],_Y[t_step:t_step+BUF_SIZE,1], '.-', color=\"g\", label = \"Cursor\")\n",
    "    axs[0].plot(dec_pos[t_step:t_step+BUF_SIZE,0], dec_pos[t_step:t_step+BUF_SIZE,1], '.-', color=\"r\", label=\"Decoded\")\n",
    "    axs[0].set_xlabel(\"Pos X\")\n",
    "    axs[0].set_ylabel(\"Pos Y\")\n",
    "    axs[1].plot(np.arange(t_step, t_step+BUF_SIZE),_Y[t_step:t_step+BUF_SIZE,0], '.-', color=\"g\", label = \"Cursor\")\n",
    "    axs[1].plot(np.arange(t_step, t_step+BUF_SIZE), dec_pos[t_step:t_step+BUF_SIZE,0], '.-', color=\"r\", label=\"Decoded\")\n",
    "    axs[1].set_xlabel(\"Time (ms)\")\n",
    "    axs[1].set_ylabel(\"Pos X\")\n",
    "    axs[1].set_xlim([t_step-20*BUF_SIZE, t_step+100])\n",
    "    axs[2].plot(np.arange(t_step, t_step+BUF_SIZE),_Y[t_step:t_step+BUF_SIZE,1], '.-', color=\"g\", label = \"Cursor\")\n",
    "    axs[2].plot(np.arange(t_step, t_step+BUF_SIZE), dec_pos[t_step:t_step+BUF_SIZE,1], '.-', color=\"r\", label=\"Decoded\")\n",
    "    axs[2].set_xlabel(\"Time (ms)\")\n",
    "    axs[2].set_ylabel(\"Pos X\")\n",
    "    axs[2].set_xlim([t_step-20*BUF_SIZE, t_step+100])\n",
    "#     axs[0].plot(np.arange(t_step, t_step+BUF_SIZE),sim.data[xvel_probe], \"g\", label = \"Cursor\")\n",
    "#     axs[0].plot(np.arange(t_step, t_step+BUF_SIZE),sim.data[output_probe][:,0], \"r\", label=\"Decoded\")\n",
    "    rasterplot(np.arange(t_step, t_step+BUF_SIZE), sim.data[neurons_probe], ax=axs[3])\n",
    "    axs[3].set_xlabel(\"Time (ms)\")\n",
    "    axs[3].set_ylabel(\"Channel\")\n",
    "    axs[3].set_xlim([t_step-20*BUF_SIZE, t_step+10])\n",
    "    if t_step==0:\n",
    "        axs[0].legend()\n",
    "        axs[1].legend()\n",
    "        axs[2].legend()\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    t_step = t_step+BUF_SIZE\n",
    "#     wait(98)\n",
    "    v= _Y[t_step:t_step+BUF_SIZE+1, 2:4]\n",
    "# with nengo.Simulator(model) as sim:\n",
    "#     # Run it for 1 second\n",
    "#     sim.run(1, progress_bar=False)\n",
    "# # Plot the decoded output of the ensemble\n",
    "# plt.figure()\n",
    "# plt.plot(sim.trange(), sim.data[xvel_probe], \"g\", label=\"X Velocity\")\n",
    "# plt.plot(sim.trange(), sim.data[output_probe][:,0], \"r\", label=\"Decoded X Velocity\")\n",
    "# plt.xlim(0, 1)\n",
    "# plt.legend()\n",
    "# plt.xlabel(\"Time (ms)\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(sim.trange(), sim.data[yvel_probe], \"g\", label=\"Y Velocity\")\n",
    "# plt.plot(sim.trange(), sim.data[output_probe][:,1], \"r\", label=\"Decoded Y Velocity\")\n",
    "# plt.xlim(0, 1)\n",
    "# plt.legend()\n",
    "# plt.xlabel(\"Time (ms)\")\n",
    "# # Plot the spiking output of the ensemble\n",
    "# plt.figure()\n",
    "# rasterplot(sim.trange(), sim.data[neurons_probe])\n",
    "# plt.xlim(0, 1)\n",
    "# plt.xlabel(\"Time (ms)\")\n",
    "# plt.ylabel(\"Channel\")\n",
    "\n",
    "\n",
    "# v= _Y[1000:2001, 2:4]\n",
    "# with nengo.Simulator(model) as sim:\n",
    "#     # Run it for 1 second\n",
    "#     sim.run(1, progress_bar=False)\n",
    "# # Plot the decoded output of the ensemble\n",
    "# plt.figure()\n",
    "# plt.plot(sim.trange(), sim.data[xvel_probe], \"g\", label=\"X Velocity\")\n",
    "# plt.plot(sim.trange(), sim.data[output_probe][:,0], \"r\", label=\"Decoded X Velocity\")\n",
    "# plt.xlim(0, 1)\n",
    "# plt.legend()\n",
    "# plt.xlabel(\"Time (ms)\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(sim.trange(), sim.data[yvel_probe], \"g\", label=\"Y Velocity\")\n",
    "# plt.plot(sim.trange(), sim.data[output_probe][:,1], \"r\", label=\"Decoded Y Velocity\")\n",
    "# plt.xlim(0, 1)\n",
    "# plt.legend()\n",
    "# plt.xlabel(\"Time (ms)\")\n",
    "# # Plot the spiking output of the ensemble\n",
    "# plt.figure()\n",
    "# rasterplot(sim.trange(), sim.data[neurons_probe])\n",
    "# plt.xlim(0, 1)\n",
    "# plt.xlabel(\"Time (ms)\")\n",
    "# plt.ylabel(\"Channel\")\n",
    "f.save('animation.gif', writer='imagemagick', fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a4f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    # Run it for 1 second\n",
    "    sim.run(89)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b2ae4c",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b72608",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nengo\n",
    "from nengo.utils.ensemble import sorted_neurons\n",
    "from nengo.utils.matplotlib import rasterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23338268",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # number of neurons\n",
    "dn = 10 # window of simulation in ms\n",
    "dw = dn / 1000 - 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdfba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "v= _Y[0:0+dn, 2:4]\n",
    "def xvelocity(t):\n",
    "    return v[int(1000*t),0]\n",
    "def yvelocity(t):\n",
    "    return v[int(1000*t),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d4ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nengo.Network(label=\"Velocity Encoder\")\n",
    "with model:\n",
    "    # Our ensemble consists of N leaky integrate-and-fire neurons,\n",
    "    # and represents a 2-dimensional signal\n",
    "    neurons = nengo.Ensemble(N, dimensions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    # Create input nodes representing the sine and cosine\n",
    "    xvel = nengo.Node(output=xvelocity)\n",
    "    yvel = nengo.Node(output=yvelocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb2d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    # The indices in neurons define which dimension the input will project to\n",
    "    nengo.Connection(xvel, neurons[0])\n",
    "    nengo.Connection(yvel, neurons[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    xvel_probe = nengo.Probe(xvel, \"output\")\n",
    "    yvel_probe = nengo.Probe(yvel, \"output\")\n",
    "    neurons_probe = nengo.Probe(neurons, \"decoded_output\", synapse=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea1caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    # Run it for 1 second\n",
    "    sim.run(dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9da75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pl\n",
    "from IPython import display\n",
    "\n",
    "n = 0\n",
    "tdisp = 0\n",
    "while n < 10000:\n",
    "    v = _Y[n:n+dn, 2:4]\n",
    "    with nengo.Simulator(model) as sim:\n",
    "        sim.run(dw)\n",
    "    pl.plot(sim.trange(), sim.data[xvel_probe], label=\"A output\")\n",
    "    pl.plot(sim.trange(), sim.data[sin_probe], \"r\", label=\"Input\")\n",
    "    pl.xlim(tdisp, tdisp+1)\n",
    "    pl.legend()\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())\n",
    "    n = n+1\n",
    "    plt.figure()\n",
    "    rasterplot(sim.trange(), sim.data[A_spikes])\n",
    "    plt.xlim(0, 1)\n",
    "    if n % 1000 == 0:\n",
    "        tdisp = tdisp + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba920a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decoded output of the ensemble\n",
    "plt.figure()\n",
    "plt.plot(sim.trange(), sim.data[A_probe], label=\"A output\")\n",
    "plt.plot(sim.trange(), sim.data[sin_probe], \"r\", label=\"Input\")\n",
    "plt.xlim(0, 1)\n",
    "plt.legend()\n",
    "\n",
    "# Plot the spiking output of the ensemble\n",
    "plt.figure()\n",
    "rasterplot(sim.trange(), sim.data[A_spikes])\n",
    "plt.xlim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d76053",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.data[A_spikes].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3de789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interest's sake, you can also sort by encoder\n",
    "indices = sorted_neurons(A, sim, iterations=250)\n",
    "plt.figure()\n",
    "rasterplot(sim.trange(), sim.data[A_spikes][:, indices])\n",
    "plt.xlim(0, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
