{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/XX_XX_CNN_macaque_pfc.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/XX_XX_CNN_macaque_pfc.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lnt_1_ellnIY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# A Generalizable CNN to Decode Intended Saccade Direction from Macaque PFC Microelectrode Recordings\n",
    "\n",
    "Please see the 04_ notebook to understand the CNN model used to decode intended saccade direction from spike trains.\n",
    "\n",
    "In this notebook, we will use the same model architecture, but during training we will feed it data from multiple sessions, comprising both monkeys and 3 different 32-channel banks of electrodes for each monkey. In our architecture, the DepthwiseConv2D layer is a spatial filter that is expected to be unique to each bank of electrodes, thus we will train 6 different models that share all layers except for the spatial filter layer unique to each model.\n",
    "\n",
    "https://www.tensorflow.org/beta/guide/keras/functional#sharing_layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Environments\n",
    "Run the first two cells to normalize Local / Colab environments, then proceed below for the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "yGrxqTomlnIc",
    "outputId": "d3d9dbae-4e45-4120-8a1f-cc7214c6f9e7",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "try:\n",
    "    # See if we are running on google.colab\n",
    "    import google.colab\n",
    "    from google.colab import files\n",
    "    os.chdir('..')\n",
    "    if not (Path.home() / '.kaggle').is_dir():\n",
    "        # Configure kaggle\n",
    "        files.upload()  # Find the kaggle.json file in your ~/.kaggle directory.\n",
    "        !pip install -q kaggle\n",
    "        !mkdir -p ~/.kaggle\n",
    "        !mv kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "    # TODO: Clone IntracranialNeurophysDL repository and add to path\n",
    "    # TODO: Clone MonkeyPFC repository and cd there\n",
    "    if Path.cwd().stem != 'IntracranialNeurophysDL':\n",
    "        if not (Path.cwd() / 'IntracranialNeurophysDL').is_dir():\n",
    "            # Download the workshop repo and change to its directory\n",
    "            !git clone --single-branch --branch cboulay/macaque_pfc --recursive https://github.com/SachsLab/IntracranialNeurophysDL.git\n",
    "        os.chdir('IntracranialNeurophysDL')\n",
    "    IN_COLAB = True\n",
    "    # Setup tensorflow 2.0\n",
    "    !pip install -q tensorflow-gpu==2.0.0-rc0\n",
    "except ModuleNotFoundError:\n",
    "    IN_COLAB = False\n",
    "    import sys\n",
    "    # chdir to MonkeyPFCSaccadeStudies\n",
    "    if Path.cwd().stem == 'Analysis':\n",
    "        os.chdir(Path.cwd().parent.parent)\n",
    "    # Add IntracranialNeurophysDL repository to path.\n",
    "    check_dir = Path.cwd()\n",
    "    while not (check_dir / 'Tools').is_dir():\n",
    "        check_dir = check_dir / '..'\n",
    "    indl_path = check_dir / 'Tools' / 'Neurophys' / 'IntracranialNeurophysDL'\n",
    "    sys.path.append(str(indl_path))\n",
    "    # Make sure the kaggle executable is on the PATH\n",
    "    os.environ['PATH'] = os.environ['PATH'] + ';' + str(Path(sys.executable).parent / 'Scripts')\n",
    "\n",
    "# Try to clear any logs from previous runs\n",
    "if (Path.cwd() / 'logs').is_dir():\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.rmtree(str(Path.cwd() / 'logs'))\n",
    "    except PermissionError:\n",
    "        print(\"Unable to remove logs directory.\")\n",
    "\n",
    "# Additional imports\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from indl import enable_plotly_in_cell, reset_keras, turbo_cmap\n",
    "%load_ext tensorboard\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n",
    "We are going to use data from multiple sessions, defined in the `sess_infos` list.\n",
    "Each name * electrode bank will get its own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sess_infos = [\n",
    "    {'name': 'JerryLee', 'bank': 'A', 'name_short': 'j', 'date': '090601', 'exp_code': 'sra3_2_j_037_00+03', 'nsx': 'datafile003.ns2'},\n",
    "    {'name': 'JerryLee', 'bank': 'C', 'name_short': 'j', 'date': '090622', 'exp_code': 'sra3_2_j_049_00+02', 'nsx': 'datafile002.ns2'},\n",
    "    {'name': 'JerryLee', 'bank': 'A', 'name_short': 'j', 'date': '090623', 'exp_code': 'sra3_1_j_050_00+', 'nsx': 'datafile002.ns2'},\n",
    "    {'name': 'JerryLee', 'bank': 'B', 'name_short': 'j', 'date': '090624', 'exp_code': 'sra3_1_j_051_00+', 'nsx': 'datafile002.ns2'},\n",
    "    {'name': 'JerryLee', 'bank': 'C', 'name_short': 'j', 'date': '090625', 'exp_code': 'sra3_1_j_052_00+', 'nsx': 'datafile003.ns2'},\n",
    "    {'name': 'Marty', 'bank': 'A', 'name_short': 'm', 'date': '090908', 'exp_code': 'sra3_1_m_070_00+02', 'nsx': 'datafile001.ns2'},\n",
    "    {'name': 'Marty', 'bank': 'A', 'name_short': 'm', 'date': '090914', 'exp_code': 'sra3_1_m_074_00+01', 'nsx': 'datafile001.ns2'},\n",
    "    {'name': 'Marty', 'bank': 'B', 'name_short': 'm', 'date': '090918', 'exp_code': 'sra3_1_m_076_00+01', 'nsx': 'datafile001.ns2'},\n",
    "#     {'name': 'Marty', 'bank': 'C', 'name_short': 'm', 'date': '090919', 'exp_code': 'sra3_1_m_077_00+01', 'nsx': 'datafile001.ns2'},\n",
    "#     {'name': 'Marty', 'bank': 'B', 'name_short': 'm', 'date': '090920', 'exp_code': 'sra3_1_m_078_00+01', 'nsx': 'datafile001.ns2'},\n",
    "    {'name': 'Marty', 'bank': 'C', 'name_short': 'm', 'date': '090921', 'exp_code': 'sra3_1_m_079_00+01', 'nsx': 'datafile001.ns2'},\n",
    "    {'name': 'Marty', 'bank': 'A', 'name_short': 'm', 'date': '090922', 'exp_code': 'sra3_1_m_080_00+01', 'nsx': 'datafile001.ns2'},\n",
    "#     {'name': 'Marty', 'bank': 'B', 'name_short': 'm', 'date': '090925', 'exp_code': 'sra3_1_m_081_00+01', 'nsx': 'datafile001.ns2'},\n",
    "    {'name': 'Marty', 'bank': 'A', 'name_short': 'm', 'date': '090926', 'exp_code': 'sra3_1_m_082_00+01', 'nsx': 'datafile001.ns2'},\n",
    "#     {'name': 'Marty', 'bank': 'C', 'name_short': 'm', 'date': '090927', 'exp_code': 'sra3_1_m_083_00+01', 'nsx': 'datafile001.ns2'},\n",
    "    {'name': 'Marty', 'bank': 'A', 'name_short': 'm', 'date': '090928', 'exp_code': 'sra3_1_m_084_00+01', 'nsx': 'datafile001.ns2'},\n",
    "#     {'name': 'Marty', 'bank': 'B', 'name_short': 'm', 'date': '090929', 'exp_code': 'sra3_1_m_085_00+01', 'nsx': 'datafile001.ns2'}\n",
    "]\n",
    "\n",
    "# Create a pandas dataframe with this information.\n",
    "col_names = ('name', 'bank', 'exp_code')\n",
    "data = [[row[col_name] for col_name in col_names] for row in sess_infos]\n",
    "sess_df = pd.DataFrame(data=data, columns=col_names)\n",
    "\n",
    "# Identify the unique combinations of monkey name and electrode bank.\n",
    "sess_cfgs = sess_df.loc[:, ['name', 'bank']].drop_duplicates()\n",
    "print(sess_cfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "ltlcRrJLlnIh",
    "outputId": "5fe6b6e3-f806-4c5c-88ff-cda10dc31fb3",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download and unzip data\n",
    "if IN_COLAB:\n",
    "    datadir = Path.cwd() / 'data' / 'monkey_pfc' / 'converted'\n",
    "else:\n",
    "    datadir = Path.cwd() / 'StudyLocationRule' / 'Data' / 'Preprocessed'\n",
    "\n",
    "if not (datadir).is_dir():\n",
    "    !kaggle datasets download --unzip --path {str(datadir)} cboulay/macaque-8a-spikes-rates-and-saccades\n",
    "    print(\"Finished downloading and extracting data.\")\n",
    "else:\n",
    "    print(\"Data directory found. Skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J5SQdqZhlnIj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data loading and splitting\n",
    "\n",
    "For each session, we are going to use 90% of the data for training and 10% of the data for validation. We will keep the same training/validation split for each epoch, so we will go through the data and get the train/valid indices now. This requires loading each dataset temporarily to pass it into the splitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import load_macaque_pfc\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "P_TRAIN = 0.8\n",
    "\n",
    "n_timestamps = None\n",
    "n_channels = None\n",
    "\n",
    "train_valid_inds = []\n",
    "for idx, row in sess_df.iterrows():\n",
    "    sess_id = row['exp_code'].replace('+', '')\n",
    "    X, Y, ax_info = load_macaque_pfc(datadir, sess_id, x_chunk='spiketrains', zscore=False)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=1 - P_TRAIN, random_state=0)\n",
    "    train_valid_inds.append(next(sss.split(X, Y)))\n",
    "    \n",
    "    # We will also take this opportunity to make sure that all data sets have the same n_timestamps and n_channels\n",
    "    if n_timestamps is None:\n",
    "        n_timestamps, n_channels = X.shape[1:]\n",
    "    if (n_timestamps != X.shape[1]) or (n_channels != X.shape[2]):\n",
    "        raise ValueError(\"Inconsistent data shape!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Vmqqw0RqlnIk",
    "outputId": "4d51a44b-9d75-4ea9-eb7c-831a11ecc8bd",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Found {} sessions.\".format(len(train_valid_inds)))\n",
    "print(\"Each session has {} timestamps and {} channels.\".format(n_timestamps, n_channels))\n",
    "print(\"Training / validation splits:\")\n",
    "print([(len(_[0]), len(_[1])) for _ in train_valid_inds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_k5BBYjlnIt"
   },
   "source": [
    "### Preparing data for deep learning\n",
    "\n",
    "The following function will be called on each dataset when it is loaded to modify the data to be more suitable for deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3l3s5QY9lnIt",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_ds_train_valid(X, Y, trn, tst, batch_size=5, max_offset=0):\n",
    "    # Convert Y from strings to integers.\n",
    "    classes, y = np.unique(Y, return_inverse=True)\n",
    "    n_trials = len(y)\n",
    "    n_subsamps = X.shape[1] - max_offset\n",
    "    \n",
    "    def augmentation_fn(x_dat, y_dat):\n",
    "        t_offset = tf.random.uniform(shape=[], minval=0, maxval=max_offset, dtype=tf.int32)\n",
    "        x_dat = tf.slice(x_dat, [t_offset, 0, 0], [n_subsamps, -1, -1])\n",
    "        return x_dat, y_dat\n",
    "    \n",
    "    def augmentation_valid_fn(x_dat, y_dat):\n",
    "        # For validation data, take only the last n_subsamps\n",
    "        x_dat = tf.slice(x_dat, [max_offset, 0, 0], [n_subsamps, -1, -1])\n",
    "        return x_dat, y_dat\n",
    "    \n",
    "    def preprocess_fn(x_dat, y_dat):\n",
    "        x_dat = tf.cast(x_dat, tf.float32)\n",
    "        x_dat = tf.expand_dims(x_dat, -1)  # Prepare as an image, with only 1 colour channel.\n",
    "        y_dat = tf.cast(y_dat, tf.uint8)\n",
    "        return x_dat, y_dat\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = X[trn], X[tst], y[trn], y[tst]\n",
    "    n_train = len(y_train)\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    ds_valid = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "    \n",
    "    ds_train = ds_train.map(preprocess_fn)\n",
    "    ds_valid = ds_valid.map(preprocess_fn)\n",
    "    if max_offset > 0:\n",
    "        ds_train = ds_train.map(augmentation_fn)\n",
    "        ds_valid = ds_valid.map(augmentation_valid_fn)\n",
    "    ds_train = ds_train.shuffle(n_train + 1).batch(batch_size, drop_remainder=True)  # , drop_remainder=True?\n",
    "    ds_valid = ds_valid.batch(batch_size)\n",
    "    \n",
    "    return ds_train, ds_valid, n_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models\n",
    "\n",
    "One model for each combination of monkey name and electrode bank, but all models will share almost all layers except those associated with the spatial filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import layers\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "def make_models(T, C, aug_offset=50,\n",
    "                k_spike_short=4, l_spike_short=22,\n",
    "                k_spike_long=2, l_spike_long=200,\n",
    "                depth_multiplier=4,\n",
    "                activation='relu',\n",
    "                dowsamp_1=10,\n",
    "                dropout_rate=0.45,\n",
    "                n_pointwise_filters=20,\n",
    "                kern_length_2=40,\n",
    "                downsamp_2=5,\n",
    "                norm_rate=0.45,\n",
    "                l2_reg=0.001\n",
    "                ):\n",
    "    \n",
    "    # Shared Head\n",
    "    shared_input_1 = tf.keras.Input(shape=(T - aug_offset, C, 1))\n",
    "    spk_short = layers.Conv2D(k_spike_short, (l_spike_short, 1), padding='same',\n",
    "                              use_bias=False,\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg))(shared_input_1)\n",
    "    spk_long = layers.Conv2D(k_spike_long, (l_spike_long, 1), padding='same',\n",
    "                             use_bias=False,\n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg))(shared_input_1)\n",
    "    shared_output_1 = layers.Concatenate(axis=-1)([spk_short, spk_long])\n",
    "    shared_head = tf.keras.Model(inputs=shared_input_1, outputs=shared_output_1, name='shared_head')\n",
    "    \n",
    "    # Shared Tail\n",
    "    shared_input_2 = tf.keras.Input(shape=(T - aug_offset, 1,\n",
    "                                           (k_spike_short + k_spike_long) * depth_multiplier))\n",
    "    _y = layers.AveragePooling2D((dowsamp_1, 1))(shared_input_2)\n",
    "    _y = layers.Dropout(dropout_rate)(_y)\n",
    "    \n",
    "    _y = layers.SeparableConv2D(n_pointwise_filters, (kern_length_2, 1), padding='valid',\n",
    "                                depthwise_regularizer=tf.keras.regularizers.l2(l=l2_reg),\n",
    "                                pointwise_regularizer=tf.keras.regularizers.l2(l=l2_reg),\n",
    "                                use_bias=False)(_y)\n",
    "    _y = layers.Activation(activation)(_y)\n",
    "    _y = layers.BatchNormalization(axis=1)(_y)\n",
    "    _y = layers.AveragePooling2D((downsamp_2, 1))(_y)\n",
    "    _y = layers.Dropout(dropout_rate)(_y)\n",
    "      \n",
    "    _y = layers.Flatten()(_y)\n",
    "    _y = layers.Dense(8, kernel_constraint=max_norm(norm_rate))(_y)\n",
    "    shared_output_2 = layers.Activation('softmax')(_y)\n",
    "    shared_tail = tf.keras.Model(inputs=shared_input_2, outputs=shared_output_2, name='shared_tail')\n",
    "    \n",
    "    cfg_models = {}\n",
    "    for cfg_idx, cfg in sess_cfgs.iterrows():\n",
    "        cfg_model_name = cfg['name'] + '_' + cfg['bank']\n",
    "        shared_input = tf.keras.Input(shape=(T - aug_offset, C, 1))\n",
    "        _y = shared_head(shared_input)\n",
    "        _y = layers.DepthwiseConv2D((1, C), use_bias=False, depth_multiplier=depth_multiplier,\n",
    "                            depthwise_regularizer=tf.keras.regularizers.l2(l=l2_reg),\n",
    "                            depthwise_constraint=max_norm(1.))(_y)\n",
    "        _y = layers.Activation(activation)(_y)\n",
    "        _y = layers.BatchNormalization(axis=1)(_y)\n",
    "        _y = layers.Dropout(dropout_rate)(_y)\n",
    "        _y = shared_tail(_y)\n",
    "        cfg_model = tf.keras.Model(inputs=shared_input, outputs=_y, name=cfg_model_name)\n",
    "        cfg_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                          optimizer='RMSprop', metrics=['accuracy'])\n",
    "        cfg_models[cfg_model_name] = cfg_model\n",
    "    \n",
    "    return shared_head, shared_tail, cfg_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_OFFSET = 50\n",
    "shared_head, shared_tail, cfg_models = make_models(n_timestamps, n_channels, aug_offset=MAX_OFFSET)\n",
    "shared_head.summary()\n",
    "shared_tail.summary()\n",
    "cfg_models['JerryLee_A'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IYJwILLelnIw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "N_EPOCHS_IN_SESS = 20\n",
    "N_EPOCHS_ACROSS_SESS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {}\n",
    "for ep_ix in range(N_EPOCHS_ACROSS_SESS):\n",
    "    for idx in np.random.permutation(len(sess_df)):\n",
    "        row = sess_df.loc[idx]\n",
    "        # Load data for this session\n",
    "        sess_id = row['exp_code'].replace('+', '')\n",
    "        X, Y, ax_info = load_macaque_pfc(datadir, sess_id, x_chunk='spiketrains', zscore=False)\n",
    "\n",
    "        # Prepare the data for DL\n",
    "        trn, vld = train_valid_inds[idx]\n",
    "        ds_train, ds_valid, n_train = get_ds_train_valid(X, Y, trn, vld, batch_size=BATCH_SIZE, max_offset=MAX_OFFSET)\n",
    "        \n",
    "        # Get/build the model for this session. The weights should carry over from previous learning.\n",
    "        cfg_model_name = row['name'] + '_' + row['bank']\n",
    "        \n",
    "        # Train model\n",
    "        print(\"Training model {} on {} ({} of {})\".format(cfg_model_name, sess_id,\n",
    "                                                          ep_ix + 1, N_EPOCHS_ACROSS_SESS))\n",
    "        history = cfg_models[cfg_model_name].fit(x=ds_train,\n",
    "                                                 epochs=N_EPOCHS_IN_SESS,\n",
    "                                                 validation_data=ds_valid,\n",
    "                                                 verbose=0)\n",
    "        print(\"Ending acc and val acc: {:.3f}, {:.3f}\".format(history.history['accuracy'][-1],\n",
    "                                                      history.history['val_accuracy'][-1]))\n",
    "        if row['exp_code'] not in hists:\n",
    "            hists[row['exp_code']] = []\n",
    "        hists[row['exp_code']].append(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "nBK_JWUBlnJE",
    "outputId": "2e3494b0-ad8f-4685-b991-feec2c746398",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agg_hists = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': []}\n",
    "for idx, row in sess_df.iterrows():\n",
    "    for k in agg_hists.keys():\n",
    "        agg_hists[k].append(np.hstack([_[k] for _ in hists[row['exp_code']]]))\n",
    "for k in agg_hists.keys():\n",
    "    agg_hists[k] = np.vstack(agg_hists[k])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), facecolor='white')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(agg_hists['accuracy'].T, 'b')\n",
    "plt.plot(agg_hists['val_accuracy'].T, 'r')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(agg_hists['loss'].T, 'b')\n",
    "plt.plot(agg_hists['val_loss'].T, 'r')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is for the deep model to do at least as well as logistic regression, which gave cross-validated classification accuracies of ~60% and ~81% in two datasets. Using the EEGNet CNN, we achieve 74% and 85%. The improvement on the first dataset improves classification above the unofficial threshold for acceptable BCI performance.\n",
    "\n",
    "We expect the deep model will be useful in other ways too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    for idx, row in sess_df.iterrows():\n",
    "        cfg_model_name = row['name'] + '_' + row['bank']\n",
    "        reset_keras(cfg_models[cfg_model_name])\n",
    "    reset_keras(shared_head)\n",
    "    reset_keras(shared_tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKenpuR2lnJH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inspecting the model\n",
    "\n",
    "We're doing a little better than we did with logistic regression,\n",
    "but let's see what we can learn from/about the model.\n",
    "\n",
    "[Further info](http://cs231n.github.io/understanding-cnn/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wFKTmTpHnSA4"
   },
   "outputs": [],
   "source": [
    "# Load the 'best' model from disk.\n",
    "reset_keras(model)\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(datadir / (SESS_ID + '_model_best_all.h5'))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-Distributed Stochastic Neighbour Embedding (t-SNE)\n",
    "\n",
    "https://distill.pub/2016/misread-tsne/\n",
    "\n",
    "From [sklearn.manifold.TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html):\n",
    "\n",
    ">t-SNE [1] is a tool to visualize high-dimensional data. It converts similarities between data points to joint probabilities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. t-SNE has a cost function that is not convex, i.e. with different initializations we can get different results.\n",
    "\n",
    "We will compare the t-SNE projections of the outputs to the projections of the inputs.\n",
    "However, the raw spiketrains do not decompose to very well so for inputs we will use spikerates that are previously derived from the spike trains convolved with a gaussian kernel (sigma=50 msec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spike rates for \n",
    "rates_X, rates_Y, rates_ax_info = load_macaque_pfc(datadir, SESS_ID, x_chunk='spikerates', zscore=True)\n",
    "print(\"Found {} trials, {} timestamps ({} to {} at {} Hz), {} channels\".format(\n",
    "    len(rates_ax_info['instance_data']), len(rates_ax_info['timestamps']),\n",
    "    rates_ax_info['timestamps'][0], rates_ax_info['timestamps'][-1], rates_ax_info['fs'], rates_X.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a colour code cycler e.g. 'C0', 'C1', etc.\n",
    "from itertools import cycle\n",
    "colour_codes = map('C{}'.format, cycle(range(10)))\n",
    "class_colors = np.array([next(colour_codes) for _ in range(10)])\n",
    "# class_colors = np.array(['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w'])\n",
    "\n",
    "TEST_PERPLEXITY = [10, 30]\n",
    "\n",
    "fig = plt.figure(figsize=(18, 6), facecolor='white')\n",
    "def plot_tsne(x_vals, y_vals, perplexity, title='Model Output'):\n",
    "    plt.scatter(x=x_vals[:, 0], y=x_vals[:, 1], color=class_colors[y_vals])\n",
    "    plt.xlabel('t-SNE D-1')\n",
    "    plt.ylabel('t-SNE D-2')\n",
    "    plt.title(title + ' (Perplexity: {})'.format(perplexity))\n",
    "    ax = plt.gca()\n",
    "\n",
    "# First plot a t-SNE on the input data. Precede TSNE with a PCA.\n",
    "pca = PCA(n_components=50)\n",
    "pca_values = pca.fit_transform(rates_X.reshape([-1, np.prod(rates_X.shape[1:])]))\n",
    "tsne_model = TSNE(n_components=2, perplexity=TEST_PERPLEXITY[-1])\n",
    "tsne_values = tsne_model.fit_transform(pca_values)\n",
    "plt.subplot(1, 3, 1)\n",
    "plot_tsne(tsne_values, rates_Y.ravel()+1, TEST_PERPLEXITY[-1], title='Input Rates')\n",
    "\n",
    "# Let's create a version of our CNN model that goes from input all the way to the 200-D flatten layer\n",
    "output_layer = -3\n",
    "tbs = 30  # tsne batch size\n",
    "truncated_model = tf.keras.Model(model.input, model.layers[output_layer].output)\n",
    "flattened_output = []\n",
    "for start_ix in range(0, X.shape[0], tbs):\n",
    "    flattened_output.append(truncated_model(X[start_ix:start_ix+tbs, MAX_OFFSET:, :].astype(np.float32)[:, :, :, None]))\n",
    "flattened_output = tf.concat(flattened_output, 0)\n",
    "reset_keras(truncated_model)\n",
    "\n",
    "for p_ix, perplexity in enumerate(TEST_PERPLEXITY):\n",
    "    # Initialize and fit our TSNE\n",
    "    tsne_model = TSNE(n_components=2, perplexity=perplexity)\n",
    "    tsne_values = tsne_model.fit_transform(flattened_output)\n",
    "    \n",
    "    plt.subplot(1, 3, p_ix + 2)\n",
    "    plot_tsne(tsne_values, Y.ravel()+1, perplexity, title='EEGNet Output')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(str(datadir / (SESS_ID + '_CNN_tSNE.png')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE on the untransformed data shows two different clusters for blue/magenta trial pairs.\n",
    "These probably came at two different blocks of time, between which there was a change in the neural activations.\n",
    "After transforming the data, these classes are grouped together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First convolutional layers\n",
    "The first pair of convolutional layers are simply performing time-domain convolutions on the spike trains.\n",
    "Whereas a typically signal processing pipeline will apply a gaussian, exponentional, or gamma kernel convolution,\n",
    "here we train the convolution kernels directly. There are separate \"short\" kernels and \"long\" kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "L3N1Wr6TlnJM",
    "outputId": "aa508731-0c5d-411c-9ae2-7dcea4f6f2c3"
   },
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12), facecolor='white')\n",
    "t = ax_info['timestamps']\n",
    "\n",
    "x_ranges = [[-0.02, 0.02], [-0.2, 0.2]]\n",
    "y_steps = [1.0, 0.5]\n",
    "\n",
    "impulse = np.zeros_like(t)\n",
    "impulse[np.argmin(np.abs(t))] = 1.0\n",
    "\n",
    "step = np.zeros_like(t)\n",
    "step[np.argmin(np.abs(t)):] = 1.0\n",
    "\n",
    "for s_l in range(2):\n",
    "    filters = np.squeeze(model.layers[1 + s_l].get_weights()[0])\n",
    "\n",
    "    # Impulse response\n",
    "    plt.subplot(2, 3, 1 + 3*s_l)\n",
    "    for filt_ix, filt_coeff in enumerate(filters.T):\n",
    "        imp_conv = scipy.signal.convolve(impulse, filt_coeff, 'same')\n",
    "        plt.plot(t, imp_conv - y_steps[s_l]*filt_ix)\n",
    "    plt.xlim(x_ranges[s_l])\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.title('Impulse Response')\n",
    "\n",
    "    # Step response\n",
    "    plt.subplot(2, 3, 2 + 3*s_l)\n",
    "    for filt_ix, filt_coeff in enumerate(filters.T):\n",
    "        step_response = scipy.signal.convolve(step, filt_coeff, 'same')\n",
    "        plt.plot(t, step_response - y_steps[s_l]*filt_ix)\n",
    "    plt.xlim(x_ranges[s_l])\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.title('Step Response')\n",
    "\n",
    "    plt.subplot(2, 3, 3 + 3*s_l)\n",
    "    for filt_ix, filt_coeff in enumerate(filters.T):\n",
    "        f, resp = scipy.signal.freqz(filt_coeff, worN=int(ax_info['fs']), fs=ax_info['fs'])\n",
    "        plt.plot(f, np.abs(resp) - filt_ix)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.title('Frequency Response')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJZMvmq6nHvy"
   },
   "source": [
    "### Spatial filter\n",
    "The second convolutional layer in our model is a set of spatial filters. We can visualize the weights that transform the 32-channel inputs to D*n_temporal_filter features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "EiDxz6VAlnJH",
    "outputId": "07f99cdc-c8a0-49a9-ee51-0509ffa00415"
   },
   "outputs": [],
   "source": [
    "LAYER_IX = 4\n",
    "spatial_filter = np.squeeze(model.layers[LAYER_IX].get_weights()[0])\n",
    "D = spatial_filter.shape[-1]\n",
    "sp_cols = int(np.ceil(np.sqrt(D + 2)))\n",
    "sp_rows = int(np.ceil((D + 2) / sp_cols))\n",
    "vmax=abs(spatial_filter).max()\n",
    "vmin=-abs(spatial_filter).max()\n",
    "fig = plt.figure(figsize=(12, 12), facecolor='white')\n",
    "for depth_ix in range(D):\n",
    "    plt.subplot(sp_rows, sp_cols, depth_ix + 1)\n",
    "    plt.imshow(spatial_filter[:, :, depth_ix], vmax=vmax, vmin=vmin)\n",
    "    plt.title('Spatial Filter Set {}'.format(depth_ix))\n",
    "    plt.xlabel('Temporal Filter')\n",
    "    plt.ylabel('Input Channel')\n",
    "# plt.colorbar()\n",
    "\n",
    "sum_abs_weight = np.sum(np.sum(np.abs(spatial_filter), axis=1), axis=-1)\n",
    "plt.subplot(sp_rows, sp_cols, D + 1)\n",
    "plt.hist(sum_abs_weight, 20)\n",
    "plt.xlabel('Sum Abs Weight')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Chan Sum Abs. Weight')\n",
    "\n",
    "plt.subplot(sp_rows, sp_cols, D + 2)\n",
    "plt.bar(np.arange(spatial_filter.shape[0]), sum_abs_weight)\n",
    "plt.xlabel('Channel ID')\n",
    "plt.ylabel('Sum Abs Weight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "ch_ids = np.argsort(sum_abs_weight)[::-1]  # channel_ids sorted by weight, descending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZPM-zZqlnJJ"
   },
   "source": [
    "There seems to be a small group of channels with large weights, another group with intermediate weights, and finally the rest of the channels with low weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf6zecPslnJS"
   },
   "source": [
    "## Filter Activation-Maximizing Inputs\n",
    "\n",
    "One useful way to understand what a convolutional layer is doing, especially for deeper layers that are combining abstract features, is to visualize an input that would maximize activation of a filter(s) within the layer.\n",
    "\n",
    "Remembering back to the step-by-step neural net in 02_02, we found the _weights_ that _minimized_ a loss function for a given set of _inputs_. Now we know the weights but we want to find the inputs that _maximize_ the activation (a.k.a. output) of a filter. We're going to use the same loss-minimization training framework, but instead of calculating a 'loss', we will calculate the mean of the output of the layer and filter of interest.\n",
    "\n",
    "We start with a random input and call the model on the input while recording with GradientTape. Then, instead of using our gradients to 'optimize loss' (i.e., step the weights down the gradients), we use our gradients to maximize output (i.e., step the input up the gradients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8ht1hcxB3bGU",
    "outputId": "e80b11c1-37f8-4c8d-b410-20dabfaae44b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def plot_layer(layer_ix, max_filts=None, n_steps=100):\n",
    "    in_shape = [1] + model.input.shape.as_list()[1:]\n",
    "    \n",
    "    layer_output = model.layers[layer_ix].output\n",
    "    n_filts = layer_output.shape[-1]\n",
    "    filt_ids = np.arange(n_filts)\n",
    "    if (max_filts is not None) and (len(filt_ids) > max_filts):\n",
    "        filt_ids = filt_ids[np.argsort(np.random.rand(n_filts))][:max_filts]\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 12), facecolor='white')\n",
    "    sp_cols = int(np.ceil(np.sqrt(len(filt_ids))))\n",
    "    sp_rows = int(np.ceil(len(filt_ids) / sp_cols))\n",
    "    \n",
    "    filt_slice = [np.s_[:] for _ in range(K.ndim(layer_output))]\n",
    "    \n",
    "    for ix, filt_ix in enumerate(filt_ids):\n",
    "        input_data = tf.convert_to_tensor(np.random.randn(*in_shape).astype(np.float32))\n",
    "        if layer_ix > (len(model.layers) - 3):\n",
    "            # model.layers[layer_ix].activation == tf.keras.activations.softmax:\n",
    "            max_model = tf.keras.Model(model.input, layer_output)\n",
    "            non_targ_id = tf.constant(np.setdiff1d(np.arange(layer_output.shape[-1], dtype=int), filt_ix))\n",
    "            for step_ix in range(n_steps):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    tape.watch(input_data)\n",
    "                    filter_act = max_model(input_data)\n",
    "                    targ_act = filter_act[0, filt_ix]\n",
    "                    nontarg_act = K.mean(tf.gather(filter_act, non_targ_id, axis=-1))\n",
    "                    loss_value = targ_act - nontarg_act\n",
    "                grads = tape.gradient(loss_value, input_data)  # Derivative of loss w.r.t. input\n",
    "                # Normalize gradients\n",
    "                grads /= (K.sqrt(K.mean(K.square(grads))) + K.epsilon())\n",
    "                input_data += grads\n",
    "        else:\n",
    "            filt_slice[-1] = filt_ix\n",
    "            max_model = tf.keras.Model(model.input, layer_output[tuple(filt_slice)])\n",
    "            for step_ix in range(n_steps):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    tape.watch(input_data)\n",
    "                    filter_act = max_model(input_data)\n",
    "                    loss_value = K.mean(filter_act)\n",
    "                grads = tape.gradient(loss_value, input_data)  # Derivative of loss w.r.t. input\n",
    "                # Normalize gradients\n",
    "                grads /= (K.sqrt(K.mean(K.square(grads))) + K.epsilon())\n",
    "                input_data += grads\n",
    "        input_data = np.squeeze(input_data)\n",
    "\n",
    "        plt.subplot(sp_rows, sp_cols, ix + 1)\n",
    "        plt.plot(t[MAX_OFFSET:], input_data[:, ch_ids[:4]])\n",
    "        plt.xlabel('Time After Target Onset (s)')\n",
    "        plt.ylabel('Filter {}'.format(filt_ix))\n",
    "        plt.title('Output {:.2f}'.format(loss_value.numpy()))\n",
    "        for xx in [0, 0.25, 1.25]:\n",
    "            plt.axvline(xx, color='k', linestyle='--')\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 is DepthwiseConv2D, 9 is SeparableConv2D\n",
    "plot_layer(9, max_filts=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zdRX_aCLDV_8"
   },
   "source": [
    "### Class Maximizing Inputs\n",
    "If we extend our reasoning from filter activations down to the next-to-last layer (15), and we choose a 'loss' that maximizes one class, we can plot maximization signals for each of the 8 output classes. If we were to do the same on the final Softmax layer (16), the results have a similar shape but are quite noisy because perfect classification is achieved quickly and thus there is no more gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layer(16, n_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPwFVrYEr8wx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Saliency Maps\n",
    "Saliency maps visualize how each part of a real input contributes to the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_hlqlOWr4Ap"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def get_losses_for_class(test_class):\n",
    "    classes, y = np.unique(Y, return_inverse=True)\n",
    "    trial_ids = np.where(y == classes.tolist().index(test_class))[0]\n",
    "    losses_grads = []\n",
    "    for tr_id in trial_ids:\n",
    "        input_data = tf.convert_to_tensor(X[tr_id, MAX_OFFSET:, :].astype(np.float32)[None, :, :, None])\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(input_data)\n",
    "            class_proba = model(input_data)\n",
    "            loss_value = K.sparse_categorical_crossentropy(y[tr_id], class_proba)\n",
    "        grads = tape.gradient(loss_value, input_data)  # Derivative of loss w.r.t. input\n",
    "        # Normalize gradients\n",
    "        grads /= (K.sqrt(K.mean(K.square(grads))) + K.epsilon())\n",
    "        losses_grads.append((loss_value, grads))\n",
    "    return losses_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "wtqESwBb2z4O",
    "outputId": "c6ad8a97-d74d-460e-8ddf-a83ef910fe16"
   },
   "outputs": [],
   "source": [
    "# Plot saliency image for a few trials in a particular class\n",
    "N_SALIENCY_TRIALS = 3\n",
    "TEST_CLASS = 5  # -1 to 6\n",
    "losses_grads = get_losses_for_class(TEST_CLASS)\n",
    "t = ax_info['timestamps'][MAX_OFFSET:]\n",
    "t0_ix = [np.argmin(np.abs(t - _)) for _ in [0, 0.25, 1.25]]\n",
    "\n",
    "loss_vals = [_[0][0].numpy() for _ in losses_grads]\n",
    "grad_vals = np.squeeze(np.concatenate([_[1].numpy() for _ in losses_grads], axis=0))\n",
    "re_ix = np.argsort(loss_vals)\n",
    "b_class = np.squeeze(Y == TEST_CLASS)\n",
    "_x = X[b_class, MAX_OFFSET:][re_ix][:N_SALIENCY_TRIALS]\n",
    "_masks = grad_vals[re_ix][:N_SALIENCY_TRIALS]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6), facecolor='white')\n",
    "for tr_ix in range(N_SALIENCY_TRIALS):\n",
    "    plt.subplot(N_SALIENCY_TRIALS, 1, tr_ix + 1)\n",
    "    plt.imshow(_masks[tr_ix].T, aspect='auto', interpolation='none', vmin=-4, vmax=4, cmap=turbo_cmap)\n",
    "    plt.eventplot([np.where(_)[0] for _ in _x[tr_ix].T], colors='k')\n",
    "    for _t in t0_ix:\n",
    "        plt.axvline(_t)\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Channel ID')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average saliencies for all trials within each class\n",
    "t = ax_info['timestamps'][MAX_OFFSET:]\n",
    "t0_ix = [np.argmin(np.abs(t - _)) for _ in [0, 0.25, 1.25]]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 18), facecolor='white')\n",
    "\n",
    "for ix, class_id in enumerate(np.unique(Y)):\n",
    "    losses_grads = get_losses_for_class(class_id)\n",
    "    loss_vals = [_[0][0].numpy() for _ in losses_grads]\n",
    "    grad_vals = np.squeeze(np.concatenate([_[1].numpy() for _ in losses_grads], axis=0))\n",
    "    grad_vals = np.mean(grad_vals, axis=0)\n",
    "    plot_ix = 2 * ix + 1 * (ix < 4) - 6 * (ix >= 4)\n",
    "    plt.subplot(4, 2, plot_ix)\n",
    "    plt.imshow(grad_vals.T, aspect='auto', interpolation='none', vmin=-4, vmax=4, cmap=turbo_cmap)\n",
    "    for _t in t0_ix:\n",
    "        plt.axvline(_t)\n",
    "    plt.title(str(class_id))\n",
    "    if (ix + 1) % 4 == 0:\n",
    "        plt.xlabel('Sample')\n",
    "    if ix < 4:\n",
    "        plt.ylabel('Channel')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDma3biLn9Q8"
   },
   "source": [
    "## Class Activation Maps\n",
    "\n",
    "Class activation maps (CAM) highlight the parts of the input that contribute most to each classification score. This is similar but different to saliency mapping. Whereas in saliency mapping the losses are back-propagated all the way back to the inputs, in CAM (or [Grad-CAM](https://arxiv.org/pdf/1610.02391.pdf)) the per-class scores / losses are propaged backward only to the last convolutional layer. These losses are then used as the weights in a weighted average of the feature map output of the last convolutional layer. If the result is smaller than the input, it is then interpolated to match the input size.\n",
    "\n",
    "Remember that in image classification the data have width pixels x height pixels x colour depths, but in our neural time-series data we have time samples x 1 x electrodes. We could use CAM on our timeseries data to identify which time points are important for each class but not channels because CAM averages across 'depth'. Time-point importance is unlikely to be informative in this dataset because it is unlikely that the timing of processing visual cues and creating motor plans is class-dependent, especially not at the time scales of the final convolution output (~100 msec).\n",
    "\n",
    "To get any information about which channels of the input were important, we would have to project the losses back to before the spatial filter layer (`DepthwiseConv2D`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Cluster channels based on cross-correlations of per-trial saliency maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization\n",
    "\n",
    "Our model had many hyperparameters. Here we search for their optimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "P_TRAIN = 0.8\n",
    "\n",
    "def evaluate_model(params, verbose=0):\n",
    "    print(params)\n",
    "    n_spike_kernels = params.get('n_spike_kernels', 4)\n",
    "    spike_kern_short = params.get('spike_kern_short', 10)\n",
    "    spike_kern_long = params.get('spike_kern_long', 100)\n",
    "    D = params.get('D', 8)\n",
    "    n_pointwise_filters = params.get('n_pointwise_filters', 22)\n",
    "    kern_length_1 = params.get('kern_length_1', 32)\n",
    "    downsamp_1 = params.get('downsamp_1', 2)\n",
    "    norm_rate = params.get('norm_rate', 0.35)\n",
    "    dropout_rate = params.get('dropout_rate', 0.4)\n",
    "    l2_reg = params.get('l2_reg', 0.00001)\n",
    "    epochs = params.get('epochs', 60)\n",
    "    \n",
    "    # Get the training/testing data for this split.\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, train_size=P_TRAIN)\n",
    "    trn, tst = next(sss.split(X, Y))\n",
    "    ds_train, ds_valid, n_train = get_ds_train_valid(X, Y, trn, tst, batch_size=BATCH_SIZE, max_offset=MAX_OFFSET)\n",
    "    \n",
    "    model = make_model(X.shape[1], X.shape[2], aug_offset=MAX_OFFSET,\n",
    "                       n_spike_kernels=n_spike_kernels, spike_kern_short=spike_kern_short, spike_kern_long=spike_kern_long,\n",
    "                       D=D,\n",
    "                       n_pointwise_filters=n_pointwise_filters, kern_length_1=kern_length_1, downsamp_1=downsamp_1,\n",
    "                       norm_rate=norm_rate, dropout_rate=dropout_rate, l2_reg=l2_reg)\n",
    "    \n",
    "    history = model.fit(x=ds_train, epochs=epochs, validation_data=ds_valid, verbose=verbose)\n",
    "    min_val_loss = min(history.history['val_loss'])\n",
    "    print(\"Min validation loss with these parameters: {}\".format(min_val_loss))\n",
    "    \n",
    "    reset_keras(model)\n",
    "    reset_keras(model)  # Just to be sure...\n",
    "    \n",
    "    return min_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, hp, Trials, tpe, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "trials = None\n",
    "hyperoptBest = None\n",
    "del trials\n",
    "del hyperoptBest\n",
    "\n",
    "\n",
    "space = {\n",
    "    'n_spike_kernels': scope.int(hp.quniform('n_spike_kernels', 1, 8, 1)),\n",
    "    'spike_kern_short': scope.int(hp.quniform('spike_kern_short', 8, 50, 2)),\n",
    "    'spike_kern_long': scope.int(hp.quniform('spike_kern_long', 60, 250, 5)),\n",
    "    'D': scope.int(hp.quniform('D', 1, 12, 1)),\n",
    "    'n_pointwise_filters': scope.int(hp.quniform('n_pointwise_filters', 2, 65, 1)),\n",
    "    'kern_length_1': scope.int(hp.quniform('kern_length_1', 4, 64, 1)),\n",
    "    'downsamp_1': scope.int(hp.quniform('downsamp_1', 2, 9, 1)),\n",
    "    'norm_rate': hp.uniform('norm_rate', 0., 0.5),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0., 0.5),\n",
    "#     'l2_reg': hp.loguniform('l2_reg', np.log(0.000001), np.log(0.1)),\n",
    "#     'epochs': scope.int(hp.quniform('epochs', 60, 300, 20)),\n",
    "}\n",
    "\n",
    "trials = Trials()  # object that holds iteration results\n",
    "#Do optimization\n",
    "eval_hours = 3.\n",
    "minutes_per_eval = 2.\n",
    "max_evals = int(eval_hours * 60 / minutes_per_eval)\n",
    "hyperoptBest = fmin(evaluate_model, space, algo=tpe.suggest, max_evals=max_evals, trials=trials)\n",
    "print(\"Best Loss: {}\".format(trials.best_trial['result']['loss']))\n",
    "print(\"Best Parameters: {}\".format(hyperoptBest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot_matrix_colored(params_names, params_values, best_losses, best_trial=None):\n",
    "    \"\"\"Scatterplot colored according to the Z values of the points.\"\"\"\n",
    "    import matplotlib\n",
    "    \n",
    "    nb_params = len(params_values)\n",
    "    best_losses = np.array(best_losses)\n",
    "    norm = matplotlib.colors.Normalize(vmin=best_losses.min(), vmax=best_losses.max())\n",
    "    \n",
    "    fig, ax = plt.subplots(nb_params, nb_params, figsize=(16, 16))#, facecolor=bg_color, edgecolor=fg_color)\n",
    "    \n",
    "    for i in range(nb_params):\n",
    "        p1 = params_values[i]\n",
    "        for j in range(nb_params):\n",
    "            p2 = params_values[j]\n",
    "            \n",
    "            axes = ax[i, j]\n",
    "            \n",
    "            if best_trial is not None:\n",
    "                axes.axvline(p2[best_trial], color='r', zorder=-1, alpha=0.3)\n",
    "                axes.axhline(p1[best_trial], color='r', zorder=-1, alpha=0.3)\n",
    "                \n",
    "            # Subplot:\n",
    "            s = axes.scatter(p2, p1, s=30, alpha=0.6,\n",
    "                             c=best_losses, cmap=turbo_cmap, norm=norm)\n",
    "\n",
    "            # Labels only on side subplots, for x and y:\n",
    "            if j == 0:\n",
    "                axes.set_ylabel(params_names[i], rotation=0)\n",
    "            else:\n",
    "                axes.set_yticks([])\n",
    "            \n",
    "            if i == nb_params - 1:\n",
    "                axes.set_xlabel(params_names[j], rotation=90)\n",
    "            else:\n",
    "                axes.set_xticks([])\n",
    "\n",
    "    fig.subplots_adjust(right=0.82, top=0.95)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    cb = fig.colorbar(s, cax=cbar_ax)\n",
    "    \n",
    "    plt.suptitle('Scatterplot matrix of tried values in the search space over different params, colored in function of best test accuracy')\n",
    "    plt.show()\n",
    "\n",
    "hp_loss = [1 / (_['result']['loss']) for _ in trials.trials]\n",
    "hp_names = list(space.keys())\n",
    "hp_vals = [[_['misc']['vals'][key][0] for _ in trials.trials] for key in hp_names]\n",
    "if 'l2_reg' in hp_names:\n",
    "    hp_vals[hp_names.index('l2_reg')] = np.log10(hp_vals[hp_names.index('l2_reg')])\n",
    "scatterplot_matrix_colored(hp_names, hp_vals, hp_loss, best_trial=trials.best_trial['tid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped bar plots of manually-input data.\n",
    "monkey_names = ['M', 'JL']\n",
    "data_types = ['LR\\nBaseline', 'LR\\nTargets', 'LR\\nFull', 'EEGNet\\nFull', 'LSTM\\nFull']\n",
    "accuracies = [[27.8, 41.6, 62.7, 74.9, 76.1],[34, 47, 81, 85.2, 85.5]]\n",
    "\n",
    "ind = np.arange(len(data_types))  # the x locations for the groups\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for m_ix, m_name in enumerate(monkey_names):\n",
    "    ax.bar(ind - width/2 + m_ix * width, accuracies[m_ix], width, label=m_name)\n",
    "\n",
    "ax.set_ylabel('Accuracies (%)')\n",
    "ax.set_ylim([0, 100])\n",
    "ax.set_title('Target Prediction by Session and Model')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(data_types)\n",
    "ax.legend()\n",
    "\n",
    "fig.savefig(str(datadir / 'converted' / ('Acc_Bars.png')))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "03_02_CNN_faces_houses.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
