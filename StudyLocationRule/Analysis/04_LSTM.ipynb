{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HwqG-TtNfh6"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "vGnyG0prNfiC",
    "outputId": "f0639ef6-d298-4e5d-eeb7-98d48e3bde09"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "try:\n",
    "    # See if we are running on google.colab\n",
    "    import google.colab\n",
    "    from google.colab import files\n",
    "    os.chdir('..')\n",
    "    if not (Path.home() / '.kaggle').is_dir():\n",
    "        # Configure kaggle\n",
    "        files.upload()  # Find the kaggle.json file in your ~/.kaggle directory.\n",
    "        !pip install -q kaggle\n",
    "        !mkdir -p ~/.kaggle\n",
    "        !mv kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "    IN_COLAB = True\n",
    "    # Setup tensorflow 2.0\n",
    "    !pip install -q tensorflow-gpu==2.0.0-beta0\n",
    "except ModuleNotFoundError:\n",
    "    IN_COLAB = False\n",
    "    import sys\n",
    "    if Path.cwd().stem == 'notebooks':\n",
    "        os.chdir(Path.cwd().parent)\n",
    "    # Make sure the kaggle executable is on the PATH\n",
    "    os.environ['PATH'] = os.environ['PATH'] + ';' + str(Path(sys.executable).parent / 'Scripts')\n",
    "\n",
    "# Try to clear any logs from previous runs\n",
    "if (Path.cwd() / 'logs').is_dir():\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.rmtree(str(Path.cwd() / 'logs'))\n",
    "    except PermissionError:\n",
    "        print(\"Unable to remove logs directory.\")\n",
    "\n",
    "# Additional imports\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "UVWjIh21OIQ0",
    "outputId": "062cdba2-b377-4799-9492-19a74880209e"
   },
   "outputs": [],
   "source": [
    "# Download and unzip data (2.1 GB)\n",
    "datadir = Path.cwd() / 'data'\n",
    "if not (datadir / 'converted').is_dir():\n",
    "    !kaggle datasets download --unzip --path {str(datadir / 'converted')} cboulay/macaque-8a-spikes-rates-and-saccades\n",
    "    print(\"Finished downloading and extracting data.\")\n",
    "else:\n",
    "    print(\"Data directory found. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "mrm_TM1fPDNB",
    "outputId": "e8d31b67-1f3d-4c52-97c7-6cc6f81cc4c2"
   },
   "outputs": [],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NN7E27yGOk0S"
   },
   "outputs": [],
   "source": [
    "def _recurse_get_dict_from_group(grp):\n",
    "    result = dict(grp.attrs)\n",
    "    for k, v in result.items():\n",
    "        if isinstance(v, np.ndarray) and v.dtype.char == 'S':\n",
    "            result[k] = v.astype('U').astype('O')\n",
    "    for k, v in grp.items():\n",
    "        result[k] = _recurse_get_dict_from_group(v)\n",
    "    return result\n",
    "\n",
    "\n",
    "def from_neuropype_h5(filename):\n",
    "    import h5py\n",
    "    from pandas import DataFrame\n",
    "    f = h5py.File(filename, 'r')\n",
    "\n",
    "    chunks = []\n",
    "    if 'chunks' in f.keys():\n",
    "        chunks_group = f['chunks']\n",
    "        for ch_key in chunks_group.keys():\n",
    "            chunk_group = chunks_group.get(ch_key)\n",
    "            # Process data\n",
    "            block_group = chunk_group.get('block')\n",
    "            data_ = block_group.get('data')\n",
    "            if isinstance(data_, h5py.Dataset):\n",
    "                data = data_[()]\n",
    "            else:\n",
    "                # Data is a group. This only happens with sparse matrices.\n",
    "                import scipy.sparse\n",
    "                data = scipy.sparse.csr_matrix((data_['data'][:], data_['indices'][:], data_['indptr'][:]),\n",
    "                                               data_.attrs['shape'])\n",
    "\n",
    "            axes_group = block_group.get('axes')\n",
    "            axes = []\n",
    "            for ax_ix, axis_key in enumerate(axes_group.keys()):\n",
    "                axis_group = axes_group.get(axis_key)\n",
    "                ax_type = axis_group.attrs.get('type')\n",
    "                new_ax = {'name': axis_key, 'type': ax_type}\n",
    "                if ax_type == 'axis':\n",
    "                    new_ax.update(dict(x=np.arange(data.shape[ax_ix])))\n",
    "                elif ax_type == 'time':\n",
    "                    nom_rate = axis_group.attrs.get('nominal_rate')\n",
    "                    if np.isnan(nom_rate):\n",
    "                        nom_rate = None\n",
    "                    new_ax.update(dict(nominal_rate=nom_rate,\n",
    "                                       times=axis_group.get('times')[()]))\n",
    "                elif ax_type == 'frequency':\n",
    "                    new_ax.update(dict(frequencies=axis_group.get('frequencies')[()]))\n",
    "                elif ax_type == 'space':\n",
    "                    new_ax.update(dict(names=axis_group.get('names')[()],\n",
    "                                       naming_system=axis_group.attrs['naming_system'],\n",
    "                                       positions=axis_group.get('positions')[()],\n",
    "                                       coordinate_system=axis_group.attrs['coordinate_system'],\n",
    "                                       units=axis_group.get('units')[()]))\n",
    "                elif ax_type == 'feature':\n",
    "                    new_ax.update(dict(names=axis_group.get('names')[()],\n",
    "                                       units=axis_group.get('units')[()],\n",
    "                                       properties=axis_group.get('properties')[()],\n",
    "                                       error_distrib=axis_group.get('error_distrib')[()],\n",
    "                                       sampling_distrib=axis_group.get('sampling_distrib')[()]))\n",
    "                elif ax_type == 'instance':\n",
    "                    new_ax.update({'times': axis_group.get('times')[()]})\n",
    "                    if 'instance_type' in axis_group.attrs:\n",
    "                        new_ax.update({'instance_type': axis_group.attrs['instance_type']})\n",
    "                    _dat = axis_group.get('data')[()]\n",
    "                    if not _dat.dtype.names:\n",
    "                        new_ax.update({'data': axis_group.get('data')[()]})\n",
    "                    else:\n",
    "                        _df = DataFrame(_dat)\n",
    "                        # Convert binary objects to string objects\n",
    "                        str_df = _df.select_dtypes([np.object])\n",
    "                        str_df = str_df.stack().str.decode('utf-8').unstack()\n",
    "                        for col in str_df:\n",
    "                            _df[col] = str_df[col]\n",
    "                        new_ax.update({'data': _df})\n",
    "\n",
    "                elif ax_type == 'statistic':\n",
    "                    new_ax.update(dict(param_types=axis_group.get('param_types')[()]))\n",
    "                elif ax_type == 'lag':\n",
    "                    new_ax.update(dict(xlags=axis_group.get('lags')[()]))\n",
    "                if new_ax is not None:\n",
    "                    axes.append(new_ax)\n",
    "\n",
    "            chunks.append((ch_key, dict(data=data, axes=axes,\n",
    "                                        props=_recurse_get_dict_from_group(chunk_group.get('props')))))\n",
    "\n",
    "    return chunks\n",
    "  \n",
    "def load_macaque_pfc(data_path, sess_id, x_chunk='spikerates', zscore=False):\n",
    "    \"\"\"\n",
    "    Load a file from the KJM faces_basic dataset.\n",
    "    :param data_path: Path object pointing to the root of the data directory (parent of 'converted/faces_basic')\n",
    "    :param sess_id: Subject ID (2-character string)\n",
    "    :param x_chunk: Type of data to return. Options are 'analogsignals' (i.e. LFPs), 'spikerates', 'spiketrains'\n",
    "    :param zscore: Set True to center and standardize X data per-channel.\n",
    "    :return: X, Y, ax_info\n",
    "    \"\"\"\n",
    "    test_file = data_path / 'converted' / (sess_id + '_segmented.h5')\n",
    "    chunks = from_neuropype_h5(test_file)\n",
    "    chunk_names = [_[0] for _ in chunks]\n",
    "    chunk = chunks[chunk_names.index(x_chunk)][1]\n",
    "    ax_types = [_['type'] for _ in chunk['axes']]\n",
    "    inst_ix, time_ix, space_ix = (ax_types.index(_) for _ in ('instance', 'time', 'space'))\n",
    "    instance_axis = chunk['axes'][inst_ix]\n",
    "    X = chunk['data']\n",
    "    Y = instance_axis['data']['sacClass'].values.reshape(-1, 1)\n",
    "    ax_info = {'instance_data': instance_axis['data'],\n",
    "               'fs': chunk['axes'][time_ix]['nominal_rate'],\n",
    "               'timestamps': chunk['axes'][time_ix]['times'],\n",
    "               'channel_names': chunk['axes'][space_ix]['names'],\n",
    "               'channel_locs': chunk['axes'][space_ix]['positions']\n",
    "               }\n",
    "\n",
    "    if time_ix > space_ix:\n",
    "        # LFPs were stored with axes order reversed.\n",
    "        X = np.transpose(X, (0, 2, 1))\n",
    "\n",
    "    if zscore:\n",
    "        if x_chunk == 'spiketrains':\n",
    "            raise ValueError(\"Cannot z-score boolean spiketrains.\")\n",
    "        # Centre and standardize across all trials*samples\n",
    "        tmp = np.reshape(X, (X.shape[0] * X.shape[1], X.shape[2]))\n",
    "        X = (X - np.mean(tmp, axis=0)) / np.std(tmp, axis=0)\n",
    "\n",
    "    return X, Y, ax_info\n",
    "  \n",
    "\n",
    "def pos_sigmoid(saccade):\n",
    "    x = np.arange(-155., 155., 310/171)\n",
    "    y = np.zeros((8, 171))\n",
    "    y[-1] = -12 / (1+(1.3**(-x)))\n",
    "    y[0] = -7 / (1+(1.03**(-x)))\n",
    "    y[1] = 2 / (1+(1.03**(-x)))\n",
    "    y[2] = 7 / (1 + (1.03 ** (-x)))\n",
    "    y[3] = 12 / (1 + (1.3 ** (-x)))\n",
    "    y[4] = 7 / (1 + (1.03 ** (x)))\n",
    "    y[5] = 2 / (1 + (1.03 ** (x)))\n",
    "    y[6] = -7 / (1 + (1.03 ** (x)))\n",
    "    return y[saccade]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YyKg7xvqd0nN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SESS_ID = ['sra3_1_j_050_00', 'sra3_1_m_074_0001']\n",
    "BATCH_SIZE = 8\n",
    "P_TRAIN = 0.8\n",
    "BIN_DURATION = 25     # Width of window used to bin spikes, in 10 ms\n",
    "BIN_OVRLP = 4\n",
    "N_TAPS = 8            # Number of bins of history used in a sequence.\n",
    "P_DROPOUT = 0.5      # Proportion of units to set to 0 on each step.\n",
    "N_RNN_UNITS = 100      # Size of RNN output (state)\n",
    "L2_REG = 1.7e-4       # Parameter regularization strength.\n",
    "STATEFUL = False      # Whether or not to keep state between sequences (True is not tested)\n",
    "EPOCHS = 15          # Number of loops through the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_QEk55j8Omvm",
    "outputId": "86c046f3-12ae-47f0-b0e0-bd2009527007"
   },
   "outputs": [],
   "source": [
    "# MONKEY J DATA\n",
    "\n",
    "X2, y, ax_info = load_macaque_pfc(datadir, SESS_ID[0], zscore=True)\n",
    "\n",
    "X = np.zeros((X2.shape[0], N_TAPS, X2.shape[2]))\n",
    "Y = np.zeros((X2.shape[0], 8))\n",
    "for j in range(N_TAPS-1):\n",
    "  X[:, j, :] = np.mean(X2[:, j*(BIN_DURATION - BIN_OVRLP):j*(BIN_DURATION - BIN_OVRLP) + BIN_DURATION, :], axis=1)\n",
    "\n",
    "X[:, N_TAPS-1, :] = np.mean(X2[:, (N_TAPS-1)*(BIN_DURATION - BIN_OVRLP):, :], axis=1)\n",
    "for i in range(X2.shape[0]):\n",
    "  Y[i, y[i]] = 1\n",
    "  \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, train_size=P_TRAIN)\n",
    "\n",
    "ds_train_j = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "ds_valid_j = tf.data.Dataset.from_tensor_slices((X_valid, Y_valid))\n",
    "\n",
    "ds_train_j = ds_train_j.shuffle(int(X.shape[0] * P_TRAIN) + 1)\n",
    "ds_train_j = ds_train_j.batch(BATCH_SIZE, drop_remainder=True)\n",
    "ds_valid_j = ds_valid_j.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "  \n",
    "print(ds_train_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6DIVV2IxbVyl",
    "outputId": "ec994e9e-6954-4c0e-960b-4568aa5ddc6f"
   },
   "outputs": [],
   "source": [
    "# MONKEY M DATA\n",
    "\n",
    "X2, y, ax_info = load_macaque_pfc(datadir, SESS_ID[1], zscore=True)\n",
    "\n",
    "X = np.zeros((X2.shape[0], N_TAPS, X2.shape[2]))\n",
    "Y = np.zeros((X2.shape[0], 8))\n",
    "for j in range(N_TAPS-1):\n",
    "  X[:, j, :] = np.mean(X2[:, j*(BIN_DURATION - BIN_OVRLP):j*(BIN_DURATION - BIN_OVRLP) + BIN_DURATION, :], axis=1)\n",
    "\n",
    "X[:, N_TAPS-1, :] = np.mean(X2[:, (N_TAPS-1)*(BIN_DURATION - BIN_OVRLP):, :], axis=1)\n",
    "for i in range(X2.shape[0]):\n",
    "  Y[i, y[i]] = 1\n",
    "  \n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, train_size=P_TRAIN)\n",
    "\n",
    "ds_train_m = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "ds_valid_m = tf.data.Dataset.from_tensor_slices((X_valid, Y_valid))\n",
    "\n",
    "ds_train_m = ds_train_m.shuffle(int(X.shape[0] * P_TRAIN) + 1)\n",
    "ds_train_m = ds_train_m.batch(BATCH_SIZE, drop_remainder=True)\n",
    "ds_valid_m = ds_valid_m.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "  \n",
    "print(ds_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "3SuZ5Kre6GS3",
    "outputId": "f0ffddfb-2310-46d2-d4c4-800755948244",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]\n",
    "output_shape = 8\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape = input_shape)\n",
    "o1 = tf.keras.layers.LSTM(N_RNN_UNITS, dropout = P_DROPOUT,\n",
    "                          recurrent_dropout = 0,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "                          recurrent_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "                          return_sequences=False, stateful=False)(inputs)\n",
    "o2 = tf.keras.layers.Dropout(P_DROPOUT)(o1)\n",
    "# o3 = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2_REG))(o2)\n",
    "outputs = tf.keras.layers.Dense(output_shape, activation='softmax')(o2)\n",
    "\n",
    "model_j = tf.keras.Model(inputs, outputs)\n",
    "# adam = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model_j.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_j.summary()\n",
    "\n",
    "model_m = tf.keras.Model(inputs, outputs)\n",
    "model_m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "1W2n0YDreMjW",
    "outputId": "0e47fd6e-db54-4151-aa58-8f660704c68f"
   },
   "outputs": [],
   "source": [
    "# MONKEY J MODEL FIT\n",
    "history = model_j.fit(x=ds_train_j, epochs=EPOCHS, verbose=1, validation_data=ds_valid_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "EFTuFxmRYVOJ",
    "outputId": "7bf0962b-fb73-4bd9-aa04-1d24c61c29b9"
   },
   "outputs": [],
   "source": [
    "# MONKEY M MODEL FIT\n",
    "history = model_m.fit(x=ds_train_m, epochs=EPOCHS, verbose=1, validation_data=ds_valid_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBKkXTWm0TCX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred_y = model.predict(x=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "colab_type": "code",
    "id": "e6gNcuddtueG",
    "outputId": "4ce5a148-564e-4f0d-b501-aa2d6ebda3db"
   },
   "outputs": [],
   "source": [
    "print([_.shape for _ in model.layers[1].get_weights()])\n",
    "\n",
    "plt.imshow(model.layers[1].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pgGPelL8d-_j",
    "outputId": "6f514eab-df24-4dd3-f62f-c70ebdd78ede"
   },
   "outputs": [],
   "source": [
    "**KALMAN FILTER**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "04_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
