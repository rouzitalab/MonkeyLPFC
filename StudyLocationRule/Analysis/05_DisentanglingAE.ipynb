{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disentangled representation of intention in macaque prefrontal cortex\n",
    "\n",
    "Herein we train a model to yield a low-dimensional latent vector that encodes only the intended saccade target, and is disentangled from another low-dimensional timeseries that encodes simple dynamics related to target-agnostic task events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "[Notes on beta-VAE in general](https://colab.research.google.com/github/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/05_04_betaVAE_TFP.ipynb).\n",
    "\n",
    "[Disentangled sequential autoencoders paper, by Li and Mandt, ICML 2018](https://arxiv.org/pdf/1803.02991.pdf), with an implementation in [TF Probability by google](https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/disentangled_vae.py) and in [pytorch by yatindandi/Disentangled-Sequential-Autoencoder](https://github.com/yatindandi/Disentangled-Sequential-Autoencoder).\n",
    "\n",
    "Further extensions of this concept can be found [Swapping Autoencoder for Deep Image Manipulation by Park et al., 2020](https://arxiv.org/pdf/2007.00653.pdf) with [pytorch implementation](https://github.com/rosinality/swapping-autoencoder-pytorch).\n",
    "* discriminator for real vs fake when keeping dynamic latent but swapping static latent from another trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "try:\n",
    "    # See if we are running on google.colab\n",
    "    from google.colab import files\n",
    "    %tensorflow_version 2.x\n",
    "    os.chdir('..')\n",
    "    \n",
    "    if not (Path.home() / '.kaggle').is_dir():\n",
    "        # Configure kaggle\n",
    "        uploaded = files.upload()  # Find the kaggle.json file in your ~/.kaggle directory.\n",
    "        if 'kaggle.json' in uploaded.keys():\n",
    "            !mkdir -p ~/.kaggle\n",
    "            !mv kaggle.json ~/.kaggle/\n",
    "            !chmod 600 ~/.kaggle/kaggle.json\n",
    "            \n",
    "    if Path.cwd().stem == 'MonkeyPFCSaccadeStudies':\n",
    "        os.chdir(Path.cwd().parent)\n",
    "    if not (Path.cwd() / 'MonkeyPFCSaccadeStudies').is_dir():\n",
    "        !git clone --single-branch --recursive https://github.com/SachsLab/MonkeyPFCSaccadeStudies.git\n",
    "        sys.path.append(str(Path.cwd() / 'MonkeyPFCSaccadeStudies'))\n",
    "    os.chdir('MonkeyPFCSaccadeStudies')\n",
    "        \n",
    "    !pip install git+https://github.com/SachsLab/indl.git\n",
    "    !pip install -q kaggle\n",
    "    !pip install --upgrade tensorflow-probability\n",
    "    IN_COLAB = True\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    IN_COLAB = False\n",
    "    import sys\n",
    "    if Path.cwd().stem == 'Analysis':\n",
    "        os.chdir(Path.cwd().parent.parent)\n",
    "    # Make sure the kaggle executable is on the PATH\n",
    "    os.environ['PATH'] = os.environ['PATH'] + ';' + str(Path(sys.executable).parent / 'Scripts')\n",
    "\n",
    "# Try to clear any logs from previous runs\n",
    "if (Path.cwd() / 'logs').is_dir():\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.rmtree(str(Path.cwd() / 'logs'))\n",
    "    except PermissionError:\n",
    "        print(\"Unable to remove logs directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports\n",
    "from functools import partial\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfkl\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from indl.display import turbo_cmap\n",
    "if True:\n",
    "    plt.style.use('dark_background')\n",
    "else:\n",
    "    plt.style.use('seaborn-poster')\n",
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 24,\n",
    "    'axes.labelsize': 20,\n",
    "    'lines.linewidth': 1,\n",
    "    'lines.markersize': 5,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 18,\n",
    "    'figure.figsize': (8, 6.4)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    data_path = Path.cwd() / 'data' / 'monkey_pfc' / 'converted'\n",
    "else:\n",
    "    data_path = Path.cwd() / 'StudyLocationRule' / 'Data' / 'Preprocessed'\n",
    "\n",
    "if not (data_path).is_dir():\n",
    "    !kaggle datasets download --unzip --path {str(data_path)} cboulay/macaque-8a-spikes-rates-and-saccades\n",
    "    print(\"Finished downloading and extracting data.\")\n",
    "else:\n",
    "    print(\"Data directory found. Skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "We will use a custom function `load_macaque_pfc` to load the data into memory.\n",
    "\n",
    "There are 4 different strings to be passed to the import `x_chunk` argument:\n",
    "* 'analogsignals' - if present. Returns 1 kHz LFPs\n",
    "* 'gaze'          - Returns 2-channel gaze data.\n",
    "* 'spikerates'    - Returns smoothed spikerates\n",
    "* 'spiketrains'\n",
    "\n",
    "The `y_type` argument can be\n",
    "* 'pair and choice' - returns Y as np.array of (target_pair, choice_within_pair)\n",
    "* 'encoded input' - returns Y as np.array of shape (n_samples, 10) (explained below)\n",
    "* 'replace with column name' - returns Y as a vector of per-trial values. e.g., 'sacClass'\n",
    "\n",
    "The actual data we load depends on the particular analysis below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.misc import sess_infos, load_macaque_pfc\n",
    "\n",
    "load_kwargs = {\n",
    "    'valid_outcomes': (0, 9),  # Use (0, 9) to include trials with incorrect behaviour\n",
    "    'zscore': False,\n",
    "    'dprime_range': (-np.inf, np.inf),  # Use (-np.inf, np.inf) to include all trials.\n",
    "    'time_range': (-np.inf, 1.35),  # np.inf),\n",
    "    'verbose': True,\n",
    "    'y_type': 'sacClass',\n",
    "    'samples_last': False,\n",
    "    'resample_X': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sess_ix = 1\n",
    "sess_info = sess_infos[test_sess_ix]\n",
    "sess_id = sess_info['exp_code']\n",
    "print(f\"\\nImporting session {sess_id}\")\n",
    "\n",
    "# Different x_chunk values: 'analogsignals' (i.e. LFPs), 'spikerates', 'spiketrains', 'gaze'\n",
    "# Rates...\n",
    "#X_rates, Y_class, ax_info = load_macaque_pfc(data_path, sess_id, x_chunk='spikerates', **load_kwargs)\n",
    "# Set baseline to 0. Makes reconstruction with relu easier.\n",
    "#X_rates = X_rates - np.min(np.min(X_rates, axis=0, keepdims=True), axis=1, keepdims=True)\n",
    "#X_rates = X_rates.astype(np.float32)\n",
    "\n",
    "X_spikes, Y_class, ax_info = load_macaque_pfc(data_path, sess_id, x_chunk='spiketrains',\n",
    "                                              **load_kwargs)\n",
    "X_spikes = X_spikes * load_kwargs['resample_X']  # spks/msec -> spks/bin\n",
    "X_spikes = X_spikes.astype(np.float32)\n",
    "Y_class = tf.keras.utils.to_categorical(Y_class, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_spikes[1, :, ::6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_READIN = False\n",
    "N_HIDDEN_STATIC = 128                # Number of RNN cells in static encoder network\n",
    "LATENT_SIZE_STATIC = 64              # Size of static latent vector f | g_0\n",
    "STATIC_LATENT_OFF_DIAG = False\n",
    "DYNAMIC_GRAPH = 'full'               # 'none', 'factorized', 'full', 'controller'\n",
    "N_HIDDEN_DYNAMIC = 12                # Number of RNN cells in dynamic encoder\n",
    "LATENT_SIZE_DYNAMIC = 2              # Size of dynamic latent vector z_t | u_t\n",
    "DYNAMIC_LATENT_OFF_DIAG = False\n",
    "N_HIDDEN_GEN = 256                   # Number of RNN cells in generator\n",
    "N_FACTORS = 36                       # Number of latent factors ?? | f_t\n",
    "# NUM_RECONSTRUCTION_SAMPLES = 1\n",
    "BATCH_SIZE = 16\n",
    "NUM_SAMPLES = 4\n",
    "RANDOM_SEED = 1337\n",
    "N_EPOCHS = 150\n",
    "MAX_GRAD_NORM = 200.0\n",
    "DROPOUT_RATE = 0.025\n",
    "L2_REG = 2e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Imports\n",
    "\n",
    "Much of our model will be created by creating model blocks comprising multiple layers/transformations. Here we import some helper functions and classes for simplifying model creation.\n",
    "\n",
    "The AutoShape classes are necessary because otherwise a block that is a tf.keras.Model subclass does not report its shape properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indl.model.tfp import scale_shift\n",
    "from indl.model import parts\n",
    "from indl.model.autoshape_mixin import AutoShapeMixin\n",
    "\n",
    "\n",
    "class BidirectionalAutoShape(AutoShapeMixin, tfkl.Bidirectional):\n",
    "    pass\n",
    "class GRUAutoShape(AutoShapeMixin, tfkl.GRU):\n",
    "    pass\n",
    "class DenseAutoShape(AutoShapeMixin, tfkl.Dense):\n",
    "    pass\n",
    "class DistLambdaAutoShape(AutoShapeMixin, tfpl.DistributionLambda):\n",
    "    pass\n",
    "class GRUCellAutoShape(AutoShapeMixin, tfkl.GRUCell):\n",
    "    pass\n",
    "class DropoutAutoShape(AutoShapeMixin, tfkl.Dropout):\n",
    "    pass\n",
    "class WeightNormAutoShape(AutoShapeMixin, tfa.layers.WeightNormalization):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from indl.data.augmentations import random_slice\n",
    "ds = tf.data.Dataset.from_tensor_slices((X_spikes, Y_class))\n",
    "# Any augmentations. e.g., random slicing.\n",
    "# p_random_slice = partial(random_slice, max_offset=3, axis=0)\n",
    "# ds = ds.map(p_random_slice)\n",
    "ds = ds.shuffle(X_spikes.shape[0] + 1)\n",
    "ds = ds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(ds.element_spec)\n",
    "\n",
    "input_shape = ds.element_spec[0].shape.as_list()\n",
    "input_shape[0] = None  # Batch dim\n",
    "input_shape = tuple(input_shape)\n",
    "n_times, n_sensors = input_shape[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read-In Feature Extraction (Optional)\n",
    "\n",
    "This optional part of the model does some mild feature extraction on the input data. The intention is to transform the data into a common dimensionality and space.\n",
    "\n",
    "Input shape: `(batch, samples, channels)`\n",
    "\n",
    "Output shape: `(batch, samples//pooling, n_kernels*depth_multiplier)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadIn(input_shape, n_kernels=6, kern_length=25, depth_multiplier=2, activation=tf.nn.leaky_relu, pooling=5, dropout_rate=0.25):\n",
    "    n_times, n_sensors = input_shape[-2:]\n",
    "    return tf.keras.Sequential([\n",
    "        tfkl.Input(shape=input_shape[-2:]),\n",
    "        tfkl.Reshape(input_shape[-2:] + (1,)),\n",
    "        tfkl.Conv2D(n_kernels, (kern_length, 1), padding='same', use_bias=False, name=\"temporal_filter\"),\n",
    "        #     tfkl.BatchNormalization(name=\"temporal_filter_bnorm\"),\n",
    "        tfkl.DepthwiseConv2D((1, n_sensors), padding='valid',\n",
    "                             depth_multiplier=depth_multiplier, use_bias=False, name=\"spatial_filter\"),\n",
    "        #     tfkl.BatchNormalization(name=\"spatial_filter_bnorm\"),\n",
    "        tfkl.Activation(activation),\n",
    "        tfkl.AveragePooling2D((pooling, 1), name=\"temporal_smoothing\"),\n",
    "        #     tfkl.Dropout(dropout_rate),\n",
    "        tfkl.Reshape((n_times // pooling, n_kernels * depth_multiplier))],\n",
    "        name=\"read_in\")\n",
    "\n",
    "K.clear_session()\n",
    "read_in = ReadIn(input_shape)\n",
    "read_in.summary()\n",
    "\n",
    "# temp_input = tf.random.uniform(ds.element_spec[0].shape)\n",
    "# tmp = read_in(temp_input)\n",
    "# print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "Posterior distributions `q` of latents $f$ (static) and $z_t$ (dynamic) are conditioned on input sequence $x_t$.\n",
    "\n",
    "Latent postierior, Static only:\n",
    "$$q(f | x_{1:T})$$\n",
    "\n",
    "Latent posterior, Static and Dynamic Factorized:\n",
    "$$q(z_{1:T}, f | x_{1:T}) = q(f | x_{1:T}) \\prod_{t=1}^T q(z_t | x_t)$$\n",
    "\n",
    "Latent posterior, Static and Dynamic Full:\n",
    "$$q(z_{1:T}, f | x_{1:T}) = q(f | x_{1:T}) q(z_{1:T} | f, x_{1:T})$$\n",
    "Note that _q(z)_ depends on _f_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Static Encoder\n",
    "\n",
    "Transform full sequence of \"features\" (`inputs` or `ReadIn(inputs)`) through (1) bidirectional LSTM then (2) affine to yield parameters of static latent posterior distribution:\n",
    "$$q(f | x_{1:T})$$\n",
    "This distribution is a multivariate normal, optionally with off-diagonal elements allowed.\n",
    "\n",
    "Model loss will include the KL divergence between the static latent posterior and a prior; the prior is a learnable multivariate normal diagonal. The prior is initialized with a mean of 0 and a stddev of 1 but these are trainable by default.\n",
    "\n",
    "See [this notebook](https://colab.research.google.com/github/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/05_04_betaVAE_TFP.ipynb) under the section \"**Define the latent prior**\" for a discussion on the merits of allowing off-diagonal elements on the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indl.model.tfp import LearnableMultivariateNormalDiag  # For prior\n",
    "from indl.model.tfp import make_mvn_prior  # , make_mvn_dist_fn\n",
    "\n",
    "\n",
    "scale_shift = np.log(np.exp(1) - 1).astype(np.float32)\n",
    "\n",
    "\n",
    "class StaticEncoder(AutoShapeMixin, tf.keras.Model):\n",
    "    def __init__(self, units=64, latent_size=32, dropout_rate=DROPOUT_RATE, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        # Model layers parameterizations do not depend on input shape so we can initialize\n",
    "        #  them here instead of .build()\n",
    "        self.dropout = DropoutAutoShape(dropout_rate)\n",
    "        # input --> bidirectional GRU --> loc & scale --> MVN distribution\n",
    "        self.static_latent_rnn = BidirectionalAutoShape(\n",
    "            GRUAutoShape(self.units, return_sequences=False),\n",
    "            merge_mode=\"concat\", name=\"static_latent_rnn\")\n",
    "        self.static_latent_loc = DenseAutoShape(self.latent_size, name=\"static_latent_loc\")\n",
    "        if STATIC_LATENT_OFF_DIAG:\n",
    "            self.static_latent_scale = DenseAutoShape(\n",
    "                tfpl.MultivariateNormalTriL.params_size(self.latent_size) - self.latent_size,\n",
    "                name=\"static_latent_scale\")\n",
    "            self.shift_scale = tfp.bijectors.FillScaleTriL()\n",
    "            self.static_latent_posterior = DistLambdaAutoShape(\n",
    "                make_distribution_fn=lambda t: tfd.MultivariateNormalTriL(loc=t[0], scale_tril=t[1]),\n",
    "#                 convert_to_tensor_fn=lambda s: s.sample(n_samples),\n",
    "                name=\"static_latent_posterior\")\n",
    "        else:\n",
    "            self.static_latent_scale = DenseAutoShape(\n",
    "                tfpl.IndependentNormal.params_size(self.latent_size) - self.latent_size,\n",
    "                name=\"static_latent_scale\")\n",
    "            self.shift_scale = lambda x: tf.math.softplus(x + scale_shift) + 1e-5\n",
    "            self.static_latent_posterior = DistLambdaAutoShape(\n",
    "                make_distribution_fn=lambda t: tfd.MultivariateNormalDiag(loc=t[0], scale_diag=t[1]),\n",
    "#                 convert_to_tensor_fn=lambda s: s.sample(n_samples),\n",
    "                name=\"static_latent_posterior\")\n",
    "            \n",
    "        # Define the static prior\n",
    "        #if STATIC_PRIOR_OFF_DIAG: self.prior = make_mvn_prior(latent_size, trainable=False)\n",
    "        # TODO: prior variance constant kappa=0.1\n",
    "        self.static_prior_factory = LearnableMultivariateNormalDiag(self.latent_size)\n",
    "        self.static_prior_factory.build(input_shape=(0,))\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        _inputs = self.dropout(inputs, training=training)\n",
    "        _hidden_state = self.static_latent_rnn(inputs)\n",
    "        _loc = self.static_latent_loc(_hidden_state)\n",
    "        _scale = self.static_latent_scale(_loc)\n",
    "        _shifted_scale = self.shift_scale(_scale)\n",
    "        _q_f = self.static_latent_posterior([_loc, _shifted_scale])\n",
    "        return _q_f   \n",
    "    \n",
    "K.clear_session()\n",
    "\n",
    "static_encoder = StaticEncoder(units=N_HIDDEN_STATIC, latent_size=LATENT_SIZE_STATIC)\n",
    "\n",
    "features_shape = (BATCH_SIZE,) + (read_in.output_shape[1:] if USE_READIN else input_shape[1:])\n",
    "print(f\"Input shape: {(None,) + features_shape[1:]}\")\n",
    "dummy_latent = static_encoder(tf.random.uniform(features_shape))\n",
    "static_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Encoder ($z_t$)\n",
    "\n",
    "Input features are transformed through (1) a bidirectional LSTM (`return_sequences=True`), (2) then RNN, and (3) a pair of affines to yield the parameters of the dynamic posterior latent distribution:\n",
    "\n",
    "$q(z_t | x_{1:T})$\n",
    "\n",
    "This is a multivariate normal distribution **at each timestep**, conditioned on features from $x_t$ **and optionally concatenated with static latent factors $f$** in the full not-factorized model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compared to LFADS\n",
    "\n",
    "The [LFADS model](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6380887/pdf/nihms-1500948.pdf) 'initial condition' encoder is similar to this model's StaticEncoder.\n",
    "The LFADS model also has an 'input controller' module, whereas here we have a DynamicEncoder. They are similar in some respects, but also different.\n",
    "\n",
    "We have a diagram that outlines LFADS architecture as well as the present model, highlighting the differences, found in this study folder `/Output/Figures/DEAE_vs_LFADS.svg`.\n",
    "\n",
    "* [LFADS source in tensorflow](https://github.com/tensorflow/models/tree/master/research/lfads)\n",
    "* [LFADS in JAX](https://github.com/google-research/computation-thru-dynamics/tree/master/lfads_tutorial)\n",
    "* [hierarchical LFADS in pytorch](https://github.com/lyprince/hierarchical_lfads)\n",
    "\n",
    "Other differences:\n",
    "\n",
    "* LFADS uses in-cell value clipping in the bidirectional GRU\n",
    "* LFADS' l2-regularization coefficient is on a scheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = \\hat{w} x$$, where $$\\hat{w}_ij = w_ij / |w_{i:}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dynamic Encoder - Factorized\n",
    "\n",
    "The full factorized encoder model is thus:\n",
    "$$q(z_{1:T}, f | x_{1:T}) = q(f | x_{1:T}) \\prod_{t=1}^T q(z_t | x_t)$$\n",
    "\n",
    "Model loss will include the KL divergence between dynamic latent posterior distribution and the prior distribution; the prior is a multivariate normal diagonal with the same shape as the dynamic posterior -- i.e. one multivariate (LATENT_SIZE_DYNAMIC) distribution per timestep (n_timesteps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indl.model.tfp import LearnableMultivariateNormalDiagCell  # For prior\n",
    "\n",
    "\n",
    "class DynamicEncoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Probabilistic encoder for the time-variant latent variable `z_t`.\n",
    "\n",
    "    The conditional distribution `q(z_t | x_t)` is a multivariate normal\n",
    "    distribution on `R^{latent_size}` at each timestep `t`, conditioned on\n",
    "    a representation of `x_t` (optionally processed from ReadIn).\n",
    "    The parameters are computed by a one-hidden layer neural net.\n",
    "\n",
    "    In this formulation, we posit that the dynamic latent variable `z_t`\n",
    "    is independent of static latent variable `f`.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size=16, latent_size=4, factorized=True,\n",
    "                 l2_reg=L2_REG, name=\"dynamic_encoder\"):\n",
    "        super().__init__(name=name)\n",
    "        self.hidden_size = hidden_size  # Number of units hidden layer and in dynamic_prior_cell\n",
    "        self.latent_size = latent_size  # Dimensionality of latent posterior\n",
    "        self.factorized = factorized\n",
    "        # The dynamic prior - an LSTMCell with learnable params, and learnable Dense layers\n",
    "        #  to generate a MVNDiag for each sequence timestep.\n",
    "        self.dynamic_prior_cell = LearnableMultivariateNormalDiagCell(self.hidden_size, self.latent_size,\n",
    "                                                                      cell_type='gru')\n",
    "        if self.factorized:\n",
    "            self.hidden_layer = DenseAutoShape(self.hidden_size, activation=tf.nn.leaky_relu,\n",
    "                                               name=\"dyn_hidden\")\n",
    "            self.dynamic_latent_rnn1 = self.dynamic_latent_rnn2 = None\n",
    "        else:\n",
    "            self.hidden_layer = None\n",
    "            self.dynamic_latent_rnn1 = BidirectionalAutoShape(\n",
    "                GRUAutoShape(self.hidden_size, return_sequences=True,\n",
    "                             recurrent_regularizer=tf.keras.regularizers.l2(l=l2_reg)),\n",
    "                merge_mode=\"sum\", name=\"dyn_hidden1\")\n",
    "            self.dynamic_latent_rnn2 = tfkl.GRU(self.hidden_size, return_sequences=True,\n",
    "                                                recurrent_regularizer=tf.keras.regularizers.l2(l=l2_reg),\n",
    "                                                name=\"dyn_hidden2\")\n",
    "            # can't use GRUAutoShape here because mismatch between input_spec being list / single item.\n",
    "        \n",
    "        self.loc = DenseAutoShape(self.latent_size, name=\"dyn_loc\")\n",
    "        self.unxf_scale = DenseAutoShape(self.latent_size, name=\"dyn_scale\")\n",
    "        # if DYNAMIC_LATENT_OFF_DIAG: ??? else:\n",
    "        self.q_z_layer = DistLambdaAutoShape(\n",
    "            make_distribution_fn=lambda t: tfd.MultivariateNormalDiag(loc=t[0], scale_diag=t[1]),\n",
    "#             convert_to_tensor_fn=lambda s: s.sample(n_samples),\n",
    "            name=\"q_z\"\n",
    "        )\n",
    "        \n",
    "    def build(self, input_shapes):\n",
    "        static_shape, features_shape = input_shapes\n",
    "        self.n_times = features_shape[-2]\n",
    "        # We can't .build our prior because its .call requires 2 inputs (sample, state)\n",
    "        # so instead we call the cell with its zero-state, effectively forcing it to build.\n",
    "        sample_batch_shape = (1,) + features_shape[1:-2]\n",
    "        sample0, state0 = self.dynamic_prior_cell.zero_state(sample_batch_shape)\n",
    "        self.dynamic_prior_cell(sample0, state0)\n",
    "#         super().build(input_shapes)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        static_sample, features = inputs\n",
    "        if self.factorized:\n",
    "            _hidden = self.hidden_layer(features)\n",
    "        else:\n",
    "            # We explicitly broadcast `x` and `f` to the same shape other than the final\n",
    "            # dimension, because `tf.concat` can't automatically do this. This will\n",
    "            # entail adding a `timesteps` dimension to `f` to give the shape `(...,\n",
    "            # batch, timesteps, latent)`, and then broadcasting the sample shapes of\n",
    "            # both tensors to the same shape.\n",
    "            timesteps = tf.shape(input=features)[-2]\n",
    "            static_sample = static_sample[..., tf.newaxis, :] + tf.zeros([timesteps, 1])\n",
    "            sample_shape_static = tf.shape(input=static_sample)[:-3]\n",
    "            sample_shape_features = tf.shape(input=features)[:-3]\n",
    "            broadcast_shape_features = tf.concat((sample_shape_static, [1, 1, 1]), 0)\n",
    "            broadcast_shape_static = tf.concat((sample_shape_features, [1, 1, 1]), 0)\n",
    "            features = features + tf.zeros(broadcast_shape_features)\n",
    "            static_sample = static_sample + tf.zeros(broadcast_shape_static)\n",
    "            # `combined` will have shape (..., batch, timesteps, hidden+latent).\n",
    "            combined = tf.concat((features, static_sample), axis=-1)\n",
    "            collapsed_shape = tf.concat(([-1], tf.shape(input=combined)[-2:]), axis=0)\n",
    "            combined = tf.reshape(combined, collapsed_shape)\n",
    "            _hidden = self.dynamic_latent_rnn1(combined)\n",
    "            _hidden = self.dynamic_latent_rnn2(_hidden)\n",
    "            expanded_shape = tf.concat((tf.shape(input=combined)[:-2],\n",
    "                                        tf.shape(input=_hidden)[1:]), axis=0)\n",
    "            _hidden = tf.reshape(_hidden, expanded_shape)  # (sample, batch, T, hidden_size)\n",
    "        loc = self.loc(_hidden)\n",
    "        unxf_scale = self.unxf_scale(_hidden)\n",
    "        scale = tf.math.softplus(unxf_scale + scale_shift) + 1e-5\n",
    "        q_z = self.q_z_layer([loc, scale])\n",
    "        return q_z\n",
    "    \n",
    "    def call_full(self, inputs):\n",
    "        raise NotImplementedError(\"Just keeping this code here for later reference. Ignore for now.\")\n",
    "        # _features needs to be repeated NUM_SAMPLES on a new samples axis at axis=0.\n",
    "        _x2 = _features[tf.newaxis, ...] + tf.zeros([NUM_SAMPLES, 1, 1, 1])\n",
    "        # Concatenate _x2 (features) and _static_sample\n",
    "        _x2 = tfkl.Concatenate()([_x2, _static_sample])  # (samples, batch, timesteps, feat_dim+latent_static)\n",
    "        # Collapse samples + batch dims  -- required by LSTM\n",
    "        _x2 = tf.reshape(_x2, [-1] + _x2.shape.as_list()[-2:])  # (samples*batch, T, feat+lat_stat)\n",
    "        # Run _x2 through bidirectional lstm then a simple RNN,\n",
    "        # then use output to parameterize distribution over latent variable z_t.\n",
    "        _x2 = tfkl.Bidirectional(\n",
    "            tfkl.GRU(self.hidden_size, return_sequences=True),\n",
    "            merge_mode=\"sum\")(_x2)\n",
    "        _x2 = tfkl.GRU(self.hidden_size, return_sequences=True)(_x2)\n",
    "        # Restore samples dim?\n",
    "        _x2 = tf.reshape(_x2, [NUM_SAMPLES, -1, n_timesteps, self.hidden_size])\n",
    "    \n",
    "    def sample_dynamic_prior(self, timesteps, samples=1, batches=1, fixed=False):\n",
    "        \"\"\"\n",
    "        Samples from self.dynamic_prior_cell `timesteps` times.\n",
    "        On each step, the previous (sample, state) is fed back into the cell\n",
    "        (zero_state used for 0th step).\n",
    "        \n",
    "        The cell returns a multivariate normal diagonal distribution for each timestep.\n",
    "        We collect each timestep-dist's params (loc and scale), then use them to create\n",
    "        the return value: a single MVN diag dist that has a dimension for timesteps.\n",
    "        \n",
    "        The cell returns a full dist for each timestep so that we can 'sample' it.\n",
    "        If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent\n",
    "        to doing a generative RNN (init state = zeros, return_sequences=True) then passing\n",
    "        those values through a pair of Dense layers to parameterize a single MVNDiag.\n",
    "        \n",
    "        :param timesteps: Number of timesteps to sample for each sequence.\n",
    "        :param samples: Number of samples to draw from the latent distribution.\n",
    "        :param batches: Number of sequences to sample.\n",
    "        :param fixed: Boolean for whether or not to share the same random\n",
    "            sample across all sequences in batch.\n",
    "        \"\"\"\n",
    "        if fixed:\n",
    "            sample_batch_size = 1\n",
    "        else:\n",
    "            sample_batch_size = batches\n",
    "\n",
    "        sample, state = self.dynamic_prior_cell.zero_state([samples, sample_batch_size])\n",
    "        locs = []\n",
    "        scale_diags = []\n",
    "        sample_list = []\n",
    "        for _ in range(timesteps):\n",
    "            dist, state = self.dynamic_prior_cell(sample, state)\n",
    "            sample = dist.sample()\n",
    "            locs.append(dist.parameters[\"loc\"])\n",
    "            scale_diags.append(dist.parameters[\"scale_diag\"])\n",
    "            sample_list.append(sample)\n",
    "\n",
    "        sample = tf.stack(sample_list, axis=2)\n",
    "        loc = tf.stack(locs, axis=2)\n",
    "        scale_diag = tf.stack(scale_diags, axis=2)\n",
    "\n",
    "        if fixed:  # tile along the batch axis\n",
    "            sample = sample + tf.zeros([batches, 1, 1])\n",
    "\n",
    "        return sample, tfd.MultivariateNormalDiag(loc=loc, scale_diag=scale_diag)\n",
    "        # TODO: Move 1 of the batch dims into event dims\n",
    "    \n",
    "\n",
    "K.clear_session()\n",
    "dynamic_encoder = DynamicEncoder(hidden_size=N_HIDDEN_DYNAMIC, latent_size=LATENT_SIZE_DYNAMIC,\n",
    "                                 factorized=DYNAMIC_GRAPH == 'factorized')\n",
    "\n",
    "dummy_static = tf.random.uniform((BATCH_SIZE, LATENT_SIZE_STATIC))  # or None if factorized\n",
    "dummy_features_shape = (BATCH_SIZE,) + (read_in.output_shape[1:] if USE_READIN else input_shape[1:])\n",
    "dummy_features = tf.random.uniform(features_shape)\n",
    "dynamic_encoder((dummy_static, dummy_features))\n",
    "dynamic_encoder.summary()\n",
    "\n",
    "\n",
    "dyn_prior_samp, dyn_prior = dynamic_encoder.sample_dynamic_prior(\n",
    "    dummy_features.shape[-2], samples=1, batches=1)\n",
    "print(\"dynamic prior: \", dyn_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_prior_cell = LearnableMultivariateNormalDiagCell(3, 4, cell_type='gru')\n",
    "sample, state = dynamic_prior_cell.zero_state([1, 1])\n",
    "locs = []\n",
    "scale_diags = []\n",
    "sample_list = []\n",
    "for _ in range(161):\n",
    "    dist, state = dynamic_prior_cell(sample, state)\n",
    "    sample = dist.sample()\n",
    "    locs.append(dist.parameters[\"loc\"])\n",
    "    scale_diags.append(dist.parameters[\"scale_diag\"])\n",
    "    sample_list.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.stack(sample_list, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latents to Factors\n",
    "\n",
    "From latent distributions (f and z_t) to factors.\n",
    "Both latent distributions are assumed sampled before inputting samples to this module.\n",
    "The static sample (f) goes through an affine then gives the initial condition for a generative RNN; the dynamic sample (z_t) provides the input to the generative RNN. z_t is generally much lower dimension than f.\n",
    "\n",
    "The RNN evolves (feeding its own output to its input on the next step). In the end it returns the sequence of states. The states are then transformed through a linear layer to give latent factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indl.model.recurrent import GenerativeRNN\n",
    "\n",
    "\n",
    "class GenerateFactors(AutoShapeMixin, tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Probabilistic decoder for `p(x_t | z_t, f)`.\n",
    "\n",
    "    The decoder generates a sequence of multi-sensor frames `x_{1:T}` from\n",
    "    dynamic and static latent variables `z_{1:T}` and `f`, respectively,\n",
    "    for timesteps `1:T`.\n",
    "    \"\"\"\n",
    "    def __init__(self, factors=8, units=64, combine_latents='state_and_input',\n",
    "                 dropout_rate=DROPOUT_RATE, l2_reg=L2_REG, **kwargs):\n",
    "        \"\"\"\n",
    "        :param combine_latents: 'tile_concat' or 'state_and_input'.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        assert combine_latents in ['state_and_input', 'tile_concat']\n",
    "        self.combine_latents = combine_latents\n",
    "        if self.combine_latents == 'state_and_input':\n",
    "            self.static_to_state0 = DenseAutoShape(units, name=\"static_to_state0\")\n",
    "        else:\n",
    "            self.static_to_state0 = None\n",
    "        #self.gen_rnn = GenerativeRNN(GRUCellAutoShape(units, use_bias=False),\n",
    "        #                             timesteps=timesteps,\n",
    "        #                             return_sequences=True,\n",
    "        #                             name=\"gen_rnn\")\n",
    "        self.gen_rnn = tfkl.GRU(units, return_sequences=True,\n",
    "                                recurrent_regularizer=tf.keras.regularizers.l2(l=l2_reg),\n",
    "                                name=\"gen_rnn\")\n",
    "        self.dropout = DropoutAutoShape(dropout_rate)\n",
    "#         self.gen_factors = WeightNormAutoShape(\n",
    "#             tfkl.Dense(factors), name=\"gen_factors_normed\")\n",
    "        self.gen_factors = DenseAutoShape(factors, name=\"gen_factors\")\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        inputs is a tuple (static, dynamic)\n",
    "        If dynamic is not used, then pass in tf.zeros, with dims (batch_size, timesteps, 1)\n",
    "        \"\"\"\n",
    "        static, dynamic = inputs\n",
    "        if self.combine_latents == 'state_and_input':\n",
    "            # Option 1 - static is init state, dynamic is inputs\n",
    "            _init_state = self.static_to_state0(static)\n",
    "            _gen_seq = self.gen_rnn(inputs=dynamic, initial_state=_init_state)\n",
    "        else:  # tile_concat\n",
    "            # Option 2 - tile static, concat with dynamic, feed both as inputs to GRU\n",
    "            dyn_steps = tf.shape(input=dynamic)[-2]\n",
    "            static = static[..., tf.newaxis, :] + tf.zeros([dyn_steps, 1])\n",
    "            latents = tf.concat([dynamic, static], axis=-1)\n",
    "            _gen_seq = self.gen_rnn(inputs=latents, initial_state=None)\n",
    "        _gen_seq = self.dropout(_gen_seq, training=training)\n",
    "        _factors = self.gen_factors(_gen_seq)\n",
    "        return _factors\n",
    "        \n",
    "\n",
    "K.clear_session()\n",
    "factor_times = n_times // read_in.get_layer(\"temporal_smoothing\").pool_size[0] if USE_READIN else n_times\n",
    "n_factors = N_FACTORS if not USE_READIN else\\\n",
    "    read_in.get_layer(\"temporal_filter\").filters * read_in.get_layer(\"spatial_filter\").depth_multiplier\n",
    "\n",
    "gen_fac = GenerateFactors(factors=n_factors, units=N_HIDDEN_GEN,\n",
    "                          combine_latents='state_and_input')\n",
    "\n",
    "dummy_static = tf.random.uniform((BATCH_SIZE, LATENT_SIZE_STATIC))\n",
    "if DYNAMIC_GRAPH != 'none':\n",
    "    dummy_dynamic = tf.random.uniform((BATCH_SIZE, factor_times, LATENT_SIZE_DYNAMIC))\n",
    "else:\n",
    "    dummy_dynamic = tf.random.uniform((BATCH_SIZE, factor_times, 1))\n",
    "generated_factors = gen_fac((dummy_static, dummy_dynamic))\n",
    "gen_fac.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read-Out: Factors to Reconstructed Features\n",
    "\n",
    "Optional. To be used when ReadIn is used.\n",
    "\n",
    "TODO: Currently broken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadOut(input_shape, out_time, out_space,\n",
    "            n_kernels=6, kern_length=25, pooling=5, factors=10, units=32, name=\"readout\"):\n",
    "    \n",
    "    n_samps = n_times * pooling - kern_length + 1\n",
    "    req_padding = max(0, out_time - n_samps)\n",
    "    req_padding = (int(math.ceil(req_padding / 2)), req_padding // 2)  # left, right\n",
    "    return tf.keras.Sequential([\n",
    "        tfkl.Input(shape=input_shape),\n",
    "        tfkl.Reshape(input_shape[:-1] + (1,) + input_shape[-1:]),\n",
    "        tfkl.UpSampling2D(size=(1, out_space)),\n",
    "        tfkl.DepthwiseConv2D(kernel_size=(1, out_space), padding='same', depth_multiplier=1),\n",
    "        tfkl.UpSampling2D(size=(pooling, 1)),\n",
    "        tfkl.SeparableConv2D(n_kernels, (kern_length, 1)),\n",
    "        tfkl.ZeroPadding2D(padding=(req_padding, 0)),\n",
    "        tfkl.Conv2D(1, (out_time, 1), padding='same'),\n",
    "        tfkl.Lambda(lambda x: x[..., 0])],\n",
    "        name=name)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "read_out = ReadOut((factor_times, n_factors), input_shape[-2], input_shape[-1])\n",
    "read_out.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct Spike Trains\n",
    "\n",
    "From factors or reconstructed features to rates.\n",
    "The rates then parameterize log_rates of poisson distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutDist(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Simple inputs --> Dense --> Poisson distribution\n",
    "    \"\"\"\n",
    "    # Because the output is a tfd object and not a Tensor,\n",
    "    # we cannot use tf.keras.Sequential(list_of_layers) nor tf.keras.Model(inputs, outputs).\n",
    "    # The output must be a distribution so we can use logprob for cost.\n",
    "    \n",
    "    def __init__(self, out_space,\n",
    "                 name='outdist', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.out_space = out_space\n",
    "        self.to_log_rates = DenseAutoShape(self.out_space, name=\"log_rate\")\n",
    "        self.q_z_layer = DistLambdaAutoShape(\n",
    "            make_distribution_fn=lambda t: tfd.Poisson(rate=tf.exp(t)),\n",
    "            name=\"p_out\"\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Generate output distribution\n",
    "        log_rates = self.to_log_rates(inputs)\n",
    "        p_out = self.q_z_layer(log_rates)\n",
    "        \n",
    "        # Move the time dimension from batch to event.\n",
    "        p_out = tfd.Independent(p_out, reinterpreted_batch_ndims=2)\n",
    "        \n",
    "        return p_out\n",
    "    \n",
    "K.clear_session()\n",
    "factor_times = n_times // read_in.get_layer(\"temporal_smoothing\").pool_size[0] if USE_READIN else n_times\n",
    "n_factors = N_FACTORS if not USE_READIN else\\\n",
    "    read_in.get_layer(\"temporal_filter\").filters * read_in.get_layer(\"spatial_filter\").depth_multiplier\n",
    "out_dist = OutDist(n_sensors)\n",
    "tmp_fac = tf.random.uniform((BATCH_SIZE, factor_times, n_factors))\n",
    "tmp_out = out_dist(tmp_fac)\n",
    "out_dist.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 readin_kernels=6 if USE_READIN else 0, readin_kern_length=25,\n",
    "                 readin_depth_multiplier=2, readin_pooling=5,\n",
    "                 static_units=N_HIDDEN_STATIC, static_latent_size=LATENT_SIZE_STATIC,\n",
    "                 dynamic_graph=DYNAMIC_GRAPH,\n",
    "                 dynamic_units=N_HIDDEN_DYNAMIC, dynamic_latent_size=LATENT_SIZE_DYNAMIC,\n",
    "                 gen_units=N_HIDDEN_GEN, gen_combine_latents='state_and_input',\n",
    "                 n_factors=N_FACTORS,\n",
    "                 dropout_rate=DROPOUT_RATE, l2_reg=L2_REG,\n",
    "                 name='autoencoder', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.readin_kernels = readin_kernels\n",
    "        self.readin_kern_length = readin_kern_length\n",
    "        self.readin_depth_multiplier = readin_depth_multiplier\n",
    "        self.readin_pooling = readin_pooling\n",
    "        \n",
    "        self.input_dropout = DropoutAutoShape(dropout_rate)\n",
    "        self.static_encoder = StaticEncoder(units=static_units,\n",
    "                                            latent_size=static_latent_size,\n",
    "                                            dropout_rate=dropout_rate)\n",
    "        self.dynamic_graph = dynamic_graph\n",
    "        if self.dynamic_graph in ['factorized', 'full']:\n",
    "            self.dynamic_encoder = DynamicEncoder(hidden_size=dynamic_units,\n",
    "                                                  latent_size=dynamic_latent_size,\n",
    "                                                  factorized=dynamic_graph == 'factorized',\n",
    "                                                  l2_reg=l2_reg)\n",
    "        else:\n",
    "            self.dynamic_encoder = None\n",
    "            \n",
    "        self.gen_units = gen_units\n",
    "        self.n_factors = self.readin_n_kernels * self.readin_depth_multiplier if USE_READIN else n_factors\n",
    "        self.gen_combine_latents = gen_combine_latents\n",
    "        self.gen_facs = GenerateFactors(factors=self.n_factors, units=self.gen_units,\n",
    "                                        combine_latents=self.gen_combine_latents,\n",
    "                                        dropout_rate=dropout_rate, l2_reg=l2_reg)\n",
    "        \n",
    "        if self.readin_kernels > 0:\n",
    "            # TODO: Currently broken\n",
    "            self.read_out = ReadOut(n_kernels=self.readin_kernels,\n",
    "                                    kern_length=self.readin_kern_length,\n",
    "                                    pooling=self.readin_pooling)\n",
    "            \n",
    "    def build(self, input_shape):\n",
    "        n_times, n_sensors = input_shape[-2:]\n",
    "        \n",
    "        if self.readin_kernels > 0:\n",
    "            self.readin = ReadIn(input_shape,\n",
    "                                 n_kernels=self.readin_kernels,\n",
    "                                 pooling=self.readin_pooling,\n",
    "                                 depth_multiplier=self.readin_depth_multiplier)\n",
    "            \n",
    "        self.out_dist = OutDist(n_sensors)\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, inputs, return_intermediates=False, training=None):\n",
    "        inputs = self.input_dropout(inputs, training=training)\n",
    "        # TODO: randomly set 30% of inputs to 0. Save the mask.\n",
    "        \n",
    "        features = self.readin(inputs) if self.readin_kernels > 0 else inputs\n",
    "        q_f = self.static_encoder(features, training=training)\n",
    "        f_sample = tf.convert_to_tensor(q_f)\n",
    "        if self.dynamic_graph != 'none':\n",
    "            q_z = self.dynamic_encoder([f_sample, features])\n",
    "            z_sample = tf.convert_to_tensor(q_z)  # Might create sample dim\n",
    "        else:\n",
    "            q_z = None\n",
    "            dummy_dynamic_sample_shape = f_sample.shape[:-1] + (features.shape[-2], 1)\n",
    "            z_sample = tf.zeros(dummy_dynamic_sample_shape)\n",
    "        facs = self.gen_facs((f_sample, z_sample), training=training)\n",
    "        log_rates = self.read_out(facs) if self.readin_kernels > 0 else facs\n",
    "        p_full = self.out_dist(log_rates)\n",
    "        \n",
    "        if not return_intermediates:\n",
    "            return p_full\n",
    "        return p_full, features, q_f, q_z, facs, log_rates, p_full\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        print(data)\n",
    "        inputs, preds = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            # TODO: coordinated dropout mask cd_mask on 30% of samples; set to 0\n",
    "            # Probably unnecessary while generated rates are so smooth.\n",
    "            \n",
    "            p_full, features, q_f, q_z, facs, log_rates, p_full = self(inputs,\n",
    "                                                                       return_intermediates=True,\n",
    "                                                                       training=True)\n",
    "            \n",
    "            # TODO: Do not allow BPTT through ~cd_mask samples.\n",
    "\n",
    "            # Reconstruction log-likelihood: p(output|input).\n",
    "            recon_post_log_prob = p_full.log_prob(inputs)\n",
    "\n",
    "            # Not necessary to sum over time axis because event shape is (time, space)\n",
    "            # recon_post_log_prob = tf.reduce_sum(recon_post_log_prob, axis=-1)\n",
    "\n",
    "            # KL Divergence - analytical\n",
    "            # Static\n",
    "            static_prior = self.static_encoder.static_prior_factory()\n",
    "            stat_kl = tfd.kl_divergence(q_f, static_prior)\n",
    "\n",
    "            # Dynamic\n",
    "            if self.dynamic_graph != 'none':\n",
    "                _, dynamic_prior = self.dynamic_encoder.sample_dynamic_prior(\n",
    "                    inputs.shape[-2], samples=1, batches=1\n",
    "                )\n",
    "                dyn_kl = tfd.kl_divergence(q_z, dynamic_prior)\n",
    "                # TODO: Check if necessary (maybe q_z needs batch dim reinterp)\n",
    "                dyn_kl = tf.reduce_mean(dyn_kl, axis=-1)\n",
    "                dyn_kl = tf.squeeze(dyn_kl)\n",
    "            else:\n",
    "                dyn_kl = tf.zeros(stat_kl.shape)\n",
    "\n",
    "            elbo = recon_post_log_prob - kl_beta * (stat_kl + dyn_kl)\n",
    "            elbo = tf.reduce_mean(input_tensor=elbo)\n",
    "            l2_loss = tf.reduce_sum(self.losses)\n",
    "            loss = -elbo + l2_loss\n",
    "            \n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # clip gradients\n",
    "#         gradients, _ = tf.clip_by_global_norm(gradients, MAX_GRAD_NORM)\n",
    "        \n",
    "        # TODO: more l2?\n",
    "        #  -with scheduler!\n",
    "        \n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Return dictionary of metrics:\n",
    "        return {\n",
    "            'neg.log.like': tf.reduce_mean(-recon_post_log_prob),\n",
    "            'kl_beta': kl_beta,\n",
    "            'static KL': tf.reduce_mean(stat_kl),\n",
    "            'dynamic KL': tf.reduce_mean(dyn_kl),\n",
    "            'l2 loss': l2_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "K.set_floatx('float32')\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "ae_model = AutoEncoder()\n",
    "dummy_input = tf.random.uniform((BATCH_SIZE,) + input_shape[1:])\n",
    "print(f\"dummy_input.shape: {dummy_input.shape}\")\n",
    "dummy_output = ae_model(dummy_input)\n",
    "print(f\"dummy_output: {dummy_output}\")\n",
    "ae_model.static_encoder.summary()\n",
    "if ae_model.dynamic_graph != 'none':\n",
    "    ae_model.dynamic_encoder.summary()\n",
    "ae_model.gen_facs.summary()\n",
    "ae_model.out_dist.summary()\n",
    "ae_model.summary()\n",
    "# Visualize: https://github.com/lutzroeder/netron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Beta Cycling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "kl_beta = K.variable(value=0.0)\n",
    "kl_beta._trainable = False  # It isn't trained. We set it explicitly with the callback.\n",
    "\n",
    "def kl_beta_update(epoch_ix, N_epochs=N_EPOCHS, M_cycles=3, R_increasing=0.8):\n",
    "    T = N_epochs // M_cycles\n",
    "    tau = (epoch_ix % T) / T\n",
    "    new_beta_value = tf.minimum(1.0, tau/R_increasing)\n",
    "#     new_beta_value = new_beta_value * BATCH_SIZE  #  / N_TRIALS\n",
    "    new_beta_value = 1.0 * new_beta_value\n",
    "    K.set_value(kl_beta, new_beta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "https://github.com/optuna/optuna/blob/master/examples/keras_simple.py\n",
    "\n",
    "https://neptune.ai/blog/optuna-vs-hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "CLASSIFIER_OBJECTIVE = True\n",
    "TUNE_STATIC = True\n",
    "TUNE_DYNAMIC = True\n",
    "TUNE_REGU = False\n",
    "TUNE_LR = False\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "    if TUNE_STATIC:\n",
    "        static_units = trial.suggest_int(\"static_units\", 4, 256, log=True)  # RNN cells in static encoder: 128\n",
    "        static_latent_size = trial.suggest_int(\"static_latent_size\", 2, 128, log=True) # f | g_0: 64\n",
    "    else:\n",
    "        static_units = 128\n",
    "        static_latent_size = 8\n",
    "        \n",
    "    if TUNE_DYNAMIC:\n",
    "        dynamic_graph = 'full'\n",
    "        # dynamic_graph = trial.suggest_categorical(\"dynamic_graph\", ['none', 'factorized', 'full', 'controller'])\n",
    "        dynamic_units = trial.suggest_int(\"dynamic_units\", 2, 32)  # RNN cells in dynamic encoder: 12\n",
    "        dynamic_latent_size = trial.suggest_int(\"dynamic_latent_size\", 2, 8)  # z_t | u_t: 2\n",
    "    else:\n",
    "        dynamic_graph = 'none'\n",
    "        dynamic_units = None\n",
    "        dynamic_latent_size = None\n",
    "\n",
    "    gen_units = trial.suggest_int(\"gen_units\", 8, 128, log=True)  # RNN cells in generator: 256\n",
    "    # gen_combine_latents = trial.suggest_categorical(\"gen_combine_latents\", ['state_and_input', 'tile_concat'])\n",
    "    gen_combine_latents = 'state_and_input'\n",
    "    gen_factors = trial.suggest_int(\"gen_factors\", 4, 32)\n",
    "\n",
    "    if TUNE_REGU:\n",
    "        dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)  # 0.025\n",
    "        l2_reg = trial.suggest_float(\"l2_reg\", 1e-6, 0.1, log=True)  # 2e-5\n",
    "    else:\n",
    "        dropout_rate=0.3\n",
    "        l2_reg=2e-5\n",
    "    \n",
    "    ae_model = AutoEncoder(static_units=static_units, static_latent_size=static_latent_size,\n",
    "                           dynamic_graph=dynamic_graph,\n",
    "                           dynamic_units=dynamic_units, dynamic_latent_size=dynamic_latent_size,\n",
    "                           gen_units=gen_units,\n",
    "                           n_factors=gen_factors,\n",
    "                           dropout_rate=dropout_rate, l2_reg=l2_reg)\n",
    "    return ae_model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    n_epochs = 50\n",
    "    K.clear_session()\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "    model = create_model(trial)\n",
    "    lr = trial.suggest_float(\"adam_learning_rate\", 1e-5, 1e-1, log=True) if TUNE_LR else 2e-3\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr))\n",
    "    print(trial.params)\n",
    "    history = model.fit(ds, epochs=n_epochs,\n",
    "                        verbose=2,\n",
    "                        callbacks=[\n",
    "                            optuna.integration.TFKerasPruningCallback(trial, 'neg.log.like'),\n",
    "                            tf.keras.callbacks.LambdaCallback(on_epoch_begin=lambda epoch, logs:\n",
    "                                                              kl_beta_update(epoch, N_epochs=n_epochs, M_cycles=1))\n",
    "                        ])\n",
    "    if not CLASSIFIER_OBJECTIVE:\n",
    "        return np.min(history.history['neg.log.like'][-n_epochs//5:])\n",
    "    else:\n",
    "        # Collect data\n",
    "        t_vec = ax_info['timestamps']\n",
    "        feat_t_vec = t_vec[model.readin.pooling//2::model.readin.pooling]\\\n",
    "                        if USE_READIN else t_vec\n",
    "        class_ids = np.zeros((0,), dtype=int)\n",
    "        static_latents = np.zeros((0, model.static_encoder.latent_size))\n",
    "        dynamic_latents = np.zeros((0, len(feat_t_vec),\n",
    "                                    model.dynamic_encoder.latent_size if DYNAMIC_GRAPH != 'none' else 1))\n",
    "        for batch in ds:\n",
    "            class_ids = np.hstack((class_ids, np.argmax(batch[1].numpy(), axis=1)))\n",
    "            p_full, features, q_f, q_z, facs, log_rates, p_full = model(batch[0], return_intermediates=True)\n",
    "            static_latents = np.vstack((static_latents, q_f.mean().numpy()))\n",
    "            \n",
    "        clf = make_pipeline(StandardScaler(), LogisticRegressionCV(cv=5, random_state=0, max_iter=5000))\n",
    "        clf.fit(static_latents, class_ids)\n",
    "        return clf.score(static_latents, class_ids)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\" if CLASSIFIER_OBJECTIVE else \"minimize\",\n",
    "                            sampler=optuna.samplers.TPESampler(),\n",
    "                            pruner=optuna.pruners.HyperbandPruner(min_resource=2)\n",
    "                           )\n",
    "study.optimize(objective, n_trials=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "ae_model = AutoEncoder(static_units=148, static_latent_size=24,\n",
    "                       dynamic_graph='full',\n",
    "                       dynamic_units=8, dynamic_latent_size=2,\n",
    "                       gen_units=10,\n",
    "                       n_factors=10,\n",
    "                       dropout_rate=0.3, l2_reg=2e-6)\n",
    "\n",
    "ae_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-3))\n",
    "history = ae_model.fit(ds, epochs=N_EPOCHS,\n",
    "                       verbose=2,\n",
    "                       callbacks=[\n",
    "                           tf.keras.callbacks.LambdaCallback(on_epoch_begin=lambda epoch,\n",
    "                                                             logs: kl_beta_update(epoch, N_epochs=N_EPOCHS))\n",
    "                           # https://keras.io/api/callbacks/lambda_callback/\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# print(plt.style.available)\n",
    "# plt.style.use('fivethirtyeight')\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(history.history['neg.log.like'], linewidth=3, color='C0', label='AE loss')\n",
    "ax1.set_ylabel('Recon. Neg.Log.Likelihoood', color='C0')\n",
    "ax1.set_ylim([800, 2000])\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.tick_params(axis='y', labelcolor='C0')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(history.history['static KL'], color='C1', label='static KL')\n",
    "ax2.plot(history.history['dynamic KL'], color='C2', label='dynamic KL')\n",
    "ax2.set_ylabel('KL Divergence', color='C1')\n",
    "ax2.set_ylim([0, 20])\n",
    "ax2.tick_params(axis='y', labelcolor='C1')\n",
    "ax2.legend(facecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Latents\n",
    "\n",
    "* Visualize priors to confirm their locations were non-zero indicating they learned.\n",
    "* Calculate 2-comp t-SNE on static latents\n",
    "* Plot 1 trial: input (spike counts), static latents in t-SNE space, dynamic latents, generated factors, recon rates.\n",
    "* Plot all trials, colour-coded by target: static latents in t-SNE space, dynamic latents as 2-D trajectories; plot per-target averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a colour code cycler e.g. 'C0', 'C1', etc.\n",
    "# from itertools import cycle\n",
    "# colour_codes = map('C{}'.format, cycle(range(10)))\n",
    "# class_colors = np.array([next(colour_codes) for _ in range(10)])\n",
    "class_colors = np.array(['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w'])\n",
    "turbo_cmap = plt.cm.get_cmap('turbo')\n",
    "c_categ = turbo_cmap(np.linspace(0, 1, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data\n",
    "t_vec = ax_info['timestamps']\n",
    "feat_t_vec = t_vec[ae_model.readin.pooling//2::ae_model.readin.pooling]\\\n",
    "                if USE_READIN else t_vec\n",
    "class_ids = np.zeros((0,), dtype=int)\n",
    "static_latents = np.zeros((0, ae_model.static_encoder.latent_size))\n",
    "dynamic_latents = np.zeros((0, len(feat_t_vec),\n",
    "                            ae_model.dynamic_encoder.latent_size if DYNAMIC_GRAPH != 'none' else 1))\n",
    "for batch in ds:\n",
    "    class_ids = np.hstack((class_ids, np.argmax(batch[1].numpy(), axis=1)))\n",
    "    p_full, features, q_f, q_z, facs, log_rates, p_full = ae_model(batch[0], return_intermediates=True)\n",
    "    static_latents = np.vstack((static_latents, q_f.mean().numpy()))\n",
    "    if DYNAMIC_GRAPH != 'none':\n",
    "        dynamic_latents = np.vstack((dynamic_latents, q_z.mean().numpy()))\n",
    "static_prior = ae_model.static_encoder.static_prior_factory().mean().numpy()\n",
    "if DYNAMIC_GRAPH != 'none':\n",
    "    dynamic_prior_samp, dynamic_prior_dist = ae_model.dynamic_encoder.sample_dynamic_prior(\n",
    "        len(feat_t_vec), samples=1, batches=1)\n",
    "    dynamic_prior = dynamic_prior_dist.mean().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "TEST_PERPLEXITY = 30  # 10, 30\n",
    "\n",
    "# Precede TSNE with a PCA.\n",
    "pca = PCA(n_components=static_latents.shape[-1])\n",
    "static_latents_pca = pca.fit_transform(static_latents)\n",
    "\n",
    "# Calculate t-SNE\n",
    "tsne_model = TSNE(n_components=2, perplexity=TEST_PERPLEXITY)\n",
    "static_latents_tsne = tsne_model.fit_transform(static_latents_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find least squares solution relating static latents to tsne embedding.\n",
    "#  Use this to identify best latent dims to plot\n",
    "W = np.linalg.lstsq(np.hstack([static_latents, np.ones((len(static_latents), 1))]),\n",
    "                    static_latents_tsne, rcond=None)[0]\n",
    "b = W[-1, :]\n",
    "W = W[:-1, :]\n",
    "important_latent_dims = np.argsort(np.sum(np.abs(W), axis=1))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scatter plot per class\n",
    "plot_range = [-5.0, 5.0]\n",
    "# print(plt.style.available)\n",
    "plt.style.use('dark_background')\n",
    "fig = plt.figure(figsize=[8, 6], tight_layout=True)\n",
    "axes = fig.subplots(2, 2)\n",
    "\n",
    "for pair_ix, dim_pair in enumerate(important_latent_dims[:8].reshape((4, 2))):\n",
    "    row_ix = pair_ix // 2\n",
    "    col_ix = pair_ix % 2\n",
    "    dat = static_latents[:, dim_pair]\n",
    "    plot_lim = int(np.ceil(np.max(np.abs(dat))))\n",
    "    axes[row_ix, col_ix].scatter(dat[:, 0], dat[:, 1],\n",
    "                                 c=c_categ[class_ids])\n",
    "    axes[row_ix, col_ix].scatter(static_prior[dim_pair[0]], static_prior[dim_pair[1]],\n",
    "                                 s=200, c='k', marker='+')\n",
    "#     axes[row_ix, col_ix].set_xlim([-plot_lim, plot_lim])\n",
    "#     axes[row_ix, col_ix].set_ylim([-plot_lim, plot_lim])\n",
    "    axes[row_ix, col_ix].set_xlabel(f\"dim {dim_pair[0]}\")\n",
    "    axes[row_ix, col_ix].set_ylabel(f\"dim {dim_pair[1]}\")\n",
    "#     axes[row_ix, col_ix].set_xticks([-plot_lim, 0, plot_lim])\n",
    "#     axes[row_ix, col_ix].set_yticks([-plot_lim, 0, plot_lim])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DYNAMIC_GRAPH != 'none':\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(feat_t_vec, dynamic_prior + 0.2*np.arange(dynamic_prior.shape[-1]).reshape((1, -1)))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(dynamic_prior[:, 0], dynamic_prior[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch (inputs) p_full, features, q_f, q_z, facs, log_rates, p_full\n",
    "tr_ix = 1  # in batch\n",
    "\n",
    "fig = plt.figure(figsize=[10, 6], tight_layout=True)\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(t_vec, batch[0][tr_ix])\n",
    "plt.title('Binned Spike Counts')\n",
    "#plt.ylim([0, 6])\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "# TODO: better way to represent per-trial static latent? t-sne space?\n",
    "plt.plot(q_f.mean()[tr_ix], '.')\n",
    "plt.title('Static Latent')\n",
    "\n",
    "if DYNAMIC_GRAPH != 'none':\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.plot(feat_t_vec, q_z.mean()[tr_ix])\n",
    "    plt.title('Dynamic Latent')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.plot(feat_t_vec, facs[tr_ix])\n",
    "plt.title('Factors')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(t_vec, p_full.mean()[tr_ix])\n",
    "plt.title('Recon. Rates')\n",
    "#plt.ylim([0, 6])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(x_vals, y_vals, perplexity, title='Model Output'):\n",
    "    plt.scatter(x=x_vals[:, 0], y=x_vals[:, 1], c=c_categ[y_vals])\n",
    "    plt.xlabel('t-SNE D-1')\n",
    "    plt.ylabel('t-SNE D-2')\n",
    "    plt.title(title + ' (Ppx: {})'.format(perplexity))\n",
    "    ax = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 1, 1)\n",
    "plot_tsne(static_latents_tsne, class_ids, TEST_PERPLEXITY, title='Latents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegressionCV(cv=5, random_state=0, \n",
    "                                                           max_iter=4000))\n",
    "clf.fit(static_latents, class_ids)\n",
    "print(clf.score(static_latents, class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rates, Y_class, _ = load_macaque_pfc(data_path, sess_id, x_chunk='spikerates',\n",
    "                                        **{**load_kwargs, 'resample_X': 1})\n",
    "X_rates = X_rates.reshape(X_rates.shape[0], -1)\n",
    "Y_class = Y_class.ravel()\n",
    "clf.fit(X_rates, Y_class)\n",
    "print(clf.score(X_rates, Y_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
