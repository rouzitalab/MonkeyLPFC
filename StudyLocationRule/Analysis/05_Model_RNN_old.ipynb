{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6HwqG-TtNfh6",
    "outputId": "b43a9836-bb95-469f-8622-a4666bb29a01"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "vGnyG0prNfiC",
    "outputId": "11ba9f8f-249f-475b-8f13-f6e13e8905a3"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "try:\n",
    "    # Only on works on Google Colab\n",
    "    from google.colab import files\n",
    "    %tensorflow_version 2.x\n",
    "    os.chdir('..')\n",
    "    \n",
    "    # Configure kaggle if necessary\n",
    "    if not (Path.home() / '.kaggle').is_dir():\n",
    "        uploaded = files.upload()  # Find the kaggle.json file in your ~/.kaggle directory.\n",
    "        if 'kaggle.json' in uploaded.keys():\n",
    "            !mkdir -p ~/.kaggle\n",
    "            !mv kaggle.json ~/.kaggle/\n",
    "            !chmod 600 ~/.kaggle/kaggle.json\n",
    "    \n",
    "    !pip install git+https://github.com/SachsLab/indl.git\n",
    "    \n",
    "    if Path.cwd().stem == 'MonkeyPFCSaccadeStudies':\n",
    "        os.chdir(Path.cwd().parent)\n",
    "    \n",
    "    if not (Path.cwd() / 'MonkeyPFCSaccadeStudies').is_dir():\n",
    "        !git clone --single-branch --recursive https://github.com/SachsLab/MonkeyPFCSaccadeStudies.git\n",
    "        sys.path.append(str(Path.cwd() / 'MonkeyPFCSaccadeStudies'))\n",
    "    \n",
    "    os.chdir('MonkeyPFCSaccadeStudies')\n",
    "        \n",
    "    !pip install -q kaggle\n",
    "    \n",
    "    # Latest version of SKLearn\n",
    "    !pip install -U scikit-learn\n",
    "    \n",
    "    IN_COLAB = True\n",
    "    \n",
    "except ModuleNotFoundError:\n",
    "    import sys\n",
    "    \n",
    "    # chdir to MonkeyPFCSaccadeStudies\n",
    "    if Path.cwd().stem == 'Analysis':\n",
    "        os.chdir(Path.cwd().parent.parent)\n",
    "        \n",
    "    # Add indl repository to path.\n",
    "    # Eventually this should already be pip installed, but it's still under heavy development so this is easier for now.\n",
    "    check_dir = Path.cwd()\n",
    "    while not (check_dir / 'Tools').is_dir():\n",
    "        check_dir = check_dir / '..'\n",
    "    indl_path = check_dir / 'Tools' / 'Neurophys' / 'indl'\n",
    "    sys.path.append(str(indl_path))\n",
    "    \n",
    "    # Make sure the kaggle executable is on the PATH\n",
    "    os.environ['PATH'] = os.environ['PATH'] + ';' + str(Path(sys.executable).parent / 'Scripts')\n",
    "    \n",
    "    IN_COLAB = False\n",
    "\n",
    "# Try to clear any logs from previous runs\n",
    "if (Path.cwd() / 'logs').is_dir():\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.rmtree(str(Path.cwd() / 'logs'))\n",
    "    except PermissionError:\n",
    "        print(\"Unable to remove logs directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from indl.display import turbo_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 24,\n",
    "    'axes.labelsize': 20,\n",
    "    'lines.linewidth': 2,\n",
    "    'lines.markersize': 5,\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'legend.fontsize': 18\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "UVWjIh21OIQ0",
    "outputId": "109a9974-aa9f-49d1-acdc-62a9a9c50cde"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    data_path = Path.cwd() / 'data' / 'monkey_pfc' / 'converted'\n",
    "else:\n",
    "    data_path = Path.cwd() / 'StudyLocationRule' / 'Data' / 'Preprocessed'\n",
    "\n",
    "if not (data_path).is_dir():\n",
    "    !kaggle datasets download --unzip --path {str(data_path)} cboulay/macaque-8a-spikes-rates-and-saccades\n",
    "    print(\"Finished downloading and extracting data.\")\n",
    "else:\n",
    "    print(\"Data directory found. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.misc import load_macaque_pfc, sess_infos, dec_from_enc\n",
    "\n",
    "load_kwargs = {\n",
    "    'x_chunk': 'spikerates',\n",
    "    'valid_outcomes': (0,),  # Use (0, 9) to include trials with incorrect behaviour\n",
    "    'zscore': True,\n",
    "    'dprime_range': (1.0, np.inf),  # Use (-np.inf, np.inf) to include all trials.\n",
    "    'verbose': True,\n",
    "    'min_block_length': 10\n",
    "}\n",
    "\n",
    "test_sess_ix = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_info = sess_infos[test_sess_ix]\n",
    "sess_id = sess_info['exp_code']\n",
    "print(f\"\\nProcessing session {sess_id}\")\n",
    "X, Y, ax_info = load_macaque_pfc(data_path, sess_id, y_type='encoded input', **load_kwargs)\n",
    "decis = dec_from_enc(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-WghpDKKIoJG"
   },
   "source": [
    "### Loading the Data and Generating an Input Based on Task information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cueColor = ax_info['instance_data'][['CueColour']].to_numpy()\n",
    "\n",
    "tmp2 = ax_info['instance_data']\n",
    "df = tmp2.drop(tmp2.index[indx])\n",
    "block_indx = np.unique(df[['Block']].to_numpy(), return_index = True)[1]\n",
    "block_indx = np.append(block_indx, X.shape[0])\n",
    "cueColor = np.delete(cueColor, indx, axis=0)\n",
    "y_true = y\n",
    " \n",
    "\n",
    "# Free memory\n",
    "del tmp\n",
    "del indx\n",
    "del block_length\n",
    "del tmp2\n",
    "\n",
    "encoded_in = np.zeros((X.shape[0], X.shape[1], 10))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    encoded_in[i, 50:, y[i]%4] = 1\n",
    "    if cueColor[i] == 'r':\n",
    "        encoded_in[i, 72:144, 4] = 1\n",
    "    elif cueColor[i] == 'g':\n",
    "        encoded_in[i, 72:144, 5] = 1\n",
    "    else:\n",
    "        encoded_in[i, 72:144, 6] = 1\n",
    "\n",
    "\n",
    "block = 1\n",
    "i = 0\n",
    "while i < X.shape[0] and block < 7:\n",
    "    if y[i]==0 or y[i]==1 or y[i]==2 or y[i]==7:\n",
    "        if cueColor[i] == 'r':\n",
    "            encoded_in[block_indx[block-1]:block_indx[block], :, 7] = 1\n",
    "        elif cueColor[i] == 'g':\n",
    "            encoded_in[block_indx[block-1]:block_indx[block], :, 8] = 1\n",
    "        else:\n",
    "            encoded_in[block_indx[block-1]:block_indx[block], :, 9] = 1\n",
    "        i = block_indx[block]\n",
    "        block = block + 1    \n",
    "    else:\n",
    "        i = i+1\n",
    "    \n",
    "y2 = np.zeros((y.shape[0], X.shape[1]))\n",
    "for i in range(y.shape[0]):\n",
    "    y2[i, :] = y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YyKg7xvqd0nN"
   },
   "outputs": [],
   "source": [
    "SESS_ID = ['sra3_1_j_050_00', 'sra3_1_m_074_0001']\n",
    "BATCH_SIZE = 16\n",
    "P_TRAIN = 0.8\n",
    "P_DROPOUT = 0.5      # Proportion of units to set to 0 on each step.\n",
    "N_RNN_UNITS = 200      # Size of RNN output (state)\n",
    "L2_REG = 1.7e-4       # Parameter regularization strength.\n",
    "STATEFUL = False      # Whether or not to keep state between sequences (True is not tested)\n",
    "EPOCHS = 5          # Number of loops through the entire data set.\n",
    "EPOCHS2 = 15\n",
    "BIN_DURATION = 25     # Width of window used to bin spikes, in 10 ms\n",
    "BIN_OVRLP = 4\n",
    "N_TAPS = 8\n",
    "IMG_SIZE = 160            # Number of bins of history used in a sequence.\n",
    "NCOMPONENTS = 8  # Number of components for CCA decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-gz-175fnBo1",
    "outputId": "be9244e3-8126-46a0-e3b4-9ad1b92f78c8"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(encoded_in, y2, train_size=P_TRAIN)\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices((X_valid, Y_valid))\n",
    "\n",
    "ds_train = ds_train.shuffle(int(encoded_in.shape[0] * P_TRAIN) + 1)\n",
    "ds_train = ds_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "ds_valid = ds_valid.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rHXZKZ7Mtu2A"
   },
   "source": [
    "# Encoded Input to 8 Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JAo8NqmBU-Wz"
   },
   "source": [
    "### Decrease Sampling Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8_RT_hNRU99O",
    "outputId": "acf695f5-42b1-49db-c0a4-00112e516be3"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((encoded_in.shape[0], N_TAPS, encoded_in.shape[2]))\n",
    "X1 = np.zeros((X2.shape[0], N_TAPS, X2.shape[2]))  #downsampled neural activity\n",
    "Y = np.zeros((encoded_in.shape[0], 8))\n",
    "for j in range(N_TAPS-1):\n",
    "    X[:, j, :] = np.mean(encoded_in[:, j*(BIN_DURATION - BIN_OVRLP):j*(BIN_DURATION - BIN_OVRLP) + BIN_DURATION, :], axis=1)  # Downsampled Encoded Input\n",
    "    X1[:, j, :] = np.mean(X2[:, j*(BIN_DURATION - BIN_OVRLP):j*(BIN_DURATION - BIN_OVRLP) + BIN_DURATION, :], axis=1)  # Downsampled Spike Rates\n",
    "\n",
    "X[:, N_TAPS-1, :] = np.mean(encoded_in[:, (N_TAPS-1)*(BIN_DURATION - BIN_OVRLP):, :], axis=1)\n",
    "X1[:, N_TAPS-1, :] = np.mean(X2[:, (N_TAPS-1)*(BIN_DURATION - BIN_OVRLP):, :], axis=1)\n",
    "\n",
    "for i in range(encoded_in.shape[0]):\n",
    "    Y[i, y[i]] = 1\n",
    "\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, y, train_size=P_TRAIN)\n",
    "\n",
    "ds_train1 = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "ds_valid1 = tf.data.Dataset.from_tensor_slices((X_valid, Y_valid))\n",
    "\n",
    "ds_train1 = ds_train1.shuffle(int(X.shape[0] * P_TRAIN) + 1)\n",
    "ds_train1 = ds_train1.batch(BATCH_SIZE, drop_remainder=True)\n",
    "ds_valid1 = ds_valid1.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "  \n",
    "print(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "MTg7RX-6SAe7",
    "outputId": "2afc5ecc-2133-4b94-f4eb-bf04478752c7"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "input_shape = X.shape[1:]\n",
    "output_shape = 8\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape = input_shape)\n",
    "o1 = tf.keras.layers.SimpleRNN(300, activation='tanh', use_bias=True,\n",
    "                            kernel_initializer='glorot_uniform',\n",
    "                            recurrent_initializer='orthogonal',\n",
    "                            bias_initializer='zeros', kernel_regularizer=None,\n",
    "                            recurrent_regularizer=None, bias_regularizer=None,\n",
    "                            activity_regularizer=None, kernel_constraint=None,\n",
    "                            recurrent_constraint=None, bias_constraint=None,\n",
    "                            dropout=0.0, recurrent_dropout=0.0,\n",
    "                            return_sequences=True, return_state=False,\n",
    "                            go_backwards=False, stateful=False, unroll=False, name='rnn1')(inputs)\n",
    "o2 = tf.keras.layers.Dense(32, name='dense1', activation='linear')(o1)\n",
    "o3 = tf.keras.layers.LSTM(100, activation='tanh',dropout = P_DROPOUT,\n",
    "                          recurrent_dropout = 0,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "                          recurrent_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "                          return_sequences=True, stateful=False, name='rnn2')(o2)\n",
    "o4 = tf.keras.layers.Dense(32, activation='linear', name='dense2')(o3)\n",
    "o5 = tf.keras.layers.GlobalAveragePooling1D(name='average')(o4)\n",
    "o6 = tf.keras.layers.Dropout(P_DROPOUT)(o5)\n",
    "outputs = tf.keras.layers.Dense(output_shape, activation='softmax')(o6)\n",
    "\n",
    "model1 = tf.keras.Model(inputs, outputs)\n",
    "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "colab_type": "code",
    "id": "i3qZplxFNp8H",
    "outputId": "34ab1256-a296-46e2-efae-c095f3f7f82b"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model1,\n",
    "    to_file='model.png',\n",
    "    show_shapes=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "cpSTWqR0UoB4",
    "outputId": "638dd00b-8836-4288-b41a-6752b832dae0"
   },
   "outputs": [],
   "source": [
    "# MONKEY J MODEL FIT\n",
    "history = model1.fit(x=ds_train1, epochs=EPOCHS2, verbose=1, validation_data=ds_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "2k7Me9r0NJZF",
    "outputId": "474100d4-b10c-4bb1-9465-2a03b5b9d54a"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hXIeJlkIuN8f"
   },
   "source": [
    "# Neural Activity to 8 Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8Yx91Hsvf0M"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X1, y, train_size=P_TRAIN)\n",
    "\n",
    "ds_trainN = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "ds_validN = tf.data.Dataset.from_tensor_slices((X_valid, Y_valid))\n",
    "\n",
    "ds_trainN = ds_trainN.shuffle(int(X.shape[0] * P_TRAIN) + 1)\n",
    "ds_trainN = ds_trainN.batch(BATCH_SIZE, drop_remainder=True)\n",
    "ds_validN = ds_validN.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "fzdiOTiJuWQ6",
    "outputId": "46d60639-9308-4ffc-c98f-04ac8eed768a"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "input_shape = X1.shape[1:]\n",
    "output_shape = 8\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape = input_shape)\n",
    "o1 = tf.keras.layers.SimpleRNN(200, activation='tanh', use_bias=True,\n",
    "                            kernel_initializer='glorot_uniform',\n",
    "                            recurrent_initializer='orthogonal',\n",
    "                            bias_initializer='zeros', kernel_regularizer=None,\n",
    "                            recurrent_regularizer=None, bias_regularizer=None,\n",
    "                            activity_regularizer=None, kernel_constraint=None,\n",
    "                            recurrent_constraint=None, bias_constraint=None,\n",
    "                            dropout=0.0, recurrent_dropout=0.0,\n",
    "                            return_sequences=True, return_state=False,\n",
    "                            go_backwards=False, stateful=False, unroll=False, name='rnn1')(inputs)\n",
    "o2 = tf.keras.layers.Dense(150, name='dense1', activation='linear')(o1)\n",
    "o3 = tf.keras.layers.LSTM(100,dropout = P_DROPOUT,\n",
    "                          recurrent_dropout = 0,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "                          recurrent_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "                          return_sequences=False, stateful=False, name='rnn2')(o2)\n",
    "o6 = tf.keras.layers.Dropout(P_DROPOUT)(o3)\n",
    "outputs = tf.keras.layers.Dense(output_shape, activation='softmax')(o6)\n",
    "\n",
    "modelN = tf.keras.Model(inputs, outputs)\n",
    "modelN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "modelN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "G_4BA1xvtyX_",
    "outputId": "03f8037c-e21a-4ff0-95eb-f96ed5322135"
   },
   "outputs": [],
   "source": [
    "# MONKEY J MODEL FIT\n",
    "history = modelN.fit(x=ds_trainN, epochs=EPOCHS2, verbose=1, validation_data=ds_validN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "a0Cvgl0u4gs_",
    "outputId": "e51f2b12-b265-43f7-b790-2a265226e800"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_hTaBFKLd6f"
   },
   "source": [
    "## Some Shallow Learning to Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "x8BWCTLjwZaC",
    "outputId": "faa2eddb-0c79-4f32-ae51-f4da10565373"
   },
   "outputs": [],
   "source": [
    "enc_in = np.reshape(encoded_in, (encoded_in.shape[0], encoded_in.shape[1] * encoded_in.shape[2]))\n",
    "yy = np.reshape(y, (y.shape[0],))\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(enc_in, yy, train_size=P_TRAIN)\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_tr, y_tr)\n",
    "print('Accuracy of LDA classifier on training set: {:.2f}'\n",
    "     .format(lda.score(x_tr, y_tr)))\n",
    "print('Accuracy of LDA classifier on test set: {:.2f}'\n",
    "     .format(lda.score(x_ts, y_ts)))\n",
    "\n",
    "print('\\n')\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_tr, y_tr)\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(x_ts, y_ts)))\n",
    "print('\\n')\n",
    "svm = SVC()\n",
    "svm.fit(x_tr, y_tr)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(x_tr, y_tr)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(x_ts, y_ts)))\n",
    "\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jEfs5fY8IM0p"
   },
   "source": [
    "# Encoded Input to Final Gaze Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8v6esDwoGIiw"
   },
   "outputs": [],
   "source": [
    "gaze = df[['PosX', 'PosY']].to_numpy()\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, gaze, train_size=P_TRAIN)\n",
    "\n",
    "ds_train2 = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "ds_valid2 = tf.data.Dataset.from_tensor_slices((X_valid, Y_valid))\n",
    "\n",
    "ds_train2 = ds_train2.shuffle(int(X.shape[0] * P_TRAIN) + 1)\n",
    "ds_train2 = ds_train2.batch(BATCH_SIZE, drop_remainder=True)\n",
    "ds_valid2 = ds_valid2.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "DDkzPxfmEKSs",
    "outputId": "df20d856-6851-43b4-b009-2a39e11bf616"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "input_shape = X.shape[1:]\n",
    "output_shape = gaze.shape[1]\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape = input_shape)\n",
    "o1 = tf.keras.layers.SimpleRNN(N_RNN_UNITS, activation='tanh', use_bias=True,\n",
    "                            kernel_initializer='glorot_uniform',\n",
    "                            recurrent_initializer='orthogonal',\n",
    "                            bias_initializer='zeros', kernel_regularizer=None,\n",
    "                            recurrent_regularizer=None, bias_regularizer=None,\n",
    "                            activity_regularizer=None, kernel_constraint=None,\n",
    "                            recurrent_constraint=None, bias_constraint=None,\n",
    "                            dropout=0.0, recurrent_dropout=0.0,\n",
    "                            return_sequences=True, return_state=False,\n",
    "                            go_backwards=False, stateful=False, unroll=False, name='rnn1')(inputs)\n",
    "o2 = tf.keras.layers.Dense(32, name='dense1')(o1)\n",
    "o3 = tf.keras.layers.LSTM(100, dropout = P_DROPOUT,\n",
    "                          recurrent_dropout = 0,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "                          recurrent_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "                          return_sequences=True, stateful=False, name='rnn2')(o2)\n",
    "o4 = tf.keras.layers.Dense(32, name='dense2')(o3)\n",
    "o5 = tf.keras.layers.AveragePooling1D(pool_size=8)(o4)\n",
    "o6 = tf.keras.layers.Flatten()(o5)\n",
    "o7 = tf.keras.layers.Dropout(P_DROPOUT)(o6)\n",
    "outputs = tf.keras.layers.Dense(output_shape, activation='linear')(o7)\n",
    "\n",
    "model2 = tf.keras.Model(inputs, outputs)\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "x2l-JnX4GPWs",
    "outputId": "f2bd305c-51a8-4b4a-d14d-192def3c24d2"
   },
   "outputs": [],
   "source": [
    "history = model2.fit(x=ds_train2, epochs=EPOCHS2, verbose=1, validation_data=ds_valid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "st4IqXiSHIWm"
   },
   "outputs": [],
   "source": [
    "pred_y = model2.predict(x=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "AbnP1-ghGjpp",
    "outputId": "0e6533b6-08d8-43c6-f990-c0513ccbd0fb"
   },
   "outputs": [],
   "source": [
    "t = [900, 1017]\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "plt.plot(gaze[t[0]:t[1], 0])\n",
    "plt.plot(pred_y[t[0]:t[1], 0])\n",
    "for ix, label in enumerate(['True', 'RNN']):\n",
    "    plt.gca().lines[ix].set_label(label)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Pos-x')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(gaze[t[0]:t[1], 1])\n",
    "plt.plot(pred_y[t[0]:t[1], 1])\n",
    "for ix, label in enumerate(['True', 'RNN']):\n",
    "    plt.gca().lines[ix].set_label(label)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Pos-y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w692QusPIX-7"
   },
   "source": [
    "## Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBeGNNcEIXjo"
   },
   "outputs": [],
   "source": [
    "pred_vel = np.diff(pred_y, axis=0)\n",
    "pred_vel /= np.linalg.norm(pred_vel)\n",
    "gaze_vel = np.diff(gaze, axis=0)\n",
    "gaze_vel /= np.linalg.norm(gaze_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "Yv8xkmgpJCN1",
    "outputId": "2709495b-54e0-47ff-c159-b66a197eae52"
   },
   "outputs": [],
   "source": [
    "t = [900, 1017]\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "plt.plot(gaze_vel[t[0]:t[1], 0])\n",
    "plt.plot(pred_vel[t[0]:t[1], 0])\n",
    "for ix, label in enumerate(['True', 'RNN']):\n",
    "    plt.gca().lines[ix].set_label(label)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Vel-x')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(gaze_vel[t[0]:t[1], 1])\n",
    "plt.plot(pred_vel[t[0]:t[1], 1])\n",
    "for ix, label in enumerate(['True', 'RNN']):\n",
    "    plt.gca().lines[ix].set_label(label)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Vel-y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYzzrI3Ub8fZ"
   },
   "source": [
    "# Encoded Input to Continous Gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "52VCWekOb_rB",
    "outputId": "f6d73b69-4895-4641-955e-6efa2ee65406"
   },
   "outputs": [],
   "source": [
    "gaze_con, _, ax_info = load_macaque_pfc(datadir, SESS_ID[0], x_chunk='gaze', zscore=True)\n",
    "\n",
    "# deleting blocks of gaze with less than 10 trials\n",
    "tmp = np.unique(ax_info['instance_data'][['Block']].to_numpy(), return_index = True)[1]\n",
    "block_length = np.diff(tmp)\n",
    "indx = []\n",
    "for i in range(len(tmp)-1):\n",
    "  if block_length[i] < 10:\n",
    "    indx = indx + list(range(tmp[i], tmp[i+1]))\n",
    "\n",
    "gaze_con = np.delete(gaze_con, indx, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UoKlsQN2hUVq"
   },
   "source": [
    "## Loading the Neural Data and Generating the Encoded Input Again for Assurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "DfnKV5iGhbD8",
    "outputId": "c5543468-6b03-40a0-d244-0cda83eb7f46"
   },
   "outputs": [],
   "source": [
    "X2, y, ax_info = load_macaque_pfc(datadir, SESS_ID[0], zscore=True)\n",
    "cueColor = ax_info['instance_data'][['CueColour']].to_numpy()\n",
    "\n",
    "# Deleting blocks with less than 10 trials\n",
    "tmp = np.unique(ax_info['instance_data'][['Block']].to_numpy(), return_index = True)[1]\n",
    "block_length = np.diff(tmp)\n",
    "indx = []\n",
    "for i in range(len(tmp)-1):\n",
    "  if block_length[i] < 10:\n",
    "    indx = indx + list(range(tmp[i], tmp[i+1]))\n",
    "\n",
    "X2 = np.delete(X2, indx, axis=0)\n",
    "y = np.delete(y, indx, axis=0)\n",
    "\n",
    "\n",
    "# Making the encoded input again\n",
    "tmp2 = ax_info['instance_data']\n",
    "df = tmp2.drop(tmp2.index[indx])\n",
    "block_indx = np.unique(df[['Block']].to_numpy(), return_index = True)[1]\n",
    "block_indx = np.append(block_indx, X2.shape[0])\n",
    "cueColor = np.delete(cueColor, indx, axis=0)\n",
    " \n",
    "\n",
    "# Free memory\n",
    "del tmp\n",
    "del indx\n",
    "del block_length\n",
    "del tmp2\n",
    "\n",
    "encoded_in = np.zeros((X2.shape[0], X2.shape[1], 10))\n",
    "\n",
    "for i in range(X2.shape[0]):\n",
    "  encoded_in[i, 50:, y[i]%4] = 1\n",
    "  if cueColor[i] == 'r':\n",
    "    encoded_in[i, 72:144, 4] = 1\n",
    "  elif cueColor[i] == 'g':\n",
    "    encoded_in[i, 72:144, 5] = 1\n",
    "  else:\n",
    "    encoded_in[i, 72:144, 6] = 1\n",
    "\n",
    "\n",
    "block = 1\n",
    "i = 0\n",
    "while i < X2.shape[0] and block < 7:\n",
    "  if y[i]==0 or y[i]==1 or y[i]==2 or y[i]==7:\n",
    "    if cueColor[i] == 'r':\n",
    "      encoded_in[block_indx[block-1]:block_indx[block], :, 7] = 1\n",
    "    elif cueColor[i] == 'g':\n",
    "      encoded_in[block_indx[block-1]:block_indx[block], :, 8] = 1\n",
    "    else:\n",
    "      encoded_in[block_indx[block-1]:block_indx[block], :, 9] = 1\n",
    "    i = block_indx[block]\n",
    "    block = block + 1    \n",
    "  else:\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMk1bKSxejAJ"
   },
   "outputs": [],
   "source": [
    "X3 = np.zeros((gaze_con.shape[0], encoded_in.shape[1], gaze_con.shape[2]))\n",
    "\n",
    "# downsampling continuous gaze to same as encoded input\n",
    "X3[:, :-1, :] = gaze_con[:, ::10, :]\n",
    "X3[:, -1, :] = gaze_con[:, -1, :]\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(encoded_in, X3, train_size=P_TRAIN)\n",
    "\n",
    "ds_train4 = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "ds_valid4 = tf.data.Dataset.from_tensor_slices((X_valid, Y_valid))\n",
    "\n",
    "ds_train4 = ds_train4.shuffle(int(encoded_in.shape[0] * P_TRAIN) + 1)\n",
    "ds_train4 = ds_train4.batch(BATCH_SIZE, drop_remainder=True)\n",
    "ds_valid4 = ds_valid4.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "LWlGOhSxe7o3",
    "outputId": "c10cfc25-9119-4c0c-cf5f-fa19347c8eaf"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "input_shape = encoded_in.shape[1:]\n",
    "output_shape = X3.shape[2]\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape = input_shape)\n",
    "o1 = tf.keras.layers.SimpleRNN(N_RNN_UNITS, activation='tanh', use_bias=True,\n",
    "                            kernel_initializer='glorot_uniform',\n",
    "                            recurrent_initializer='orthogonal',\n",
    "                            bias_initializer='zeros', kernel_regularizer=None,\n",
    "                            recurrent_regularizer=None, bias_regularizer=None,\n",
    "                            activity_regularizer=None, kernel_constraint=None,\n",
    "                            recurrent_constraint=None, bias_constraint=None,\n",
    "                            dropout=0.0, recurrent_dropout=0.0,\n",
    "                            return_sequences=True, return_state=False,\n",
    "                            go_backwards=False, stateful=False, unroll=False, name='rnn1')(inputs)\n",
    "o2 = tf.keras.layers.Dense(32, name='dense1')(o1)\n",
    "o3 = tf.keras.layers.LSTM(100, dropout = P_DROPOUT,\n",
    "                          recurrent_dropout = 0,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "                          recurrent_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "                          return_sequences=True, stateful=False, name='rnn2')(o2)\n",
    "o4 = tf.keras.layers.Dense(32, name='dense2')(o3)\n",
    "o5 = tf.keras.layers.Dropout(P_DROPOUT)(o4)\n",
    "outputs = tf.keras.layers.Dense(output_shape, activation='linear')(o5)\n",
    "\n",
    "model8 = tf.keras.Model(inputs, outputs)\n",
    "model8.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "rJAVB3ikfDir",
    "outputId": "4b30bd5d-3b4f-43d9-ac3e-a045fa334021"
   },
   "outputs": [],
   "source": [
    "history = model8.fit(x=ds_train4, epochs=EPOCHS2, verbose=1, validation_data=ds_valid4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PLViOc2zSEby"
   },
   "outputs": [],
   "source": [
    "predicted_gaze = model8.predict(encoded_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "colab_type": "code",
    "id": "iWuJHLD_SdbE",
    "outputId": "32255758-6fab-4e47-b1ee-cbf96b71bbf4"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(10,8))\n",
    "fig.suptitle('Decoding Monkeys Time-Continuous Gaze')\n",
    "axs[0].plot(predicted_gaze[20, :, 0], 'C0', label='RNN')\n",
    "axs[0].plot(X3[20, :, 0], 'C1', label='Actual')\n",
    "axs[0].set_title(\"Gaze X-Position\")\n",
    "axs[1].plot(predicted_gaze[20, :, 1], 'C0')\n",
    "axs[1].plot(X3[20, :, 1], 'C1')\n",
    "axs[1].set_title(\"Gaze Y-Position\")\n",
    "fig.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKRSKZ1_fNxF"
   },
   "outputs": [],
   "source": [
    "layer_name = 'dense1'\n",
    "intermediate_layer_model1 = tf.keras.Model(inputs=model8.input,\n",
    "                                 outputs=model8.get_layer(layer_name).output)\n",
    "layer_name = 'dense2'\n",
    "intermediate_layer_model2 = tf.keras.Model(inputs=model8.input,\n",
    "                                 outputs=model8.get_layer(layer_name).output)\n",
    "data = encoded_in\n",
    "intermediate_output1 = intermediate_layer_model1.predict(data)\n",
    "intermediate_output2 = intermediate_layer_model2.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_M15jR7QfGlS"
   },
   "source": [
    "## CCA on RNN activations and Spikerates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJ2lDkypZ12q"
   },
   "outputs": [],
   "source": [
    "A = np.mean(X2, axis=0) # Spikerates averaged over trials\n",
    "B = np.mean(intermediate_output1, axis=0) # RNN activations averaged over trials\n",
    "cca = CCA(n_components = NCOMPONENTS)\n",
    "\n",
    "a_score, b_score = cca.fit_transform(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "colab_type": "code",
    "id": "zINenp0YKAXh",
    "outputId": "69b946a4-a61c-45d9-f0be-62a8264f5aa7"
   },
   "outputs": [],
   "source": [
    "# Normalizing the components to plot with each other\n",
    "a_score_norm = (a_score - np.mean(a_score, axis=0))/np.max(np.abs(a_score), axis=0)\n",
    "b_score_norm = (b_score - np.mean(b_score, axis=0))/np.max(np.abs(b_score), axis=0)\n",
    "\n",
    "COMPONENTSPLOT = 8  # To plot the first 'COMPONENTSPLOT'\n",
    "fig, axs = plt.subplots(int(COMPONENTSPLOT/4), 4, figsize=(20,10))\n",
    "fig.suptitle('CCA First 8 Components on Trial-Averaged Data')\n",
    "for component in range(COMPONENTSPLOT):\n",
    "  axs[int(component/4), component%4].plot(a_score_norm[:,component], 'C0')\n",
    "  axs[int(component/4), component%4].plot(b_score_norm[:,component], 'C1')\n",
    "  axs[int(component/4), component%4].set_title(\"Comopnent #: \" + str(component+1))\n",
    "\n",
    "fig.legend(('Neural Acitivity', 'RNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "R_bl6Yzdum2e",
    "outputId": "687d8fc4-16a8-4d9e-95b0-eed9b488ae03"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import linregress\n",
    "\n",
    "corrcoef, p_value = pearsonr(a_score[:,0],b_score[:,0])\n",
    "print(\"Pearson R correlation coefficient for the first component is: \" + str(corrcoef))\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(a_score[:,0],b_score[:,0])\n",
    "print(\"\\nScipy linear regression R2 value for the first component is: \" + str(r_value**2))\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/37398856/how-to-get-the-first-canonical-correlation-from-sklearns-cca-module\n",
    "print(\"\\nNumpy correlation coefficient for all components are: \" + str(np.corrcoef(a_score.T, b_score.T).diagonal(offset=NCOMPONENTS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XXOgiUrVGuD-"
   },
   "source": [
    "### Reconstrocting maximum-correlated signals in original space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aZocxtKSCSBs"
   },
   "outputs": [],
   "source": [
    "neural_reconstructed = cca.inverse_transform(a_score_norm)\n",
    "rnn_reconstructed = cca.inverse_transform(b_score_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5tEywaj-G_Xz"
   },
   "source": [
    "Plotting the reconstructed neural and RNN components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "colab_type": "code",
    "id": "DUSRH9owG-61",
    "outputId": "1e4b3c6f-c510-4714-fdeb-423dacea93f8"
   },
   "outputs": [],
   "source": [
    "NCHANNELS = 8\n",
    "fig, axs = plt.subplots(int(NCHANNELS/4), 4, figsize=(20,10))\n",
    "fig.suptitle('First 8 Channels of Reconstructed Neural Activity and RNN Activations in Original Space')\n",
    "for channel in range(NCHANNELS):\n",
    "  axs[int(channel/4), channel%4].plot(neural_reconstructed[:,channel], 'C0')\n",
    "  axs[int(channel/4), channel%4].plot(rnn_reconstructed[:,channel], 'C1')\n",
    "  axs[int(channel/4), channel%4].set_title(\"Channel \" + str(channel+1))\n",
    "\n",
    "fig.legend(('Neural Acitivity', 'RNN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCel9IzLvrIw"
   },
   "source": [
    "## Plotting the Original Spike Rates to Compare with The Reconstructed Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GXsi8UAF9SS5"
   },
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HossfrrOv3He",
    "outputId": "dbf76922-1488-42be-df75-862c1c1b34c6"
   },
   "outputs": [],
   "source": [
    "original = A\n",
    "reconstructed = neural_reconstructed\n",
    "\n",
    "NCHANNELS = 32\n",
    "fig, axs = plt.subplots(int(NCHANNELS/4), 4, figsize=(20,35))\n",
    "fig.suptitle('Original Spike Rates VS. Reconstructed')\n",
    "for channel in range(NCHANNELS):\n",
    "  axs[int(channel/4), channel%4].plot(original[:,channel], 'C0')\n",
    "  axs[int(channel/4), channel%4].plot(reconstructed[:,channel], 'C1')\n",
    "  axs[int(channel/4), channel%4].set_title(\"Channel \" + str(channel+1))\n",
    "\n",
    "fig.legend(('Original', 'Reconstructed'))\n",
    "fig.tight_layout(rect=[0, 0.03, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMFahK2k84Do"
   },
   "source": [
    "IF we use NCOMPONENTS = 32, the reconstucted neural activity and the original spike rates will be exactly the same (As it should be)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "8vpRkztmSA45",
    "JAo8NqmBU-Wz",
    "eMmkVzfcXYNV",
    "8rktdy_9lOWu",
    "Gg5XgclGzzZH",
    "rCNSkqyxeMzj",
    "QVbgVGh5vu-5",
    "E_hTaBFKLd6f",
    "KwUJm-XEYPWi",
    "w692QusPIX-7",
    "HCaIgFsUG6dI"
   ],
   "name": "06_RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
